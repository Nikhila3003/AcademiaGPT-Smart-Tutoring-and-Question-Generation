page_content='**Prerequisites**  \n- [Intro](../p01_pandas_intro/v01_pandas_intro.ipynb)\n- [Boolean selection](../p01_pandas_intro/v02_pandas_basics.ipynb)\n- [Indexing](../p02_organizing_data_with_pandas_1/01_the_index.ipynb)  \n**Outcomes**  \n- Be able to use string methods to clean data that comes as a string\n- Be able to drop missing data\n- Use cleaning methods to prepare and analyze a real dataset  \n**Data**  \n- Item information from about 3,000 Chipotle meals from about 1,800\nGrubhub orders  \n```python\nimport pandas as pd\nimport numpy as np\n```' metadata={'Header 1': 'Cleaning Data'}page_content='- [Cleaning Data](#Cleaning-Data)\n- [Cleaning Data](#Cleaning-Data)\n- [String Methods](#String-Methods)\n- [Type Conversions](#Type-Conversions)\n- [Missing Data](#Missing-Data)\n- [Case Study](#Case-Study)\n- [Appendix: Performance of `.str` Methods](#Appendix:-Performance-of-`.str`-Methods)' metadata={'Header 1': 'Cleaning Data', 'Header 2': 'Outline'}page_content='For many data projects, a [significant proportion of\ntime](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#74d447456f63)\nis spent collecting and cleaning the data — not performing the analysis.  \nThis non-analysis work is often called “data cleaning”.  \npandas provides very powerful data cleaning tools, which we\nwill demonstrate using the following dataset.  \n```python\ndf = pd.DataFrame({"numbers": ["#23", "#24", "#18", "#14", "#12", "#10", "#35"],\n"nums": ["23", "24", "18", "14", np.nan, "XYZ", "35"],\n"colors": ["green", "red", "yellow", "orange", "purple", "blue", "pink"],\n"other_column": [0, 1, 0, 2, 1, 0, 2]})\ndf  \n```  \nWhat would happen if we wanted to try and compute the mean of\n`numbers`?  \n```python\ndf["numbers"].mean()  \n```  \nIt throws an error!  \nCan you figure out why?  \nHint: When looking at error messages, start at the very\nbottom.  \nThe final error says, `TypeError: Could not convert #23#24... to numeric`.  \nThe problem is that if we look at the `dtypes` of the DataFrame that the elements of the `numbers` column are strings!  \nWe learned how to modify strings in one of the lectures about Python fundamentals. Let\'s modify one of the strings contained in the `numbers` column as a reminder:  \n```python\nnumbers_str = "#35"  \nnumbers_num = int(numbers_str.replace("#", ""))  \nprint(numbers_str)\nprint(numbers_num)\nprint(type(numbers_num))\n```' metadata={'Header 1': 'Cleaning Data', 'Header 2': 'Cleaning Data'}page_content='Our solution to the previous exercise was to remove the `#` by using\nthe `replace` string method: `int(numbers_str.replace("#", ""))`.  \nOne way to make this change to every element of a column would be to\nloop through all elements of the column and apply the desired string\nmethods…  \n```python\n%%time' metadata={'Header 1': 'Cleaning Data', 'Header 2': 'String Methods'}page_content='for row in df.iterrows():' metadata={'Header 1': 'Iterate over all rows'}page_content='index_value, column_values = row' metadata={'Header 1': 'The first element is an index and the second is a Series with the data from that row'}page_content='clean_number = int(column_values["numbers"].replace("#", ""))' metadata={'Header 1': 'Apply string method'}page_content='df.at[index_value, "numbers_loop"] = clean_number\n```  \nWhile this is fast for a small dataset like this, this method slows for larger datasets.  \nOne *significantly* faster (and easier) method is to apply a string\nmethod to an entire column of data.  \nMost methods that are available to a Python string (we learned a\nfew of them in the [strings lecture](../python_fundamentals/basics.ipynb)) are\nalso available to a pandas Series that has `dtype` object.  \nWe access them by doing `s.str.method_name` where `method_name` is\nthe name of the method.  \nWhen we apply the method to a Series, it is applied to all rows in the\nSeries in one shot!  \nLet’s redo our previous example using a pandas `.str` method.  \n```python\n%%time' metadata={'Header 1': 'the loop the best chance to beat a faster method which we show you next.'}page_content='df["numbers_str"] = df["numbers"].str.replace("#", "")  \ndf.dtypes\n```  \nWe can use `.str` to access almost any string method that works on\nnormal strings. (See the [official\ndocumentation](https://pandas.pydata.org/pandas-docs/stable/text.html)\nfor more information.)  \n```python\ndf["colors"].str.contains("p")\n```  \n```python\ndf["colors"].str.capitalize()\n```' metadata={'Header 1': 'See appendix at the end of the lecture for an application on a larger DataFrame'}page_content='In our example above, the `dtype` of the `numbers_str` column shows that pandas still treats\nit as a string even after we have removed the `"#"`.  \nWe need to convert this column to numbers.  \nThe best way to do this is using the `pd.to_numeric` function.  \nThis method attempts to convert whatever is stored in a Series into\nnumeric values  \nFor example, after the `"#"` removed, the numbers of column\n`"numbers"` are ready to be converted to actual numbers.  \n```python\ndf["numbers_numeric"] = pd.to_numeric(df["numbers_str"])\n```  \n```python\ndf.dtypes\n```  \n```python\ndf.head()\n```  \nWe can convert to other types well.  \nUsing the `astype` method, we can convert to any of the supported\npandas `dtypes` (recall the [intro lecture](intro.ipynb)).  \nBelow are some examples. (Pay attention to the reported `dtype`)  \n```python\ndf["numbers_numeric"].astype(str)\n```  \n```python\ndf["numbers_numeric"].astype(float)\n```' metadata={'Header 1': 'See appendix at the end of the lecture for an application on a larger DataFrame', 'Header 2': 'Type Conversions'}page_content='Many datasets have missing data.  \nIn our example, we are missing an element from the `"nums"` column.  \n```python\ndf\n```  \nWe can find missing data by using the `isnull` method.  \n```python\ndf.isnull()\n```  \nWe might want to know whether particular rows or columns have any\nmissing data.  \nTo do this we can use the `.any` method on the boolean DataFrame\n`df.isnull()`.  \n```python\ndf.isnull().any(axis=0)\n```  \n```python\ndf.isnull().any(axis=1)\n```  \nMany approaches have been developed to deal with missing data, but the two most commonly used (and the corresponding DataFrame method) are:  \n- Exclusion: Ignore any data that is missing (`.dropna`).\n- Imputation: Compute “predicted” values for the data that is missing\n(`.fillna`).  \nFor the advantages and disadvantages of these (and other) approaches,\nconsider reading the [Wikipedia\narticle](https://en.wikipedia.org/wiki/Missing_data).  \nFor now, let’s see some examples.  \n```python' metadata={'Header 1': 'See appendix at the end of the lecture for an application on a larger DataFrame', 'Header 2': 'Missing Data'}page_content='df.dropna(axis=1)\n```  \n```python' metadata={'Header 1': 'drop all rows containing a missing observation'}page_content='df.fillna(value=100)\n```  \n```python' metadata={'Header 1': 'fill the missing values with a specific value'}page_content='df.fillna(method="bfill")\n```  \n```python' metadata={'Header 1': 'use the _next_ valid observation to fill the missing data'}page_content='df.fillna(method="ffill")\n```  \nWe will see more examples of dealing with missing data in future\nchapters.' metadata={'Header 1': 'use the _previous_ valid observation to fill missing data'}page_content='We will now use data from an\n[article](https://www.nytimes.com/interactive/2015/02/17/upshot/what-do-people-actually-order-at-chipotle.html)\nwritten by The Upshot at the NYTimes.  \nThis data has order information from almost 2,000 Chipotle orders and\nincludes information on what was ordered and how much it cost.  \n```python\nurl = "https://datascience.quantecon.org/assets/data/chipotle_raw.csv.zip"\nchipotle = pd.read_csv(url)\nchipotle.head()\n```  \n```python\nchipotle.head()\n```  \n**Exercise**  \nWe\'d like you to use this data to answer the following questions.  \n- What is the average price of an item with chicken?\n- What is the average price of an item with steak?\n- Did chicken or steak produce more revenue (total)?\n- How many missing items are there in this dataset? How many missing\nitems in each column?  \nHint: before you will be able to do any of these things you will need to\nmake sure the `item_price` column has a numeric `dtype` (probably\nfloat)  \n```python  \n```  \n```python  \n```  \n```python  \n```  \n```python  \n```' metadata={'Header 1': 'use the _previous_ valid observation to fill missing data', 'Header 2': 'Case Study'}page_content='Let’s repeat the “remove the `#`” example from above, but this time on\na much larger dataset.  \n```python\nimport numpy as np\ntest = pd.DataFrame({"floats": np.round(100*np.random.rand(100_000), 2)})\ntest["strings"] = test["floats"].astype(str) + "%"\ntest.head()\n```  \n```python\n%%time  \nfor row in test.iterrows():\nindex_value, column_values = row\nclean_number = column_values["strings"].replace("%", "")\ntest.at[index_value, "numbers_loop"] = clean_number\n```  \n```python\n%%time\ntest["numbers_str_method"] = test["strings"].str.replace("%", "")\n```  \n```python\ntest["numbers_str_method"].equals(test["numbers_loop"])\n```  \nWe got the exact same result in a fraction of the time!' metadata={'Header 1': 'use the _previous_ valid observation to fill missing data', 'Header 2': 'Appendix: Performance of `.str` Methods'}