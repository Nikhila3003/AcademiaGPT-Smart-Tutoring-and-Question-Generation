page_content='**Outcomes**  \n- Learn how to download file from internet using the [requests](https://requests.readthedocs.io/en/master/) library\n- Know how to operate on a `.zip` file in memory, without writing to hard drive\n- Practice merging datasets  \n**Note: requires internet access to run.**  \nThis Jupyter notebook was originally created in 2016 by Dave Backus, Chase Coleman, Brian LeBlanc, and Spencer Lyon for the NYU Stern course [Data Bootcamp](http://databootcamp.nyuecon.com/).  \nThe notebook has been modified for this course  \n```python\n%matplotlib inline  \nimport pandas as pd             # data package\nimport matplotlib.pyplot as plt # graphics\nimport datetime as dt           # date tools, used to note current date' metadata={'Header 1': 'Pandas Example: MovieLens Data'}page_content='import os                       # operating system tools (check files)\nimport requests, io             # internet and input tools\nimport zipfile as zf            # zip file tools\nimport shutil                   # file management tools\n```' metadata={'Header 1': 'these are new'}page_content='The [GroupLens](https://grouplens.org/) team at the University of Minnesota has prepared many datasets  \nOne is called [MovieLens](https://grouplens.org/datasets/movielens/), and contains millions of movie ratings by viewers and users of the MovieLens website  \nWe will use a small subset of the data with 100,000 ratings  \nThis data comes in a `.zip` file that contains a handful of csv\'s and a readme  \nHere are some details about the zipped files:  \n* `ratings.csv`:  each line is an individual film rating with the rater and movie id\'s and the rating.  Order:  `userId, movieId, rating, timestamp`.\n* `tags.csv`:  each line is a tag on a specific film.  Order:  `userId, movieId, tag, timestamp`.\n* `movies.csv`:  each line is a movie name, its id, and its genre.  Order:  `movieId, title, genres`.  Multiple genres are separated by "pipes" `|`.\n* `links.csv`:  each line contains the movie id and corresponding id\'s at [IMBd](http://www.imdb.com/) and [TMDb](https://www.themoviedb.org/).  \nWe are interested in the `ratings.csv` and `movies.csv` files as pandas DataFrames  \nThere are at least two approaches to doing this:  \n1. Download the file to the hard drive, unzip manually, then come back and use `pd.read_csv`\n2. Have Python download the file, learn to use Python to handle zip files, then use `pd.read_csv`  \nThe first option is likely easier, but the second is more powerful  \nWe will choose option 2 here as it gives us a chance to learn more "real-world" data+Python skills  \n**Why do it the hard way?**  \n- It builds character\n- Entire analysis can be self-contained in our notebook, no external *by hand* steps  needed\n- Can be applied to other datasets, as we\'ll surely see a zip file again in the future' metadata={'Header 1': 'these are new', 'Header 2': 'MovieLens data'}page_content="**WANT:** create pandas DataFrames from the `ratings.csv` and `movies.csv` files in the zipfile on the GroupLens website  \nLet's unpack what steps need to happen:  \n1. Download the file: we'll use the [requests](http://docs.python-requests.org/) package\n2. Unpack raw downloaded content as file: using built-in [io](https://docs.python.org/3.5/library/io.html) module's `io.BytesIO`\n3. Access csv files inside the zip file: using built-in [zipfile](https://docs.python.org/3.5/library/zipfile.html) module to read csv's from zip\n4. Read in csvs: easy part -- using `pd.read_csv`" metadata={'Header 1': 'these are new', 'Header 2': 'Automated file download'}page_content='The `requests` documentation states  \n>Recreational use of other HTTP libraries may result in dangerous side-effects, including: security vulnerabilities, verbose code, reinventing the wheel, constantly reading documentation, depression, headaches, or even death.  \nWe whole-heartedly agree' metadata={'Header 1': 'these are new', 'Header 2': 'Automated file download', 'Header 3': 'Digression 1'}page_content='We found this [Stack Overflow exchange](http://stackoverflow.com/questions/23419322/download-a-zip-file-and-extract-it-in-memory-using-python3) helpful when creating this solution' metadata={'Header 1': 'these are new', 'Header 2': 'Automated file download', 'Header 3': 'Digression 2'}page_content="Let's get to it!  \nHere we download the file and print out some information about the response object  \n```python" metadata={'Header 1': 'these are new', 'Header 2': 'Automated file download', 'Header 3': 'Step 1: Download the file'}page_content="url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\nres = requests.get(url)" metadata={'Header 1': 'Step 1 -- download the file'}page_content="print('Response status code:', res.status_code)\nprint('Response type:', type(res))\nprint('Response .content:', type(res.content))\nprint('Response headers:\\n', res.headers, sep='')\n```" metadata={'Header 1': '(sub-step, see what the response looks like)'}page_content="The ZipFile is a binary file format (not plain text)  \nFor this reason we need to treat the contents of the file as bytes  \nWe'll load in `res.content` into an instance of `io.BytesIO  \n```python" metadata={'Header 1': '(sub-step, see what the response looks like)', 'Header 3': 'Step 2: read file as bytes'}page_content='bytes = io.BytesIO(res.content)\n```' metadata={'Header 1': 'Step 2 -- read bytes of response contentonvert bytes to zip file'}page_content='Now we have downloaded file, and interpreted as a binary source (`BytesIO`)  \nThis is not just any binary file, but rather a zip compressed file  \nPython knows how to handle these using the built-in `zipfile` module  \nBelow we tell Python to interpret the `BytesIO` as a ZipFile  \n```python' metadata={'Header 1': 'Step 2 -- read bytes of response contentonvert bytes to zip file', 'Header 3': 'Step 3: Interpret bytes as ZipFile'}page_content="zip = zf.ZipFile(bytes)\nprint('Type of zipfile object:', type(zip))\n```  \nNow that we have a ZipFile, we need to explore what is inside  \nThe `ZipFile` class has a handy method named `namelist`  \nThis method lists all folders and files in the zip archive  \nLet's take a look  \n```python" metadata={'Header 1': 'Step 3 -- Interpret bytes as zipfile'}page_content='names = zip.namelist()\nnames\n```  \nNotice that our target `ratings.csv` and `movies.csv` files are there  \nHowever, they are in a folder named `ml-latest-small`  \nWe could write out the "path" to those files by hand, but instead we\'ll let Python find them for us  \n```python\nmovie_fn = [n for n in names if "movies" in n][0]\nratings_fn = [n for n in names if "ratings" in n][0]  \nprint("The path to movies.csv is:", movie_fn)\n```' metadata={'Header 1': '(sub-step, inspect the file)'}page_content="Now that we have the ZipFile **and** the path to our csvs, let's read them in as DataFrames  \nFor this we'll use our friend `pd.read_csv`  \nWe need to call the `.open` method on our zipfile  \nThis method expects the path to the file we need to open, these are saved in `movie_fn` and `ratings_fn` above  \n```python" metadata={'Header 1': '(sub-step, inspect the file)', 'Header 3': 'Step 4: `pd.read_csv` the Files'}page_content="movies  = pd.read_csv(zip.open(movie_fn))\nratings = pd.read_csv(zip.open(ratings_fn))\n```  \nLet's take a look at the data  \n```python\nmovies.info()\nmovies.head(3)\n```  \n```python\nratings.info()\nratings.head(3)\n```" metadata={'Header 1': "extract and read csv's"}page_content="The movie ratings in the dataframe `ratings` give us individual opinions about movies, but they don't include the name of the movie.  \n**Why not?**" metadata={'Header 1': "extract and read csv's", 'Header 2': 'Data Organization'}page_content='Storing movie names in rating DataFrame would cause movie name to be repeated many times  \nThe string "Grumpier Old Men (1995)" takes up more space in a file than the integer `3`  \nSo, the GroupLens team decided to store the movie name in `movies.csv`, and a `movidId` column that is an integer  \nIn other files, they can use just the `movieId` column  \nThis is an eample of a relational database (think SQL) technique known as [normalization](https://en.wikipedia.org/wiki/Database_normalization)  \n**Why normalize?**  \nThere are many benefits to normalization, but two that immediately come to mind are:  \n1. Save storage space: movie title (and genres in this example) are not repeated for each rating\n2. Easier to maintain/update  \nFor the second point, suppose the GroupLens team wanted to include the movie\'s director  \nIn the current, normalized format they would add a `director` column to `movies.csv` and have one row to update per movie  \nIf they instead chose to put the movie title inside the `ratings.csv` they would have to find all occurances of each movie and add the director' metadata={'Header 1': "extract and read csv's", 'Header 2': 'Data Organization', 'Header 3': 'Normalization'}page_content='We **want** to be able to analyze the ratings for movies, and associate those ratings with a movie name  \nWe need a way to bring in the movie title information into the `ratings` DataFrame  \nThis is a perfect use case for `merge`!  \nLet\'s start with a small example, just the first three rows of ratings:  \nHere\'s what this looks like  \n```python\nratings.head(3)\n```  \nNow let\'s see what happens when we `merge` this with the `movies` DataFrame  \n```python\nratings.head(3).merge(movies, on="movieId")\n```  \nHere\'s a breakdown of what happened:  \n- For each row in `ratings.head(3)` pandas found the `movieId`\n- It then looked for row(s) in `movies` that had a matching `movieId`\n- It then added columns `title` and `genres` alongside existing columns from `ratings` (`userId`, `rating`, `timestamp`) to form combined DataFrame  \nLet\'s now apply this `merge` to the whole `ratings` dataset  \n```python\ncombo = pd.merge(ratings, movies,   # left and right df\'s\nhow=\'left\',        # add to left\non=\'movieId\'       # link with this variable/column\n)  \nprint(\'Dimensions of ratings:\', ratings.shape)\nprint(\'Dimensions of movies:\', movies.shape)\nprint(\'Dimensions of new df:\', combo.shape)  \ncombo.head(20)\n```  \n**Exercise.** Some of these we know how to do, the others we don\'t.  For the ones we know, what is the answer?  For the others, what (in loose terms) do we need to be able to do to come up with an answer?  \n* What is the overall average rating?\n* What is the overall distribution of ratings?\n* What is the average rating of each movie?\n* How many ratings does each movie get?  \n```python' metadata={'Header 1': "extract and read csv's", 'Header 2': 'Combining ratings and movies'}page_content="combo['rating'].mean()\n```  \n```python" metadata={'Header 1': 'Your code/idea here -- average rating'}page_content="fig, ax = plt.subplots()\nbins = [bin/100 for bin in list(range(25, 550, 50))]\nprint(bins)\ncombo['rating'].plot(kind='hist', ax=ax, bins=bins, color='blue', alpha=0.5)\nax.set_xlim(0,5.5)\nax.set_ylabel('Number')\nax.set_xlabel('Rating')\nplt.show()  \n```  \n```python\nimport plotly.graph_objects as go  \ntrace = go.Histogram(\nx=combo['rating'],\nname='control',\nautobinx=False,\nxbins=dict(\nstart=.5,\nend=5.0,\nsize=0.5\n),\nmarker_color='Blue',\nopacity=0.75\n)  \nlayout = go.Layout(\ntitle='Distribution of ratings',\nxaxis_title='Rating value',\nyaxis_title='Count',\nbargap=0.01,\nbargroupgap=0.1,\n)  \nfig = go.Figure(data=[trace], layout=layout)\nfig.show()\n```  \n```python" metadata={'Header 1': 'Your code/idea here -- distribution of ratings'}page_content="combo[combo['movieId']==31]['rating'].mean()\n```  \n```python\n%%time" metadata={'Header 1': 'average for a specific movie'}page_content="ave_mov = combo['rating'].groupby(combo['movieId']).mean()\nave_mov.reset_index()\n```  \n```python" metadata={'Header 1': 'average for all movies (spoiler we will learn this next time!!)'}page_content="combo[combo['movieId']==31]['rating'].count()\n```  \n```python" metadata={'Header 1': 'number of ratings for a single movie'}page_content="combo['rating'].groupby(combo['movieId']).count().reset_index()\n```" metadata={'Header 1': 'number of ratings for all movies (another spoiler!)'}page_content='The [Pandas docs](http://pandas.pydata.org/pandas-docs/stable/merging.html) are ok, but we prefer the Data Carpentry [guide](http://www.datacarpentry.org/python-ecology-lesson/04-merging-data)  \n```python  \n```' metadata={'Header 1': 'number of ratings for all movies (another spoiler!)', 'Header 2': 'Resources'}