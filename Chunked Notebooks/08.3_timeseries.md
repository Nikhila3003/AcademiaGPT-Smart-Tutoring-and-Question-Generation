page_content='**Prerequisites**  \n- Python functions\n- GroupBy  \n**Outcomes**  \n- Know how pandas handles dates\n- Understand how to parse strings into `datetime` objects\n- Know how to write dates as custom formatted strings\n- Be able to access day, month, year, etc. for a `DateTimeIndex` and\na column with `dtype` `datetime`\n- Understand both rolling and re-sampling operations and the difference\nbetween the two  \n**Data**  \n- Bitcoin to USD exchange rates from March 2014 to the present' metadata={'Header 1': 'Temporal Data'}page_content='- [Time series](#Time-series)\n- [Intro](#Intro)\n- [Parsing Strings as Dates](#Parsing-Strings-as-Dates)\n- [Date Formatting](#Date-Formatting)\n- [Extracting Data](#Extracting-Data)\n- [Accessing Date Properties](#Accessing-Date-Properties)\n- [Leads and Lags: `df.shift`](#Leads-and-Lags:-`df.shift`)\n- [Rolling Computations: `.rolling`](#Rolling-Computations:-`.rolling`)\n- [Changing Frequencies: `.resample`](#Changing-Frequencies:-`.resample`)\n- [Optional: API keys](#Optional:-API-keys)\n- [Exercises](#Exercises)  \n```python' metadata={'Header 1': 'Temporal Data', 'Header 2': 'Outline'}page_content='```  \n```python\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport quandl' metadata={'Header 1': '%pip install quandl'}page_content='quandl.ApiConfig.api_key = os.environ.get("QUANDL_AUTH", "Dn6BtVoBhzuKTuyo6hbp")\nstart_date = "2014-05-01"  \n%matplotlib inline' metadata={'Header 1': 'see section on API keys at end of lecture!'}page_content='plt.style.use("ggplot")\n```' metadata={'Header 1': 'activate plot theme'}page_content="pandas has extensive support for handling dates and times  \nWe will loosely refer to data with date or time information as time series data  \nToday we'll explore pandas timeseries capabilities  \nAmong these topics are:  \n- Parsing strings as dates\n- Writing `datetime` objects as (inverse operation of previous point)\n- Extracting data from a DataFrame or Series with date information in\nthe index\n- Shifting data through time (taking leads or lags)\n- Re-sampling data to a different frequency and rolling operations  \n**NOTE:** here, even more than with previous topics, we will skip a lot of the\nfunctionality pandas offers, and we urge you to refer to the [official\ndocumentation](https://pandas.pydata.org/pandas-docs/stable/timeseries.html) for\nmore information" metadata={'Header 1': 'activate plot theme', 'Header 2': 'Intro'}page_content='Dates often come to us as strings  \nHopefully, the date strings follow a structured format or pattern  \nOne common pattern is `YYYY-MM-DD`: 4 numbers for the year, 2 for the month, and\n2 for the day with each section separated by a `-`  \nFor example, we write Christmas day 2020 in this format as  \n```python\nchristmas_str = "2020-12-25"\n```  \nTo convert a string into a time-aware object, we use the `pd.to_datetime`\nfunction.  \n```python\nchristmas = pd.to_datetime(christmas_str)\nprint("The type of christmas is", type(christmas))\nchristmas\n```  \nThe `pd.to_datetime` function is pretty smart at guessing the format of the\ndate…  \n```python\nfor date in ["December 25, 2020", "Dec. 25, 2020",\n"Monday, Dec. 25, 2020", "25 Dec. 2020", "25th Dec. 2020"]:\nprint("pandas interprets {} as {}".format(date, pd.to_datetime(date)))\n```  \nHowever, sometimes we will need to give pandas a hint  \nFor example, that same time (midnight on Christmas) would be reported on an\nAmazon transaction report as  \n```python\nchristmas_amzn = "2020-12-25T00:00:00+ 00 :00"\n```  \nIf we try to pass this to `pd.to_datetime`, it will fail  \n```python\npd.to_datetime(christmas_amzn)\n```  \nTo parse a date with this format, we need to specify the `format` argument for\n`pd.to_datetime`  \n```python\nchristmas_amzn\n```  \n```python\namzn_strftime = "%Y-%m-%dT%H:%M:%S+ 00 :00"\npd.to_datetime(christmas_amzn, format=amzn_strftime)\n```  \nCan you guess what `amzn_strftime` represents?  \nLet’s take a closer look at `amzn_strftime` and `christmas_amzn`  \n```python\nprint(amzn_strftime)\nprint(christmas_amzn)\n```  \nNotice that both of the strings have a similar form, but that instead of actual\nnumerical values, `amzn_strftime` has *placeholders*  \nSpecifically, anywhere the `%` shows up is a signal to the `pd.to_datetime`\nfunction that it is where relevant information is stored  \nFor example, the `%Y` is a stand-in for a four digit year, `%m` is for 2 a digit\nmonth, and so on…  \nThe official [Python\ndocumentation](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior)\ncontains a complete list of possible `%`something patterns that are accepted in\nthe `format` argument  \n<a id=\'exercise-0\'></a> **Exercise 1**  \nBy referring to table found at the link above, figure out the correct argument\nto pass as `format` in order to parse the dates in the next three cells below.  \nTest your work by passing your format string to `pd.to_datetime`.  \n```python\nchristmas_str2 = "2020:12:25"\n```  \n```python\ndbacks_win = "M:11 D:4 Y:2001 9:15 PM"\n```  \n```python\namerica_bday = "America was born on July 4, 1776"\n```' metadata={'Header 1': 'activate plot theme', 'Header 2': 'Parsing Strings as Dates'}page_content='`pd.to_datetime` can convert a collection (e.g. list, tuple, Series) of date\nstrings to dates in one go  \n```python\npd.to_datetime(["2020-12-25", "2020-12-31"])\n```  \nWe\'ll just do the one example b/c everything for one date applies to a\ncollection of dates' metadata={'Header 1': 'activate plot theme', 'Header 2': 'Parsing Strings as Dates', 'Header 3': 'Multiple Dates'}page_content='Often when working with multiple dates, they will be regularly spaced  \nPandas provides the `date_range` function to help construct sequences of regularly spaced dates  \nThere are two basic forms of calling `pd.date_range`:  \n```python' metadata={'Header 1': 'activate plot theme', 'Header 2': 'Parsing Strings as Dates', 'Header 3': '`pd.date_range`'}page_content='pd.date_range(START, END, freq=FREQUENCY)  \npd.date_range(START, periods=N, freq=FREQUENCY)\n```  \nIn the above examples  \n- `START` and `END` represent anything `pd.to_datetime` can recognize as a date\n- `FREQUENCY` is a frequency string like `"D"` for daily and `"A"` for annual\n- `N` is an integer  \nLet\'s see how it works  \n```python\npd.date_range("2020-03-13", "2024-03-13", freq="A")\n```  \n```python\npd.date_range("2020-04-01", "2020-04-25")  # default freq is "D"\n```  \n```python\npd.date_range("2020-04-01", periods=25, freq="m")  # same as above\n```' metadata={'Header 1': 'first approach'}page_content='The frequency arguments we\'ve been passing are known as "offset aliases" in the pandas documentation  \nThere are  *many* of them  \nHere we include a table (taken from [their documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases))  \n| Alias    | Description                                      |\n| -------- | ------------------------------------------------ |\n| B        | business day frequency                           |\n| C        | custom business day frequency                    |\n| D        | calendar day frequency                           |\n| W        | weekly frequency                                 |\n| M        | month end frequency                              |\n| SM       | semi-month end frequency (15th and end of month) |\n| BM       | business month end frequency                     |\n| CBM      | custom business month end frequency              |\n| MS       | month start frequency                            |\n| SMS      | semi-month start frequency (1st and 15th)        |\n| BMS      | business month start frequency                   |\n| CBMS     | custom business month start frequency            |\n| Q        | quarter end frequency                            |\n| BQ       | business quarter end frequency                   |\n| QS       | quarter start frequency                          |\n| BQS      | business quarter start frequency                 |\n| A, Y     | year end frequency                               |\n| BA, BY   | business year end frequency                      |\n| AS, YS   | year start frequency                             |\n| BAS, BYS | business year start frequency                    |\n| BH       | business hour frequency                          |\n| H        | hourly frequency                                 |\n| T, min   | minutely frequency                               |\n| S        | secondly frequency                               |\n| L, ms    | milliseconds                                     |\n| U, us    | microseconds                                     |\n| N        | nanoseconds                                      |  \nPandas also allows for "anchored offsets"  \nThis are represented as a suffix on the offset alias that ties the date offset to a particular end of a range  \nFor example `A` would return the last day of the year, while `A-MAR` would return the last day of March of each year  \nThe list of anchored offsets is even longer, so we\'ll just provide a [link to the docs](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#anchored-offsets)' metadata={'Header 1': 'first approach', 'Header 3': 'Offset Aliases'}page_content='Often we need to do arithmatic computations with datetime objects themselves  \nFor example, we can subtract one date from another...  \n```python\nnew_year = pd.to_datetime("2020-01-01")\ndiff = christmas - new_year\nprint("diff is type", type(diff))\ndiff\n```  \n`TimeDelta` objects represent the difference between two timestamps  \nThey have various properties like days and seconds  \n```python\ndiff.days\n```  \n```python\ndiff.seconds\n```  \nNotice that `diff.seconds` was `0`  \nThe difference was *exactly* 359 days, so no seconds were needed  \nIf a `Timedelta` is added to a `Timestamp`, the result is a `Timestamp`:  \n```python\nnew_year + diff  # diff = christmas - new_year\n```  \n`Timedelta`s can also do arithmetic with integers:  \n```python\n10*diff\n```  \nThe interpretation of `N*diff` is the duration `diff` repeated `N` times  \nWe often construct `Timedelta` by hand  \n```python\ndiff2 = pd.Timedelta(days=1, hours=4, minutes=3)\ndiff2\n```  \n```python\ndiff2 + christmas\n```  \nA common technique is to construct a variable representing a "standard" Timedelta of interest and then use scalar multiplication and addition to adjust dates  \nFor example  \n```python\noneday = pd.Timedelta(days=1)\nonehour = pd.Timedelta(hours=1)  \noneday + onehour\n```  \n```python\nchristmas + 365*oneday\n```  \n```python\nchristmas + 365*oneday - onehour\n```' metadata={'Header 1': 'first approach', 'Header 2': 'TimeDelta'}page_content='We can use the `%`pattern format to have pandas write `datetime` objects as\nspecially formatted strings using the `strftime` (string format time) method  \nFor example,  \n```python\nchristmas\n```  \n```python\nchristmas.strftime("We love %A %B %d (also written %c)")\n```  \n<a id=\'exercise-1\'></a> **Exercise 2**  \nUse `pd.to_datetime` to express the birthday of one of your friends or family\nmembers as a `datetime` object.  \nThen use the `strftime` method to write a message of the format:  \n```python\nNAME\'s birthday is June 10, 1989 (a Saturday)\n```  \n(where the name and date are replaced by the appropriate values)' metadata={'Header 1': 'first approach', 'Header 2': 'Date Formatting'}page_content="Pandas is aware of when DataFrames or Series have dates on the index  \nIn these cases it uses a special `DateTimeIndex` for the index  \nThe special index comes with many convenient data access features  \nWe will explore these now  \nIt's easiest to understand how they work by example, so we'll load in some real\nworld data:  \n```python" metadata={'Header 1': 'first approach', 'Header 2': 'Extracting Data'}page_content='btc_usd = quandl.get("BCHARTS/BITSTAMPUSD", start_date=start_date)' metadata={'Header 1': 'get data from quandl'}page_content='btc_usd.info()\nbtc_usd.head()\n```  \nHere, we have the Bitcoin (BTC) to US dollar (USD) exchange rate from March 2014\nuntil today.  \nNotice that the type of index is `DateTimeIndex`.  \nThis is the key that enables things like…  \nExtracting all data for the year 2015 by passing `"2015"` to `.loc`.  \n```python\nbtc_usd.loc["2015"]\n```  \nWe can also narrow down to specific months.  \n```python' metadata={'Header 1': 'btc_usd = pd.read_csv("btc_usd.csv", parse_date=["Date"])'}page_content='btc_usd.loc["August 2017"]\n```  \n```python' metadata={'Header 1': "By month's name"}page_content='btc_usd.loc["08/2017"]\n```  \nOr even a day…  \n```python' metadata={'Header 1': "By month's number"}page_content='btc_usd.loc["August 1, 2020"]\n```  \n```python' metadata={'Header 1': 'By date name'}page_content='btc_usd.loc["08-01-2020"]\n```  \n**Question:** What can we pass as the `.loc` argument when we have a\n`DateTimeIndex`?  \n**Answer:** Anything that can be converted to a `datetime` using\n`pd.to_datetime`, *without* having to specify the format argument.  \nWhen we pass date-like objects to `.loc`, pandas returns *all* rows whose date\nin the index "belong" to that date or period  \nWe can also use the range shorthand notation to give a start and end date for\nselection  \n```python\nbtc_usd.loc["April 1, 2015":"April 10, 2015"]\n```  \n<a id=\'exercise-2\'></a> **Exercise 3**  \nFor each item in the list, extract the specified data from `btc_usd`:  \n- July 2017 through August 2017 (inclusive)\n- April 25, 2015 to June 10, 2016\n- October 31, 2017' metadata={'Header 1': 'By date number'}page_content='We can access parts of a date: e.g. the month, minute, second, or hour  \nWhen the date/time information is in the index, we can to `df.index.XX` where\n`XX` is replaced by `year`, `month`, or whatever we would like to access.  \n```python\nbtc_usd.index.year\n```  \n```python\nbtc_usd.index.day\n```  \nWe can also do the same if the date/time information is stored in a column, but\nwe have to use a slightly different syntax.  \n```python\ndf["column_name"].dt.XX\n```  \nLet\'s see it in action:  \n```python\nbtc_date_column = btc_usd.reset_index()\nbtc_date_column.head()\n```  \n```python\nbtc_date_column["Date"].dt.year.head()\n```  \n```python\nbtc_date_column["Date"].dt.month.head()\n```' metadata={'Header 1': 'By date number', 'Header 2': 'Accessing Date Properties'}page_content='When doing time series analysis, we often want to compare data at one date\nagainst data at another date  \npandas can help us with this if we leverage the `shift` method  \nWithout any additional arguments, `shift()` will move all data *forward* one\nperiod, filling the first row with missing data  \n```python' metadata={'Header 1': 'By date number', 'Header 2': 'Leads and Lags: `df.shift`'}page_content='btc_usd.head()\n```  \n```python\nbtc_usd.shift().head()\n```  \nWe can use this to compute the percent change from one day to the next  \n(Quiz: Why does that work? Remember how pandas uses the index to *align* data.)  \n```python\n((btc_usd - btc_usd.shift()) / btc_usd.shift()).head()\n```  \nSetting the first argument to `n` tells pandas to shift the data down `n` rows\n(apply an `n` period lag).  \n```python\nbtc_usd.shift(3).head()\n```  \nA negative value will shift the data *up* or apply a lead.  \n```python\nbtc_usd.shift(-2).head()\n```  \n```python\nbtc_usd.shift(-2).tail()\n```  \n<a id=\'exercise-3\'></a> **Exercise 4**  \nUsing the `shift` function, determine the week with the largest percent change\nin the volume of trades (the `"Volume (BTC)"` column).  \nRepeat the analysis at the bi-weekly and monthly frequencies.  \nHint 1: We have data at a *daily* frequency and one week is `7` days.  \nHint 2: Approximate a month by 30 days.  \n```python' metadata={'Header 1': 'so we can see the result of shift clearly'}page_content='```' metadata={'Header 1': 'your code here'}page_content='pandas has facilities that enable easy computation of *rolling statistics*.  \nThese are best understood by example, so we will dive right in.  \n```python' metadata={'Header 1': 'your code here', 'Header 2': 'Rolling Computations: `.rolling`'}page_content='btc_small = btc_usd.head(6)\nbtc_small\n```  \nBelow, we compute the 2 day moving average (for all columns).  \n```python\nbtc_small\n```  \n```python\nbtc_small.rolling("2d").mean()\n```  \nTo do this operation, pandas starts at each row (date) then looks *backwards*\nthe specified number of periods (here 2 days) and then applies some aggregation\nfunction (`mean`) on all the data in that window.  \nIf pandas cannot look back the full length of the window (e.g. when working on\nthe first row), it fills as much of the window as possible and then does the\noperation. Notice that the value at 2014-05-01 is the same in both DataFrames.  \nBelow, we see a visual depiction of the rolling maximum on a 21 day window for\nthe whole dataset.  \n```python\nfig, ax = plt.subplots(figsize=(14, 8))\nbtc_usd["Open"].plot(ax=ax, linestyle="--", alpha=0.8)\nbtc_usd.rolling("21d").max()["Open"].plot(ax=ax, alpha=0.8, linewidth=3)\nax.legend(["Original", "21 day max"]);\n```  \nWe can also ask pandas to `apply` custom functions, similar to what we saw when\nstudying GroupBy.  \n```python\ndef is_volatile(x):\n"Returns a 1 if the variance is greater than 1, otherwise returns 0"\nif x.var() > 1.0:\nreturn 1.0\nelse:\nreturn 0.0\n```  \n```python\nbtc_small.rolling("2d").apply(is_volatile)\n```  \n**Exercise 5**  \nImagine that you have access to the [TARDIS time\nmachine](https://en.wikipedia.org/wiki/TARDIS) from “Dr. Who”.  \nYou are allowed to use the TARDIS only once, subject to the following\nconditions:  \n- You may travel back to any day in the past.\n- On that day, you may purchase one bitcoin *at market open*.\n- You can then take the time machine 30 days into the future and sell your bitcoin *at market close*.\n- Then you return to the present, pocketing the profits.  \nHow would you pick the day?  \nThink carefully about what you would need to compute to make the optimal choice.\nTry writing it out in the markdown cell below so you have a clear description of\nthe *want* operator that we will apply after the exercise.  \n(Note: **Don’t** look too far below, because in the next non-empty cell we have\nwritten out our answer.)  \nTo make this decision, we want to know …  \n**Your answer here**  \nTo make the optimal decision, we need to know the maximum difference between the\nclose price at the end of the window and the open price at the start of the\nwindow.  \n**Exercise 6**  \nDo the following:  \n1. Write a pandas function that implements your strategy.\n1. Pass it to the `agg` method of `rolling_btc`.\n1. Extract the `"Open"` column from the result.\n1. Find the date associated with the maximum value in that column.  \nHow much money did you make?  \n```python\ndef daily_value(df):' metadata={'Header 1': 'first take only the first 6 rows so we can easily see what is going on'}page_content='pass  \nrolling_btc = btc_usd.rolling("30d")' metadata={'Header 1': 'DELETE `pass` below and replace it with your code'}page_content='```' metadata={'Header 1': 'do steps 2-4 here'}page_content='In addition to computing rolling statistics, we can also change the frequency of\nthe data.  \nFor example, instead of a monthly moving average, suppose that we wanted to\ncompute the average *within* each calendar month.  \nWe will use the `resample` method to do this.  \nBelow are some examples.  \n```python' metadata={'Header 1': 'do steps 2-4 here', 'Header 2': 'Changing Frequencies: `.resample`'}page_content='btc_usd.resample("BQ").mean()\n```  \nNote that unlike with `rolling`, a single number is returned for each column for\neach quarter.  \nThe `resample` method will alter the frequency of the data and the number of\nrows in the result will be different from the number of rows in the input.  \nOn the other hand, with `rolling`, the size and frequency of the result are the\nsame as the input.  \nWe can sample at other frequencies and aggregate with multiple aggregations\nfunction at once.  \n```python' metadata={'Header 1': 'business quarter'}page_content='btc_usd.resample("2BQS").agg(["min", "max"])\n```  \nAs with `groupby` and `rolling`, you can also provide custom functions to\n`.resample(...).agg` and `.resample(...).apply`  \n**Exercise 7**  \nNow suppose you still have access to the TARDIS, but the conditions are slightly\ndifferent.  \nYou may now:  \n- Travel back to the *first day* of any month in the past.\n- On that day, you may purchase one bitcoin *at market open*.\n- You can then travel to any day *in that month* and sell the bitcoin *at market close*.\n- Then return to the present, pocketing the profits.  \nTo which month would you travel? On which day of that month would you return to\nsell the bitcoin?  \nDetermine what you would need to compute to make the optimal choice. Try writing\nit out in the markdown cell below so you have a clear description of the *want*\noperator that we will apply after the exercise.  \n(Note: **Don’t** look too many cells below, because we have written out our\nanswer.)  \nTo make the optimal decision we need …  \n**Your answer here**  \nTo make the optimal decision we need to, for each month, compute the maximum\nvalue of the close price on any day minus the open price on the first day of the\nmonth.  \n**Exercise 8**  \nDo the following:  \n1. Write a pandas function that implements your strategy.\n1. Pass it to the `agg` method of `resampled_btc`.\n1. Extract the `"Open"` column from the result.\n1. Find the date associated with the maximum value in that column.  \nHow much money did you make? Compare with your neighbor.  \nWas this strategy more profitable than the previous one? By how much?  \n```python\ndef monthly_value(df):' metadata={'Header 1': 'multiple functions at 2 start-of-quarter frequency'}page_content='pass  \nresampled_btc = btc_usd.resample("MS")' metadata={'Header 1': 'DELETE `pass` below and replace it with your code'}page_content='```' metadata={'Header 1': 'Do steps 2-4 here'}page_content='Recall above that we had the line of code:  \n```python\nquandl.ApiConfig.api_key = "Dn6BtVoBhzuKTuyo6hbp"\n```  \nThis line told the `quandl` library that when obtaining making requests for\ndata, it should use the *API key* `Dn6BtVoBhzuKTuyo6hbp`.  \nAn API key is a sort of password that web services (like the Quandl API) require\nyou to provide when you make requests.  \nUsing this password, we were able to make a request to Quandl to obtain data\ndirectly from them.  \nThe API key used here is one that we requested on behalf of this course.  \nIf you plan to use Quandl more extensively, you should obtain your own personal\nAPI key from [their\nwebsite](https://docs.quandl.com/docs#section-authentication) and re-run the\n`quandl.ApiConfig.api_key...` line of code with your new API key on the\nright-hand side.' metadata={'Header 1': 'Do steps 2-4 here', 'Header 2': 'Optional: API keys'}