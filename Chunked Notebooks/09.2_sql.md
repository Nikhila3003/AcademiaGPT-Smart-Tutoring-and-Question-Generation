page_content='We will learn how to use SQL today (mostly by example)  \nOur example data comes from the [Instacart dataset](./01_data_description.ipynb) we discussed previously  \n```python\nimport os\nimport pandas as pd\nimport sqlalchemy as sa\nimport zipfile\nimport requests\nfrom io import BytesIO  \nfrom sqlalchemy.ext.declarative import declarative_base\n```' metadata={'Header 1': 'SQL Introduction'}page_content='SQL is a "query language" that can be used to communicate with (relational) databases.  \nSQL itself is more of a standard for a language to communicate with databases rather than an implemented programming language which means that each database creates their own implementation of how SQL commands get translated into queries.  \n**What problem does SQL solve?**  \n1. Straightforward way to ingest data from a database\n2. Industry standard to make database code/requirements (nearly) compatible\n3. The implementations often provide great ways to provide multiple levels of "access" to a dataset\n- Some users will be "data users" and will use the data in their projects -- These users can get away with "read only access" to the database\n- Other users will be "data creators" and will maintain and update the data stored in the database -- These users will need to be able to either add data or participate through other administration roles\n4. Allows administrators to impose strict requirements across the data -- For example, could impose a uniqueness constraint if we did not want an email to correspond to more than one user etc...  \n**Our focus today**  \nOur main focus for this class will be on introducing how to be "database users" rather than "database administrators"' metadata={'Header 1': 'SQL Introduction', 'Header 2': 'SQL (structured query language)'}page_content='We\'ll now discuss a few details of SQL and SQLAlchemy:  \n`sqlalchemy` is a Python package that allows one to generically interface with many different "flavors" of SQL (PostgreSQL, MySQL, SQLite, etc...) using Python code.  \nWe will only discuss it briefly today because it isn\'t the focus of this lecture.' metadata={'Header 1': 'SQL Introduction', 'Header 2': 'SQL and SQLAlchemy'}page_content='As we mentioned, one of the benefits of SQL is that it allows those who are creating the databases to impose tight requirements on what is contained in the data:  \n* **Tables**: SQL allows one to specify a table with pre-defined columns, cross-table restrictions, and more\n* **Types**: Each column in a SQL table must have a specified type. These types are mostly the "usual suspects"\n- Boolean\n- Date\n- Numeric (Float, Integer, ...)\n- String' metadata={'Header 1': 'SQL Introduction', 'Header 2': 'SQL and SQLAlchemy', 'Header 3': 'SQL Tables and Types'}page_content='```python\nBase = declarative_base()  \nclass Aisles(Base):\n__tablename__ = "aisles"\naisle_id = sa.Column(sa.Integer, primary_key=True)\naisle = sa.Column(sa.String)  \nclass Departments(Base):\n__tablename__ = "departments"\ndepartment_id = sa.Column(sa.Integer, primary_key=True)\ndepartment = sa.Column(sa.String)  \nclass Products(Base):\n__tablename__ = "products"\nproduct_id = sa.Column(sa.Integer, primary_key=True)\nproduct_name = sa.Column(sa.String)\naisle_id = sa.Column(sa.Integer)  # One can set these to reference the aisles/departments tables\ndepartment_id = sa.Column(sa.Integer)  \nclass Orders(Base):\n__tablename__ = "orders"\norder_id = sa.Column(sa.Integer, primary_key=True)\nuser_id = sa.Column(sa.Integer)\neval_set = sa.Column(sa.String)\norder_number = sa.Column(sa.Integer)\norder_dow = sa.Column(sa.Integer)\norder_hour_of_day = sa.Column(sa.Integer)\ndays_since_prior_order = sa.Column(sa.Integer)  \nclass ProductsOrdered(Base):\n__tablename__ = "products_ordered"\norder_id = sa.Column(sa.Integer, primary_key=True)\nproduct_id = sa.Column(sa.Integer, primary_key=True)\nadd_to_cart_order = sa.Column(sa.Integer)\nreordered = sa.Column(sa.Boolean)\n```' metadata={'Header 1': 'SQL Introduction', 'Header 2': 'SQL and SQLAlchemy', 'Header 3': 'Declaring table structures'}page_content="We're going to postpone a detailed discussion on what happens next for now...  \nThe tl;dr is that the code cell below is completely commented out. That cell takes the csv files that we previously saw and loads them in to a SQLite database  \nIt isn't a very effiicent operation, so we've done it for you and uploaded the results.  \nThe code cell two beneath this one will check the database already exists, if not it will download it for you.  \n```python" metadata={'Header 1': 'SQL Introduction', 'Header 2': 'SQL and SQLAlchemy', 'Header 3': 'Dump data into database'}page_content='```  \n```python\ndef download_db():\nif os.path.exists("instacart.db"):\nprint("Already have file")\nreturn\nurl = "https://compsosci-resources.s3.amazonaws.com/instacart/instacart.db.zip"\nres = requests.get(url)\nif not res.ok:\nraise Exception("Could not download database")  \nwith zipfile.ZipFile(BytesIO(res.content)) as z:\nz.extract("instacart.db")  \ndownload_db()\n```' metadata={'Header 1': ')'}page_content='In order to access the data in the database, we need a sqlalchemy engine  \nThis is a type provided by sqlalchemy that (1) knows how to interact with a database and (2) abstracts over the type of database so we can use the same Python code to interact with multiple database types.  \n```python' metadata={'Header 1': ')', 'Header 3': 'A SQLAlchemy Engine'}page_content='eng = sa.create_engine("sqlite:///instacart.db")  \nSession = sa.orm.sessionmaker(bind=eng)\n```' metadata={'Header 1': 'Create a SQL alchemy engine and add table information to the engine'}page_content='Unless you end up becoming a data engineer, you will spend most of your time interacting with an already created database that others manage...  \nBecause of this, we will spend most of our time focused on reading data from a database' metadata={'Header 1': 'Create a SQL alchemy engine and add table information to the engine', 'Header 2': 'Reading data from a SQL database'}page_content='We will run the raw SQL commands into the SQLAlchemy engine, but you could interact with the engine using SQLAlchemy  \n**Note**: It is good practice to capitalize the SQL keywords -- For example, rather than write `select` or `from`, you should write `SELECT` and `FROM`  \n```python\ndef run_query(eng, query, str_length=30):\nwith eng.connect() as conn:\nresult = conn.execute(query)\ncols = result.keys()\nvals = result.fetchmany(5)  \nfmter = ("{" + f":<{str_length}" + "}") * len(cols)\nprint(fmter.format(*cols))\nfor _vals in vals:\n_pvals = map(lambda x: str(x)[:str_length], _vals)\nprint(fmter.format(*_pvals))\n```' metadata={'Header 1': 'Create a SQL alchemy engine and add table information to the engine', 'Header 2': 'Reading data from a SQL database', 'Header 3': 'SQL Read Commands'}page_content='The most fundamental read command in SQL combines the `SELECT` statement with the `FROM` statement.  \n* `SELECT` specifies what data to read (and what to call it)\n* `FROM` specifies where that data can be read from  \n**Select all columns from a single table**  \n```python\nquery = """\nSELECT *\nFROM products\n"""  \nrun_query(eng, query)  \n```  \n**Select certain columns**  \n```python\nquery = """\nSELECT product_id, aisle_id, department_id\nFROM products\n"""  \nrun_query(eng, query)  \n```  \n**Select and rename certain columns**  \n```python\nquery = """\nSELECT product_id AS pid, aisle_id AS aid, department_id AS did\nFROM products\n"""  \nrun_query(eng, query)  \n```  \n**Reference table using abbreviation**  \n```python\nquery = """\nSELECT p.product_id AS pid, p.aisle_id, p.department_id\nFROM products p\n"""  \nrun_query(eng, query)  \n```  \n**Select functions of columns**  \n```python\nquery = """\nSELECT product_id AS pid, aisle_id, department_id, aisle_id + department_id AS a_d_id\nFROM products p\n"""  \nrun_query(eng, query)  \n```' metadata={'Header 1': 'Create a SQL alchemy engine and add table information to the engine', 'Header 2': 'Reading data from a SQL database', 'Header 3': 'SQL Read Commands', 'Header 4': 'SELECT/FROM'}page_content='SQL is a relational database which means that  \n1. We will typically store data in multiple tables\n2. We\'d like to be able to combine and manipulate data from multiple tables  \n`JOIN` allows us bring together two (or more) datasets into a single query  \n**Select all columns from two tables**  \n```python\nquery = """\nSELECT *\nFROM products p\nJOIN aisles a ON (p.aisle_id=a.aisle_id)\n"""  \nrun_query(eng, query, 18)  \n```  \n**Select subset of columns from each table**  \n```python\nquery = """\nSELECT p.product_name, p.aisle_id, p.department_id, a.aisle\nFROM products p\nJOIN aisles a ON (p.aisle_id=a.aisle_id)\n"""  \nrun_query(eng, query, 30)  \n```  \n**Select data with different joins**  \nThe merges that we\'ve done using pandas use the same notation as SQL joins:  \n- `LEFT`: Use values from the left table to merge datasets\n- `RIGHT`: Use values from the right table to merge datasets\n- `INNER`: Only keep values contained in both the left and right datasets\n- `OUTER`: Keep all values contained in either the left or right dataset.  \n```python\nquery = """\nSELECT p.product_name, p.aisle_id, p.department_id, a.aisle\nFROM products p\nINNER JOIN aisles a ON (p.aisle_id=a.aisle_id)\n"""' metadata={'Header 1': 'Create a SQL alchemy engine and add table information to the engine', 'Header 2': 'Reading data from a SQL database', 'Header 3': 'SQL Read Commands', 'Header 4': 'JOIN'}page_content='run_query(eng, query, 30)  \n```  \n**Select data with multiple joins**  \nWe don\'t have to restrict ourselves to only combining two datasets -- We can combine as many as we\'d like!  \n```python\nquery = """\nSELECT p.product_name, a.aisle, d.department\nFROM products p\nLEFT JOIN aisles a ON (p.aisle_id=a.aisle_id)\nLEFT JOIN departments d ON (p.department_id=d.department_id)\n"""  \nrun_query(eng, query, 30)  \n```' metadata={'Header 1': 'missing data...'}page_content='We are often interested in working with subsets of the data rather than selecting all of the rows.  \nSQL allows us to specify certain conditions to restrict the set of observations that are returned using the `WHERE` clause.  \n**Retrieve certain groups** (compare  strings)  \n```python\nquery = """\nSELECT p.product_name, a.aisle, d.department\nFROM products p\nLEFT JOIN aisles a ON (p.aisle_id=a.aisle_id)\nLEFT JOIN departments d ON (p.department_id=d.department_id)\nWHERE d.department = \'snacks\'\n"""  \nrun_query(eng, query, 30)  \n```  \n**Retrieve certain groups** (compare numbers)  \n```python\nquery = """\nSELECT p.product_name, a.aisle, d.department, a.aisle_id\nFROM products p\nLEFT JOIN aisles a ON (p.aisle_id=a.aisle_id)\nLEFT JOIN departments d ON (p.department_id=d.department_id)\nWHERE a.aisle_id > 132\n"""  \nrun_query(eng, query, 30)  \n```  \n**Multiple conditions**  \nWe use `AND` and `OR` to specify the boolean condition  \n```python\nquery = """\nSELECT p.product_name, a.aisle, d.department, a.aisle_id, d.department_id\nFROM products p\nLEFT JOIN aisles a ON (p.aisle_id=a.aisle_id)\nLEFT JOIN departments d ON (p.department_id=d.department_id)\nWHERE a.aisle_id > 100 OR d.department_id<10\n"""  \nrun_query(eng, query, 30)  \n```  \n**Retrieve the most recent data** (compare datetime)  \nImagine we had a table that contained quarterly sales  \n| dt | store_id | sales |\n| ---- | ---- | ---- |\n| 2020-03-31 | 1 | 100 |\n| 2020-06-30 | 1 | 200 |\n| 2020-09-30 | 1 | 300 |\n| 2020-12-31 | 1 | 400 |\n| 2020-03-31 | 2 | 1000 |\n| 2020-06-30 | 2 | 2000 |\n| 2020-09-30 | 2 | 3000 |\n| 2020-12-31 | 2 | 4000 |  \nIf we wanted to select only the observations from quarter 1, we could write  \n```sql\nSELECT *\nFROM sales\nWHERE dt<\'2020-04-01\'\n```  \n| dt | store_id | sales |\n| ---- | ---- | ---- |\n| 2020-03-31 | 1 | 100 |\n| 2020-03-31 | 2 | 1000 |  \nIf we wanted to select observations from Q3 and Q4, we could write  \n```sql\nSELECT *\nFROM sales\nWHERE dt>\'2020-06-31\'\n```  \n| dt | store_id | sales |\n| ---- | ---- | ---- |\n| 2020-09-30 | 1 | 300 |\n| 2020-12-31 | 1 | 400 |\n| 2020-09-30 | 2 | 3000 |\n| 2020-12-31 | 2 | 4000 |' metadata={'Header 1': 'missing data...', 'Header 4': 'WHERE'}page_content='The `GROUP BY` argument allows us to aggregate certain groups of values (much like the pandas `groupby` method).  \nWhen you perform a `GROUP BY`, any column that is not an element of the "group" must have a reduction function applied to it  \n**Group by single column**  \n```python\nquery = """\nSELECT order_dow, COUNT(user_id) AS norder\nFROM orders o\nGROUP BY order_dow\n"""  \nrun_query(eng, query, 15)  \n```  \n**Group by multiple columns**  \n```python\nquery = """\nSELECT user_id, order_dow, COUNT(order_id) AS norder\nFROM orders o\nGROUP BY user_id, order_dow\n"""  \nrun_query(eng, query, 15)  \n```  \n**Aggregate multiple columns**  \n```python\nquery = """\nSELECT user_id, order_dow,\nCOUNT(order_id) AS norder,\nAVG(days_since_prior_order) AS avg_days_since_order\nFROM orders o\nGROUP BY user_id, order_dow\n"""  \nrun_query(eng, query, 15)  \n```' metadata={'Header 1': 'missing data...', 'Header 4': 'GROUP BY'}page_content='`ORDER BY` allows us to sort the output of a query  \n**Order by single column**  \n```python\nquery = """\nSELECT order_id, user_id, order_number, days_since_prior_order\nFROM orders o\nORDER BY user_id\n"""  \nrun_query(eng, query, 15)  \n```  \n**Order by multiple columns**  \n```python\nquery = """\nSELECT order_id, user_id, order_number, days_since_prior_order\nFROM orders o\nORDER BY user_id, order_number\n"""  \nrun_query(eng, query, 15)  \n```  \n**Order by ascending/descending**  \nThe keywords for specifying the order of ordering are `ASC` (for ascending) and `DESC` (for descending)  \n```python\nquery = """\nSELECT order_id, user_id, order_number, days_since_prior_order\nFROM orders o\nWHERE days_since_prior_order < 30\nORDER BY days_since_prior_order DESC, user_id ASC\n"""  \nrun_query(eng, query, 15)  \n```' metadata={'Header 1': 'missing data...', 'Header 4': 'ORDER BY'}page_content='`LIMIT` is a SQL clause that specifies the (maximum) number of rows that should be returned.  \nIt performs the same role as the pandas dataframe `head` method -- It allows you to select the $n$ largest/smallest values or simply get a preview of your data  \n**Retrieve first n rows**  \n```python\n%%time  \nquery_l10 = """\nSELECT *\nFROM orders o\nLIMIT 10\n"""  \n_ = eng.execute(query_l10).fetchall()  \n```  \n```python\n%%time  \nquery_all = """\nSELECT *\nFROM orders o\n"""  \n_ = eng.execute(query_all).fetchall()  \n```' metadata={'Header 1': 'missing data...', 'Header 4': 'LIMIT'}page_content='We have directly used SQLAlchemy\'s engine to read in data up until this point, but we can also read from the engine using pandas!  \n```python\nquery = """\nSELECT order_id, user_id, order_number, days_since_prior_order\nFROM orders o\nORDER BY days_since_prior_order DESC, user_id ASC\n"""  \npd.read_sql(query, eng)\n```' metadata={'Header 1': 'missing data...', 'Header 3': 'Reading with pandas'}page_content='`WITH` clauses allow us to define a "temporary table" that can be used in a subsequent query  \n```python\nquery = """\nWITH agg_po AS (\nSELECT po.product_id,\nCOUNT(po.add_to_cart_order) AS norder,\nSUM(po.reordered) AS nreorder\nFROM products_ordered po\nLEFT JOIN orders o ON po.order_id=o.order_id\nWHERE o.days_since_prior_order IS NOT NULL\nGROUP BY po.product_id\n)\nSELECT apo.product_id, apo.norder, apo.nreorder,\n(apo.nreorder*1.0 / apo.norder) AS frac_reorder,\np.product_name, p.aisle_id, p.department_id\nFROM agg_po as apo\nLEFT JOIN products p ON apo.product_id=p.product_id\nWHERE apo.nreorder > 10\nORDER BY frac_reorder DESC\n"""  \ndf = pd.read_sql(query, eng)\n```' metadata={'Header 1': 'missing data...', 'Header 2': 'Redoing our reorder example in SQL using a `WITH` clause'}