{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24895884-5cc6-4db9-b166-b93810068787",
   "metadata": {},
   "source": [
    "### Loading the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d4ffa8-d45f-4929-a6fe-501bbfbc8469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "COLLECTION_NAME = \"documents\"\n",
    "DB_CONNECTION = \"postgresql://postgres:supa-jupyteach@192.168.0.77:54328/postgres\"\n",
    "\n",
    "def get_vectorstore():\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    db = PGVector(embedding_function=embeddings,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        connection_string=DB_CONNECTION,\n",
    "    )\n",
    "    return db\n",
    "\n",
    "db = get_vectorstore()\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de587ee-6b66-4b43-b4ea-2e5afc2f6b9d",
   "metadata": {},
   "source": [
    "### Connecting to the LLM\n",
    "\n",
    "To connect to the LLM we will follow recent (August 2023) reccomendations from the langchain team. \n",
    "\n",
    "For reference you can use this [blog post](https://blog.langchain.dev/conversational-retrieval-agents/) and this [guide](https://python.langchain.com/docs/use_cases/question_answering/conversational_retrieval_agents?ref=blog.langchain.dev)\n",
    "\n",
    "The tools those resources reccommend are imported as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9570b44-b92b-415d-b4a8-108075d62029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3788c110-35ff-4468-ad19-ba8b58256a73",
   "metadata": {},
   "source": [
    "We start with the `create_conversational_retrieval_agent` function. \n",
    "\n",
    "Let's check its docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6290707-3218-4e15-a3a9-b18f2686ef3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mcreate_conversational_retrieval_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mllm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtools\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseTool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mremember_intermediate_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmemory_key\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'chat_history'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msystem_message\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSystemMessage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_token_limit\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgentExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "A convenience method for creating a conversational retrieval agent.\n",
       "\n",
       "Args:\n",
       "    llm: The language model to use, should be ChatOpenAI\n",
       "    tools: A list of tools the agent has access to\n",
       "    remember_intermediate_steps: Whether the agent should remember intermediate\n",
       "        steps or not. Intermediate steps refer to prior action/observation\n",
       "        pairs from previous questions. The benefit of remembering these is if\n",
       "        there is relevant information in there, the agent can use it to answer\n",
       "        follow up questions. The downside is it will take up more tokens.\n",
       "    memory_key: The name of the memory key in the prompt.\n",
       "    system_message: The system message to use. By default, a basic one will\n",
       "        be used.\n",
       "    verbose: Whether or not the final AgentExecutor should be verbose or not,\n",
       "        defaults to False.\n",
       "    max_token_limit: The max number of tokens to keep around in memory.\n",
       "        Defaults to 2000.\n",
       "\n",
       "Returns:\n",
       "    An agent executor initialized appropriately\n",
       "\u001b[0;31mFile:\u001b[0m      ~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/agents/agent_toolkits/conversational_retrieval/openai_functions.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_conversational_retrieval_agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1223a2f-3226-402b-8d96-ed27c51a7193",
   "metadata": {},
   "source": [
    "Note that we need to pass three arguments\n",
    "\n",
    "1. `llm`: an instance of an LLM subclass. We will use `langchain.chat_models.ChatOpenAI`\n",
    "2. `tools`: a list of langchain [tools](https://python.langchain.com/docs/modules/agents/tools/). Tools allow the LLM to access arbitrary external resources like searching the web, running Python code, etc. For us we will use tools to do retrieval and langchain will help us via that `create_retriever_tool` function we imported\n",
    "3. `system_message`: This is where we customize the system prompt/set of instructions for the llm. This is where you will spend most of your time and will need to create many (dozens!) of variations to see what works best.\n",
    "\n",
    "Note that if we didn't pass a custom system prompt, a default one would be added. You can read the contents of the default prompt [here](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/agent_toolkits/conversational_retrieval/openai_functions.py#L17-L24). I'll also include it right here so we can discuss...\n",
    "\n",
    "```python\n",
    "def _get_default_system_message() -> SystemMessage:\n",
    "    return SystemMessage(\n",
    "        content=(\n",
    "            \"Do your best to answer the questions. \"\n",
    "            \"Feel free to use any tools available to look up \"\n",
    "            \"relevant information, only if necessary\"\n",
    "        )\n",
    "    )\n",
    "```\n",
    "\n",
    "Notice that they instruct the llm to answer questions **and** to \"Feel free to use any tools available to look up relevant information, only if necessary\". We should always include that second sentence instructing the LLM to use tools. Otherwise, it won't do any retrieval.\n",
    "\n",
    "Below I will show an example of items 1, 2, and 3. In your work you can keep items 1 and 2 fixed, but will need to customize 3 as we've described. To help this workflow, I will define a function that always creates 1 and 2, but will take 3 as an argument..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eedac8a0-d971-442d-9632-94f07c3fe6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.messages import SystemMessage\n",
    "\n",
    "def create_chain(system_message_text):\n",
    "    # step 1: create llm\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    \n",
    "    # step 2: create retriever tool\n",
    "    tool = create_retriever_tool(\n",
    "        retriever,\n",
    "        \"search_course_content\",\n",
    "        \"Searches and returns documents regarding the contents of the course and notes from the instructor.\",\n",
    "    )\n",
    "    tools = [tool]\n",
    "\n",
    "    # step 3: create system message from the text passed in as an argument\n",
    "    system_message = SystemMessage(content=system_message_text)\n",
    "\n",
    "    # return the chain\n",
    "    return create_conversational_retrieval_agent(\n",
    "        llm=llm, \n",
    "        tools=tools, \n",
    "        verbose=True, \n",
    "        system_message=system_message\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1baad8-34e2-452d-b5ac-c48111ca07d2",
   "metadata": {},
   "source": [
    "Finally, here is an example of a system prompt that I wrote and a few messages showing how to interact with the returned chat model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91f07c79-b857-40ec-a593-6adcc00ea516",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_system_prompt_text = \"\"\"\\\n",
    "You are a helpful, knowledgeable, and smart teaching assistant.\n",
    "\n",
    "You specialize in helping students understand concepts their instructors teach by:\n",
    "\n",
    "1. Explaining concepts in concise, simple, and clear language\n",
    "2. Providing additional examples of the topics being discussed\n",
    "3. Summarizing content from the instructor, which will be provided to you along with the student's question\n",
    "\n",
    "Feel free to use any tools available to look up relevant information, only if necessary\n",
    "\"\"\"\n",
    "\n",
    "example_chat = create_chain(example_system_prompt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe711980-2063-49d1-b7ac-f4c139c09f12",
   "metadata": {},
   "source": [
    "We are now ready to chat with this AI!\n",
    "\n",
    "We do so by calling `example_chat` as a function and passing in a dictionary with a single key called `input` with the student's message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15eb02b8-6884-4556-905e-e99f9c1e4554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Spencer! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Hi, I'm Spencer\",\n",
       " 'chat_history': [HumanMessage(content=\"Hi, I'm Spencer\"),\n",
       "  AIMessage(content='Hello Spencer! How can I assist you today?')],\n",
       " 'output': 'Hello Spencer! How can I assist you today?',\n",
       " 'intermediate_steps': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_chat({\"input\": \"Hi, I'm Spencer\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c02e03-7edc-4043-908f-76088ec98ad9",
   "metadata": {},
   "source": [
    "Notice no retrieval was done! This is good.\n",
    "\n",
    "Now let's ask a question and see retrieval happen\n",
    "\n",
    "Notice that we simply call `example_chat` again. Langchain will keep track of the entire history of the chat for us, so we just call back into this same function.\n",
    "\n",
    "Also notice that I'm storing the result to a variable called `result`. We'll unpack this later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02f3bfc4-254c-4f74-b809-3aa6d771fc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_course_content` with `core reshaping operations for pandas DataFrame`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(page_content=\"Hello, this is Spencer Lion and I'm really excited about our topic today today. We're talking about group-by operations and pandas, which in my opinion is one of the very coolest and most powerful operations we can do. Let's take a stock of our pandas journey thus far. We started out by learning about the core data types and pandas. This includes the series and the data frame. We then learned how we can do operations such as extracting values or subsets of values from our series and data frame objects. We learned about how we can do arithmetic, either on single values or on entire columns or entire data frames, all at once. We then studied how we can organize our data in pandas using the index and the column names. We saw how a careful selection of the index and columns names could help with analysis because pandas will align the data for us using the index and column names. We then took some time to understand how to reshape data, how to maybe transform it from why to long format, as well as how we can compute things like pivot tables and other\", metadata={'source': 'videos/transcripts_tiny/2.5.1 Groupby Operations.srt', 'chunk_number': 0, 'timestamps': '00:00:00 --> 00:01:19'}), Document(page_content=\"Stack is moving our data from wide to long and unstack is going to be moving from long to wide. Okay. So set index, reset index, stack and unstack are going to be the most fundamental reshaping operations. If you know these four or five methods, what you can do is any of the other operations that we discussed today will typically be a combination of these operations. And in fact, some of them are exactly written as combinations of these operations in the pandas code base. One little hint is, we remember stack for unstack using the following nomonic. unstack moves index levels up. Okay. So next we're going to start talking about some additional methods that again are going to be, they could be performed using the methods we've already discussed. Okay. So melt is going to be a method that moves from wide to long form. It's going to move all of the values stored in your data frame to a single column with all other columns being used to contain identifying information. Now this should sound a lot like changing data to tidy data and it is.\", metadata={'source': 'videos/transcripts_tiny/2.3.2 Reshaping data with pandas.srt', 'chunk_number': 14, 'timestamps': '00:18:33 --> 00:20:03'}), Document(page_content=\"Stack is moving our data from wide to long and unstack is going to be moving from long to wide. Okay. So set index, reset index, stack and unstack are going to be the most fundamental reshaping operations. If you know these four or five methods, what you can do is any of the other operations that we discussed today will typically be a combination of these operations. And in fact, some of them are exactly written as combinations of these operations in the pandas code base. One little hint is, we remember stack for unstack using the following nomonic. unstack moves index levels up. Okay. So next we're going to start talking about some additional methods that again are going to be, they could be performed using the methods we've already discussed. Okay. So melt is going to be a method that moves from wide to long form. It's going to move all of the values stored in your data frame to a single column with all other columns being used to contain identifying information. Now this should sound a lot like changing data to tidy data and it is.\", metadata={'source': 'videos/transcripts_tiny/2.3.2 Reshaping data with pandas.srt', 'chunk_number': 14, 'timestamps': '00:18:33 --> 00:20:03'}), Document(page_content=\"it never got finished but hopefully this has been a chance to we think this is a fun example hopefully this was a chance to refresh you on some of the pandas topics that we've covered especially the reshaping because we can't emphasize this enough reshaping and cleaning are things that you'll only learn to do by doing them yourself so hopefully this gives you a playground and some data where you can start trying to do the same so that's everything I have bye bye\", metadata={'source': 'videos/transcripts_tiny/2.4.2 Pandas Review UN Population data (2 of 2).srt', 'chunk_number': 33, 'timestamps': '00:42:17 --> 00:42:46'})]\u001b[0m\u001b[32;1m\u001b[1;3mThe professor mentioned that the four core reshaping operations for a pandas DataFrame are:\n",
      "\n",
      "1. Set Index: This operation sets one or more columns as the index of the DataFrame, allowing for easier data manipulation and analysis based on the index values.\n",
      "\n",
      "2. Reset Index: This operation resets the index of the DataFrame back to the default integer index, removing any previously set index.\n",
      "\n",
      "3. Stack: This operation reshapes the DataFrame from wide to long format by stacking the column labels into a single column, creating a hierarchical index.\n",
      "\n",
      "4. Unstack: This operation reshapes the DataFrame from long to wide format by unstacking the hierarchical index and spreading the values from a single column into multiple columns.\n",
      "\n",
      "These four operations are fundamental for reshaping and organizing data in pandas.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = example_chat({\"input\": \"What did the professor say are the four core reshaping operations for a pandas DataFrame?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "406da9a0-60ed-43f8-be26-54de2788b137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The professor mentioned that the four core reshaping operations for a pandas DataFrame are:\n",
      "\n",
      "1. Set Index: This operation sets one or more columns as the index of the DataFrame, allowing for easier data manipulation and analysis based on the index values.\n",
      "\n",
      "2. Reset Index: This operation resets the index of the DataFrame back to the default integer index, removing any previously set index.\n",
      "\n",
      "3. Stack: This operation reshapes the DataFrame from wide to long format by stacking the column labels into a single column, creating a hierarchical index.\n",
      "\n",
      "4. Unstack: This operation reshapes the DataFrame from long to wide format by unstacking the hierarchical index and spreading the values from a single column into multiple columns.\n",
      "\n",
      "These four operations are fundamental for reshaping and organizing data in pandas.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487ed24-57fa-400a-944d-b88ee380107a",
   "metadata": {},
   "source": [
    "Excellent! This is spot on. And notice that retrieval happened.\n",
    "\n",
    "We can see it in the printout above, but we can also check `result` for more details\n",
    "\n",
    "The retrieval details will be contained in `result[\"intermediate_steps\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f0795b-8dda-4ac6-9905-480444f73794",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result['intermediate_steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "114386b0-e34b-484b-92ae-9af8e0f0a02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['intermediate_steps'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd0c0cc-70b9-4395-bc0d-6bc22a8bcf09",
   "metadata": {},
   "source": [
    "This is a list of all intermediate steps that were done. This is only a 1 element list. Let's check that value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61317955-97b4-47a0-89ac-0dc0f9764986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result['intermediate_steps'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65b1134f-bbc4-42a7-a611-9ec83896b1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['intermediate_steps'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277051f5-6941-412a-87c5-87ad5abfe9b4",
   "metadata": {},
   "source": [
    "A two element tuple... let's unpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27118f02-3b54-4da7-8145-9a2889084d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = result['intermediate_steps'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86c0965e-b9b2-4cf6-9499-ac7f8f735882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.schema.agent.AgentActionMessageLog"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9daa4835-7a8e-44f5-af53-f81298c6f5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547958b6-3279-4f06-b485-9369e909e68b",
   "metadata": {},
   "source": [
    "Ok so the first element of the tuple in `result['intermediate_steps'][0]` is a log (record) of what intermediate step happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d0d2893-1c69-42a5-b7b2-da9a8d605319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentActionMessageLog(tool='search_course_content', tool_input='core reshaping operations for pandas DataFrame', log='\\nInvoking: `search_course_content` with `core reshaping operations for pandas DataFrame`\\n\\n\\n', message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'search_course_content', 'arguments': '{\\n  \"__arg1\": \"core reshaping operations for pandas DataFrame\"\\n}'}})])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095384f-70db-4b96-a32a-79edbf0096d9",
   "metadata": {},
   "source": [
    "We see that this is an intermediate step where the llm used the `search_course_content` tool. Remember above we set up the retriever to look for contents and gave it that name. The log message above shows the details about what was sent to the retriever.\n",
    "\n",
    "Finally, the second element in the `result['intermediate_steps'][0]` tuple has a list of the documents (chunks) that were retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcdf02c1-d268-45ec-865b-85d63fb657f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Hello, this is Spencer Lion and I'm really excited about our topic today today. We're talking about group-by operations and pandas, which in my opinion is one of the very coolest and most powerful operations we can do. Let's take a stock of our pandas journey thus far. We started out by learning about the core data types and pandas. This includes the series and the data frame. We then learned how we can do operations such as extracting values or subsets of values from our series and data frame objects. We learned about how we can do arithmetic, either on single values or on entire columns or entire data frames, all at once. We then studied how we can organize our data in pandas using the index and the column names. We saw how a careful selection of the index and columns names could help with analysis because pandas will align the data for us using the index and column names. We then took some time to understand how to reshape data, how to maybe transform it from why to long format, as well as how we can compute things like pivot tables and other\", metadata={'source': 'videos/transcripts_tiny/2.5.1 Groupby Operations.srt', 'chunk_number': 0, 'timestamps': '00:00:00 --> 00:01:19'}),\n",
       " Document(page_content=\"Stack is moving our data from wide to long and unstack is going to be moving from long to wide. Okay. So set index, reset index, stack and unstack are going to be the most fundamental reshaping operations. If you know these four or five methods, what you can do is any of the other operations that we discussed today will typically be a combination of these operations. And in fact, some of them are exactly written as combinations of these operations in the pandas code base. One little hint is, we remember stack for unstack using the following nomonic. unstack moves index levels up. Okay. So next we're going to start talking about some additional methods that again are going to be, they could be performed using the methods we've already discussed. Okay. So melt is going to be a method that moves from wide to long form. It's going to move all of the values stored in your data frame to a single column with all other columns being used to contain identifying information. Now this should sound a lot like changing data to tidy data and it is.\", metadata={'source': 'videos/transcripts_tiny/2.3.2 Reshaping data with pandas.srt', 'chunk_number': 14, 'timestamps': '00:18:33 --> 00:20:03'}),\n",
       " Document(page_content=\"Stack is moving our data from wide to long and unstack is going to be moving from long to wide. Okay. So set index, reset index, stack and unstack are going to be the most fundamental reshaping operations. If you know these four or five methods, what you can do is any of the other operations that we discussed today will typically be a combination of these operations. And in fact, some of them are exactly written as combinations of these operations in the pandas code base. One little hint is, we remember stack for unstack using the following nomonic. unstack moves index levels up. Okay. So next we're going to start talking about some additional methods that again are going to be, they could be performed using the methods we've already discussed. Okay. So melt is going to be a method that moves from wide to long form. It's going to move all of the values stored in your data frame to a single column with all other columns being used to contain identifying information. Now this should sound a lot like changing data to tidy data and it is.\", metadata={'source': 'videos/transcripts_tiny/2.3.2 Reshaping data with pandas.srt', 'chunk_number': 14, 'timestamps': '00:18:33 --> 00:20:03'}),\n",
       " Document(page_content=\"it never got finished but hopefully this has been a chance to we think this is a fun example hopefully this was a chance to refresh you on some of the pandas topics that we've covered especially the reshaping because we can't emphasize this enough reshaping and cleaning are things that you'll only learn to do by doing them yourself so hopefully this gives you a playground and some data where you can start trying to do the same so that's everything I have bye bye\", metadata={'source': 'videos/transcripts_tiny/2.4.2 Pandas Review UN Population data (2 of 2).srt', 'chunk_number': 33, 'timestamps': '00:42:17 --> 00:42:46'})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f448e-97e3-4b2b-b423-135a9243f334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyteach)",
   "language": "python",
   "name": "jupyteach"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
