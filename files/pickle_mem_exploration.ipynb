{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3f09f2d-cc8e-4369-8098-0128c9fad57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a helpful, knowledgeable, and smart teaching assistant.\n",
    "\n",
    "You are speaking with a student named {user_name}\n",
    "\n",
    "You specialize in helping students understand concepts their instructors teach by:\n",
    "\n",
    "1. Decribe concepts and formulas as if I am explaining to a 6-year old and related to a simple real-world scenario.\n",
    "2. Providing additional examples of the topics being discussed\n",
    "3. Summarizing content from the instructor, which will be provided to you along with the student's question\n",
    "4. Reply back with more guidance with concise responses and give a step by step explainations following\n",
    "the key points that have been covered with more details.\n",
    "5. Add important BULLET POINTS giving a detailed overview with an example code if necessary.\n",
    "6. Explain the concepts to a foriegn student in their native language if needed.\n",
    "7. Create a sophisticated, humor joke about the concepts and formulas.\n",
    "\n",
    "Feel free to use any tools available to look up relevant information, only if necessary\n",
    "\"\"\"\n",
    "\n",
    "def create_chain(\n",
    "    system_message_text,\n",
    "    course_slug,\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo-1106\",\n",
    "    model_kwargs=dict(),\n",
    "    verbose=False,\n",
    "):\n",
    "    # step 1: create llm\n",
    "    retriever = get_vectorstore(course_slug=course_slug).as_retriever()\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=temperature,\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    # step 2: create retriever tool\n",
    "    tool = create_retriever_tool(\n",
    "        retriever,\n",
    "        \"search_course_content\",\n",
    "        \"Searches and returns documents regarding the contents of the course and notes from the instructor.\",\n",
    "    )\n",
    "    tools = [tool]\n",
    "\n",
    "    # step 3: create system message from the text passed in as an argument\n",
    "    system_message = SystemMessage(content=system_message_text)\n",
    "\n",
    "    # return the chain\n",
    "    return create_conversational_retrieval_agent(\n",
    "        llm=llm, tools=tools, verbose=verbose, system_message=system_message\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cddb57-ee34-4c55-852c-3f06dbb5dcaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df0d6591-eed2-45f6-a997-854613632573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "import structlog\n",
    "pickle_dir = pathlib.Path(\"/home/jupyteach-msda/jupyteach-ai/AcademiaGPT Project/pickles\")\n",
    "\n",
    "logger = structlog.get_logger()\n",
    "\n",
    "\n",
    "def save_chat_memory(chat, chat_id):\n",
    "    with open(pickle_dir / f\"{chat_id}.pickle\", \"wb\") as f:\n",
    "        mem = chat.memory.chat_memory\n",
    "        pickle.dump(mem, f)\n",
    "        logger.msg(f\"saved {len(mem.messages)} messages\", chat_id=chat_id)\n",
    "\n",
    "\n",
    "def maybe_load_chat_memory(chat, chat_id):\n",
    "    file_name = pickle_dir / f\"{chat_id}.pickle\"\n",
    "    if file_name.exists():\n",
    "        with open(file_name, \"rb\") as f:\n",
    "            chat.memory.chat_memory = mem = pickle.load(f)\n",
    "            logger.msg(f\"loaded {len(mem.messages)} messages\", chat_id=chat_id)\n",
    "    return chat\n",
    "\n",
    "with open(pickle_dir/\"7.pickle\", \"rb\") as f:\n",
    "    chat_mem = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6f50422-9ffc-42a2-b185-66f9ffd5bd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d252e808-aec8-4753-a8d8-e5d35601d349",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chat \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_chain\u001b[49m(\n\u001b[1;32m      2\u001b[0m     FINAL_SYSTEM_PROMPT\u001b[38;5;241m.\u001b[39mformat(user_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpencer Lyon\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      3\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(),\n\u001b[1;32m      4\u001b[0m     course_slug\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsda-test-course\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_chain' is not defined"
     ]
    }
   ],
   "source": [
    "chat = create_chain(\n",
    "    FINAL_SYSTEM_PROMPT.format(user_name=\"Spencer Lyon\"),\n",
    "    model_kwargs=dict(),\n",
    "    course_slug=\"msda-test-course\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e2420e-b067-4b77-a8ae-0a2c0b588d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c5e7d-9a34-4201-a28c-a93ab31d08a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (langchain)",
   "language": "python",
   "name": "python3_langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
