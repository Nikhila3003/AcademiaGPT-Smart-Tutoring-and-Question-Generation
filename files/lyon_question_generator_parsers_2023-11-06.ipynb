{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "970265df-fe49-4032-9cac-d83a1a469f84",
   "metadata": {},
   "source": [
    "## Question Type examples\n",
    "\n",
    "In this notebook we work with the 4 Jupyteach question types: `SingleSelection`, `MultipleSelection`, `Code`, `FillInBlank`\n",
    "\n",
    "We will import the corresponding Pydantic classes from `question_generator_model.py`\n",
    "\n",
    "We will then create a `langchain.output_parsers.PydanticOutputParser` for each question type and demonstrate how to use each of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48bf10cb-f4c3-452f-94d5-6d532286f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from question_generator_model import (\n",
    "    MultipleSelection, \n",
    "    SingleSelection, \n",
    "    Code, \n",
    "    FillInBlank\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6ac8b4-2371-4d85-9d08-15b7a972af9e",
   "metadata": {},
   "source": [
    "Here is an example of each question type\n",
    "\n",
    "> Note: you should also read the docstrings for more details on how each question type works\n",
    "\n",
    "> Note 2: You don't have to create these class instances yourself... langchain will do this for you when we create a `PydanticOutputParser` for each of the question types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78ce2ee0-7e3b-4803-a59d-c57ca664abdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What are some possible consequences of a learning rate that is too large?\n",
       "\n",
       "- [x] The algorithm never converges\n",
       "- [x] The algorithm becomes unstable\n",
       "- [ ] Learning is stable, but very slow\n"
      ],
      "text/plain": [
       "What are some possible consequences of a learning rate that is too large?\n",
       "\n",
       "- [x] The algorithm never converges\n",
       "- [x] The algorithm becomes unstable\n",
       "- [ ] Learning is stable, but very slow"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_question = MultipleSelection(\n",
    "    question_text=\"What are some possible consequences of a learning rate that is too large?\",\n",
    "    difficulty=2,\n",
    "    choices=[\n",
    "        \"The algorithm never converges\",\n",
    "        \"The algorithm becomes unstable\",\n",
    "        \"Learning is stable, but very slow\"\n",
    "    ],\n",
    "    solution=[0, 1],\n",
    "    topics=[\"optimization\", \"gradient descent\"]\n",
    ")\n",
    "ms_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fcdf9363-f344-41b2-bb22-738015b1fc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What does `.loc` do?\n",
       "\n",
       "Below is an example of how it might be used\n",
       "\n",
       "```python\n",
       "df.loc[1995, \"NorthEast\"]\n",
       "```\n",
       "\n",
       "- [x] The `.loc` method allows a user to select rows/columns by name\n",
       "- [ ] The `.loc` method allows a  user to select rows/columns by their position\n",
       "- [ ] The `.loc` method is for aggregating data\n"
      ],
      "text/plain": [
       "What does `.loc` do?\n",
       "\n",
       "Below is an example of how it might be used\n",
       "\n",
       "```python\n",
       "df.loc[1995, \"NorthEast\"]\n",
       "```\n",
       "\n",
       "- [x] The `.loc` method allows a user to select rows/columns by name\n",
       "- [ ] The `.loc` method allows a  user to select rows/columns by their position\n",
       "- [ ] The `.loc` method is for aggregating data"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_question = SingleSelection(\n",
    "    question_text=\"\"\"What does `.loc` do?\n",
    "\n",
    "Below is an example of how it might be used\n",
    "\n",
    "```python\n",
    "df.loc[1995, \"NorthEast\"]\n",
    "```\"\"\",\n",
    "    difficulty=2,\n",
    "    topics=[\"pandas\", \"loc\", \"indexing\"],\n",
    "    choices=[\n",
    "        \"The `.loc` method allows a user to select rows/columns by name\",\n",
    "        \"The `.loc` method allows a  user to select rows/columns by their position\",\n",
    "        \"The `.loc` method is for aggregating data\"\n",
    "    ],\n",
    "    solution=0\n",
    ")\n",
    "ss_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ee1f585-20ad-4e4e-a0d7-965538940cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Suppose you have already executed the following code:\n",
       "\n",
       "```python\n",
       "import numpy as np\n",
       "\n",
       "A = np.array([[1, 2], [3, 4]])\n",
       "b = np.array([10, 42])\n",
       "```\n",
       "\n",
       "Fill in the blanks below to solve the matrix equation $Ax = b$ for $x$\n",
       "\n",
       "\n",
       "```python\n",
       "from scipy.linalg import ___X\n",
       "\n",
       "x = ___X(A, ___X)\n",
       "```\n",
       "\n",
       "**Solution**\n",
       "\n",
       "[solve, solve, b]\n",
       "```\n",
       "\n",
       "**Rendered Solution**\n",
       "\n",
       "```python\n",
       "from scipy.linalg import solve\n",
       "\n",
       "x = solve(A, b)\n",
       "```\n",
       "\n",
       "**Test Suite**\n",
       "\n",
       "```python\n",
       "import numpy as np\n",
       "\n",
       "A = np.array([[1, 2], [3, 4]])\n",
       "b = np.array([10, 42])\n",
       "\n",
       "\n",
       "from scipy.linalg import solve\n",
       "\n",
       "x = solve(A, b)\n",
       "\n",
       "assert np.allclose(x, [22, -6])\n",
       "```"
      ],
      "text/plain": [
       "Suppose you have already executed the following code:\n",
       "\n",
       "```python\n",
       "import numpy as np\n",
       "\n",
       "A = np.array([[1, 2], [3, 4]])\n",
       "b = np.array([10, 42])\n",
       "```\n",
       "\n",
       "Fill in the blanks below to solve the matrix equation $Ax = b$ for $x$\n",
       "\n",
       "\n",
       "```python\n",
       "from scipy.linalg import ___X\n",
       "\n",
       "x = ___X(A, ___X)\n",
       "```\n",
       "\n",
       "**Solution**\n",
       "\n",
       "[solve, solve, b]\n",
       "```\n",
       "\n",
       "**Rendered Solution**\n",
       "\n",
       "```python\n",
       "from scipy.linalg import solve\n",
       "\n",
       "x = solve(A, b)\n",
       "```\n",
       "\n",
       "**Test Suite**\n",
       "\n",
       "```python\n",
       "import numpy as np\n",
       "\n",
       "A = np.array([[1, 2], [3, 4]])\n",
       "b = np.array([10, 42])\n",
       "\n",
       "\n",
       "from scipy.linalg import solve\n",
       "\n",
       "x = solve(A, b)\n",
       "\n",
       "assert np.allclose(x, [22, -6])\n",
       "```"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib_question = FillInBlank(\n",
    "    question_text='''\\\n",
    "Suppose you have already executed the following code:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([10, 42])\n",
    "```\n",
    "\n",
    "Fill in the blanks below to solve the matrix equation $Ax = b$ for $x$\n",
    "''',\n",
    "    difficulty=2,\n",
    "    topics=[\"linear algebra\", \"regression\", \"numpy\"],\n",
    "    starting_code='''\\\n",
    "from scipy.linalg import ___X\n",
    "\n",
    "x = ___X(A, ___X)''',\n",
    "    solution=[\"solve\", \"solve\", \"b\"],\n",
    "    setup_code='''\\\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([10, 42])\n",
    "''',\n",
    "    test_code=\"assert np.allclose(x, [22, -6])\"\n",
    ")\n",
    "fib_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "956ae60d-3cc3-49aa-9bfb-71b1664505df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "How would you create a `DatetimeIndex` starting on January 1, 2022 and ending on June 1, 2022 with the values taking every hour in between?\n",
       "\n",
       "Save this to a variable called `dates`\n",
       "\n",
       "```python\n",
       "dates = ...\n",
       "```\n",
       "\n",
       "**Solution**\n",
       "\n",
       "```python\n",
       "dates = pd.date_range(\"2022-01-01\", \"2022-06-01\", freq=\"h\")\n",
       "```\n",
       "\n",
       "**Test Suite**\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "dates = pd.date_range(\"2022-01-01\", \"2022-06-01\", freq=\"h\")\n",
       "\n",
       "assert dates.sort_values()[0].strftime(\"%Y-%m-%d\") == \"2022-01-01\"\n",
       "assert dates.sort_values()[-1].strftime(\"%Y-%m-%d\") == \"2022-06-01\"\n",
       "assert dates.shape[0] == 3625\n",
       "```"
      ],
      "text/plain": [
       "How would you create a `DatetimeIndex` starting on January 1, 2022 and ending on June 1, 2022 with the values taking every hour in between?\n",
       "\n",
       "Save this to a variable called `dates`\n",
       "\n",
       "```python\n",
       "dates = ...\n",
       "```\n",
       "\n",
       "**Solution**\n",
       "\n",
       "```python\n",
       "dates = pd.date_range(\"2022-01-01\", \"2022-06-01\", freq=\"h\")\n",
       "```\n",
       "\n",
       "**Test Suite**\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "dates = pd.date_range(\"2022-01-01\", \"2022-06-01\", freq=\"h\")\n",
       "\n",
       "assert dates.sort_values()[0].strftime(\"%Y-%m-%d\") == \"2022-01-01\"\n",
       "assert dates.sort_values()[-1].strftime(\"%Y-%m-%d\") == \"2022-06-01\"\n",
       "assert dates.shape[0] == 3625\n",
       "```"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_question = Code(\n",
    "    question_text='''How would you create a `DatetimeIndex` starting on January 1, 2022 and ending on June 1, 2022 with the values taking every hour in between?\n",
    "\n",
    "Save this to a variable called `dates`''',\n",
    "    difficulty=2,\n",
    "    topics=[\"pandas\", \"dates\"],\n",
    "    starting_code=\"dates = ...\",\n",
    "    setup_code=\"import pandas as pd\",\n",
    "    test_code='''\\\n",
    "assert dates.sort_values()[0].strftime(\"%Y-%m-%d\") == \"2022-01-01\"\n",
    "assert dates.sort_values()[-1].strftime(\"%Y-%m-%d\") == \"2022-06-01\"\n",
    "assert dates.shape[0] == 3625''',\n",
    "    solution='dates = pd.date_range(\"2022-01-01\", \"2022-06-01\", freq=\"h\")'\n",
    ")\n",
    "code_question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab832509-2265-4d67-9c69-0d12babc8dfd",
   "metadata": {},
   "source": [
    "## Create PydanticOutputParser\n",
    "\n",
    "Now we will create a `langchain.output_parsers.PydanticOutputParser` for each question type.\n",
    "\n",
    "These objects have to main purposes:\n",
    "\n",
    "1. They provide a set of format instructions that will be embedded into the system prompt. We can get them via the `.get_format_instructions()` method\n",
    "2. They know how to parse the return value from the LLM into an instance of our Pydantic class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc6eb98-9ca5-4f7c-8847-2a8d170ec29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a66cd151-5329-4b26-8294-2b7ceb90b0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output parsers\n",
    "\n",
    "ms_parser = PydanticOutputParser(pydantic_object=MultipleSelection)\n",
    "code_parser = PydanticOutputParser(pydantic_object=Code)\n",
    "ss_parser = PydanticOutputParser(pydantic_object=SingleSelection)\n",
    "fib_parser = PydanticOutputParser(pydantic_object=FillInBlank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6ff1e-deea-4210-bc93-76fb5f7461cb",
   "metadata": {},
   "source": [
    "Let' see the format instructions for the `ss_parser`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66951832-a573-46a6-949b-870bcf907130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"    Question where user is presented a prompt in `question_text` and \\n    given `starting_code`. They are then supposed to modify the `starting_code`\\n    to complete the question. After doing so the code will be verified by running\\n    the following template as if it were python code:\\n\\n    ```python\\n    {setup_code}\\n\\n    {student_response}\\n\\n    {test_code}\\n    ```\\n\\n    The test code should have `assert` statements that verify the correctness of\\n    the `student_response`\\n\\n    Examples\\n    --------\\n    {\\n      \\\"question_text\\\": \\\"How would you create a `DatetimeIndex` starting on January 1, 2022 and ending on June 1, 2022 with the values taking every hour in between?\\n\\nSave this to a variable called `dates`\\\",\\n      \\\"difficulty\\\": 2,\\n      \\\"topics\\\": [\\\"pandas\\\", \\\"dates\\\"],\\n      \\\"starting_code\\\": \\\"dates = ...\\\",\\n      \\\"solution\\\": \\\"dates = pd.date_range(\\\"2022-01-01\\\", \\\"2022-06-01\\\", freq=\\\"h\\\")\\\",\\n      \\\"setup_code\\\": \\\"import pandas as pd\\\",\\n      \\\"test_code\\\": \\\"assert dates.sort_values()[0].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-01-01\\\"\\nassert dates.sort_values()[-1].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-06-01\\\"\\nassert dates.shape[0] == 3625\\\"\\n    }\\n    \", \"properties\": {\"question_text\": {\"description\": \"The main text of the question. Markdown formatted\", \"title\": \"Question Text\", \"type\": \"string\"}, \"difficulty\": {\"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\", \"title\": \"Difficulty\", \"type\": \"integer\"}, \"topics\": {\"description\": \"A list of one or more topics that the question is testing\", \"items\": {\"type\": \"string\"}, \"title\": \"Topics\", \"type\": \"array\"}, \"starting_code\": {\"description\": \"Starting code that will be the initial contents of the student's text editor. Used to provide scaffold/skeleton code\", \"title\": \"Starting Code\", \"type\": \"string\"}, \"solution\": {\"description\": \"The correct code\", \"title\": \"Solution\", \"type\": \"string\"}, \"setup_code\": {\"description\": \"Any code that needs to execute prior to the student code to ensure any libraries are imported and any variables are set up\", \"title\": \"Setup Code\", \"type\": \"string\"}, \"test_code\": {\"description\": \"Code containing `assert` statements that verifies the correctnessof the student's response\", \"title\": \"Test Code\", \"type\": \"string\"}}, \"required\": [\"question_text\", \"difficulty\", \"topics\", \"starting_code\", \"solution\", \"setup_code\", \"test_code\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(code_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a6578-c35c-4e60-a69f-928f494d1033",
   "metadata": {},
   "source": [
    "## Example for each question type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73c1b696-cb42-4d79-b941-4bc1d556e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_system_prompt = \"\"\"You are a smart, helpful teaching assistant chatbot named Callisto.\n",
    "\n",
    "You assist professors that teach courses about Python, data science, and machine learning\n",
    "to graduate students.\n",
    "\n",
    "You have 5+ years of experience writing Python code to do a variety of tasks. \n",
    "\n",
    "Your responses typically include examples of datasets or code snippets.\n",
    "\n",
    "For each message you will be given two inputs\n",
    "\n",
    "topic: string\n",
    "difficulty: integer\n",
    "\n",
    "Your task is to produce practice questions to help students solidify their understanding of the provided topic\n",
    "\n",
    "The difficulty will be a number between 1 and 3, with 1 corresponding to a request for an easy question, and 3 for the most difficult question.\n",
    "\n",
    "If the user asks you for another question and does not specify either a new topic or a new difficulty, you must use the previous topic or difficulty\n",
    "\n",
    "Your responses must always exactly match the specified format with no extra words or content.\n",
    "\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f60b588a-8fed-4293-8407-ed8c102dd75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv(\"/home/jupyteach-msda/jupyteach-ai/.env\")\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.schema import LLMResult\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "class JupyteachQuestionChain(LLMChain):\n",
    "    \"\"\"\n",
    "    necessary for memory and PydanticOutputParser to work at the same time. \n",
    "    \n",
    "    Notice that we set `ConversationBufferMemory.output_key` to `\"original_text_response\"`\n",
    "    and we use `\"original_text_response\"` as a key in `create_outputs` below.\n",
    "    \"\"\"\n",
    "\n",
    "    def create_outputs(self, llm_result: LLMResult) -> List[Dict[str, Any]]:\n",
    "        out = super().create_outputs(llm_result)\n",
    "        return [\n",
    "            {**d, \"original_text_response\": g[0].text}\n",
    "             for (d, g) in zip(out, llm_result.generations)\n",
    "        ]\n",
    "\n",
    "\n",
    "def build_llm_for_pydantic_model(model_class):\n",
    "    parser = PydanticOutputParser(pydantic_object=model_class)\n",
    "    system = SystemMessagePromptTemplate.from_template(common_system_prompt)\n",
    "    human = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate(\n",
    "        messages = [system, MessagesPlaceholder(variable_name=\"history\"), human],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        # output_parser=parser,\n",
    "    )\n",
    "    \n",
    "    model = ChatOpenAI(temperature=0.4)\n",
    "    \n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"history\", \n",
    "        return_messages=True,\n",
    "        output_key=\"original_text_response\",\n",
    "    )\n",
    "    return JupyteachQuestionChain(\n",
    "        memory=memory,\n",
    "        llm=model,\n",
    "        prompt=prompt,\n",
    "        output_parser=parser,\n",
    "        output_key=\"question\",\n",
    "        return_final_only=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "732a27ac-a80c-43f5-825b-a5d940c87bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"    Question where user is presented a prompt in `question_text` and \\n    a list of `choices`. They are supposed to provide the single best\\n    answer (`solution`) as an integer, which is the index into `choices.\\n\\n    All questions must have a minimum of 2 options\\n\\n    Examples\\n    --------\\n    {\\n      \\\"question_text\\\": \\\"What does `.loc` do?\\n\\nBelow is an example of how it might be used\\n\\n```python\\ndf.loc[1995, \\\"NorthEast\\\"]\\n```\\\",\\n      \\\"difficulty\\\": 2,\\n      \\\"topics\\\": [\\\"pandas\\\", \\\"loc\\\", \\\"indexing\\\"],\\n      \\\"choices\\\": [\\n        \\\"The `.loc` method allows a user to select rows/columns by name\\\",\\n        \\\"The `.loc` method allows a  user to select rows/columns by their position\\\",\\n        \\\"The `.loc` method is for aggregating data\\\"\\n      ],\\n      \\\"solution\\\": 0\\n    }\\n    \", \"properties\": {\"question_text\": {\"description\": \"The main text of the question. Markdown formatted\", \"title\": \"Question Text\", \"type\": \"string\"}, \"difficulty\": {\"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\", \"title\": \"Difficulty\", \"type\": \"integer\"}, \"topics\": {\"description\": \"A list of one or more topics that the question is testing\", \"items\": {\"type\": \"string\"}, \"title\": \"Topics\", \"type\": \"array\"}, \"choices\": {\"description\": \"A list of markdown formatted strings representing the options for the student. Minimum of length 2\", \"items\": {\"type\": \"string\"}, \"title\": \"Choices\", \"type\": \"array\"}, \"solution\": {\"description\": \"Index into choices representing correct answer. Zero based\", \"title\": \"Solution\", \"type\": \"integer\"}}, \"required\": [\"question_text\", \"difficulty\", \"topics\", \"choices\", \"solution\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=SingleSelection)\n",
    "system = SystemMessagePromptTemplate.from_template(common_system_prompt)\n",
    "human = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6079b6bf-75af-493d-8a7e-f0b1367d1c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What is the purpose of the `fit` method in scikit-learn's LinearRegression?\n",
       "\n",
       "- [x] To train the linear regression model on the given training data\n",
       "- [ ] To make predictions using the trained linear regression model\n",
       "- [ ] To evaluate the performance of the linear regression model\n"
      ],
      "text/plain": [
       "What is the purpose of the `fit` method in scikit-learn's LinearRegression?\n",
       "\n",
       "- [x] To train the linear regression model on the given training data\n",
       "- [ ] To make predictions using the trained linear regression model\n",
       "- [ ] To evaluate the performance of the linear regression model"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_chain = build_llm_for_pydantic_model(SingleSelection)\n",
    "q_ss = ss_chain.invoke(input=\"difficulty: 1\\ntopic: scikit-learn LinearRegression\")\n",
    "q_ss[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "166f9a6a-4529-454a-9369-81facfbc1c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What are the main differences between pandas and numpy?\n",
       "\n",
       "- [x] Pandas is primarily used for data manipulation and analysis, while numpy is used for numerical computing and mathematical operations.\n",
       "- [x] Pandas provides a DataFrame object that allows for easy handling of structured data, while numpy provides multi-dimensional arrays for efficient storage and manipulation of homogeneous data.\n",
       "- [x] Pandas has built-in support for handling missing data, while numpy does not.\n",
       "- [ ] Numpy is faster than pandas for numerical computations because it is implemented in C.\n",
       "- [ ] Both pandas and numpy are open-source libraries for Python.\n"
      ],
      "text/plain": [
       "What are the main differences between pandas and numpy?\n",
       "\n",
       "- [x] Pandas is primarily used for data manipulation and analysis, while numpy is used for numerical computing and mathematical operations.\n",
       "- [x] Pandas provides a DataFrame object that allows for easy handling of structured data, while numpy provides multi-dimensional arrays for efficient storage and manipulation of homogeneous data.\n",
       "- [x] Pandas has built-in support for handling missing data, while numpy does not.\n",
       "- [ ] Numpy is faster than pandas for numerical computations because it is implemented in C.\n",
       "- [ ] Both pandas and numpy are open-source libraries for Python."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_chain = build_llm_for_pydantic_model(MultipleSelection)\n",
    "q_ms = ms_chain.invoke(input=\"difficulty: 3\\ntopic: pandas vs numpy\")\n",
    "q_ms[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a74f312-6fb2-46d2-9e15-fc1c130bbde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "How would you reshape the following DataFrame `df` so that the columns become rows and the rows become columns?\n",
       "\n",
       "```\n",
       "   A  B  C\n",
       "0  1  4  7\n",
       "1  2  5  8\n",
       "2  3  6  9\n",
       "```\n",
       "\n",
       "Save the reshaped DataFrame to a variable called `df_reshaped`\n",
       "\n",
       "```python\n",
       "df_reshaped = ...\n",
       "```\n",
       "\n",
       "**Solution**\n",
       "\n",
       "```python\n",
       "df_reshaped = df.T\n",
       "```\n",
       "\n",
       "**Test Suite**\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n",
       "\n",
       "df_reshaped = df.T\n",
       "\n",
       "assert df_reshaped.shape == (3, 3)\n",
       "assert df_reshaped.columns.tolist() == ['A', 'B', 'C']\n",
       "assert df_reshaped.index.tolist() == [0, 1, 2]\n",
       "assert df_reshaped.values.tolist() == [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
       "```"
      ],
      "text/plain": [
       "How would you reshape the following DataFrame `df` so that the columns become rows and the rows become columns?\n",
       "\n",
       "```\n",
       "   A  B  C\n",
       "0  1  4  7\n",
       "1  2  5  8\n",
       "2  3  6  9\n",
       "```\n",
       "\n",
       "Save the reshaped DataFrame to a variable called `df_reshaped`\n",
       "\n",
       "```python\n",
       "df_reshaped = ...\n",
       "```\n",
       "\n",
       "**Solution**\n",
       "\n",
       "```python\n",
       "df_reshaped = df.T\n",
       "```\n",
       "\n",
       "**Test Suite**\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n",
       "\n",
       "df_reshaped = df.T\n",
       "\n",
       "assert df_reshaped.shape == (3, 3)\n",
       "assert df_reshaped.columns.tolist() == ['A', 'B', 'C']\n",
       "assert df_reshaped.index.tolist() == [0, 1, 2]\n",
       "assert df_reshaped.values.tolist() == [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
       "```"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_chain = build_llm_for_pydantic_model(Code)\n",
    "q_code = code_chain.invoke(input=\"difficulty: 2\\ntopic: pandas reshaping\")\n",
    "q_code[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59127fb1-7ba7-4d21-a20f-b9ff1c739a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Write a Python for loop that iterates over a list of numbers and prints the square of each number.\n",
       "\n",
       "```python\n",
       "numbers = [1, 2, 3, 4, 5]\n",
       "\n",
       "for number in numbers:\n",
       "    ___X\n",
       "```\n",
       "\n",
       "**Solution**\n",
       "\n",
       "[print(number ** 2)]\n",
       "```\n",
       "\n",
       "**Rendered Solution**\n",
       "\n",
       "```python\n",
       "numbers = [1, 2, 3, 4, 5]\n",
       "\n",
       "for number in numbers:\n",
       "    print(number ** 2)\n",
       "```\n",
       "\n",
       "**Test Suite**\n",
       "\n",
       "```python\n",
       "\n",
       "\n",
       "numbers = [1, 2, 3, 4, 5]\n",
       "\n",
       "for number in numbers:\n",
       "    print(number ** 2)\n",
       "\n",
       "import io\n",
       "import sys\n",
       "\n",
       "# Redirect stdout to capture printed output\n",
       "stdout = sys.stdout\n",
       "sys.stdout = io.StringIO()\n",
       "\n",
       "numbers = [1, 2, 3, 4, 5]\n",
       "\n",
       "for number in numbers:\n",
       "    print(number ** 2)\n",
       "\n",
       "# Get the printed output\n",
       "output = sys.stdout.getvalue()\n",
       "\n",
       "# Reset stdout\n",
       "sys.stdout = stdout\n",
       "\n",
       "# Check if the output is correct\n",
       "assert output == '1\\n4\\n9\\n16\\n25\\n'\n",
       "```"
      ],
      "text/plain": [
       "Write a Python for loop that iterates over a list of numbers and prints the square of each number.\n",
       "\n",
       "```python\n",
       "numbers = [1, 2, 3, 4, 5]\n",
       "\n",
       "for number in numbers:\n",
       "    ___X\n",
       "```\n",
       "\n",
       "**Solution**\n",
       "\n",
       "[print(number ** 2)]\n",
       "```\n",
       "\n",
       "**Rendered Solution**\n",
       "\n",
       "```python\n",
       "numbers = [1, 2, 3, 4, 5]\n",
       "\n",
       "for number in numbers:\n",
       "    print(number ** 2)\n",
       "```\n",
       "\n",
       "**Test Suite**\n",
       "\n",
       "```python\n",
       "\n",
       "\n",
       "numbers = [1, 2, 3, 4, 5]\n",
       "\n",
       "for number in numbers:\n",
       "    print(number ** 2)\n",
       "\n",
       "import io\n",
       "import sys\n",
       "\n",
       "# Redirect stdout to capture printed output\n",
       "stdout = sys.stdout\n",
       "sys.stdout = io.StringIO()\n",
       "\n",
       "numbers = [1, 2, 3, 4, 5]\n",
       "\n",
       "for number in numbers:\n",
       "    print(number ** 2)\n",
       "\n",
       "# Get the printed output\n",
       "output = sys.stdout.getvalue()\n",
       "\n",
       "# Reset stdout\n",
       "sys.stdout = stdout\n",
       "\n",
       "# Check if the output is correct\n",
       "assert output == '1\\n4\\n9\\n16\\n25\\n'\n",
       "```"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib_chain = build_llm_for_pydantic_model(FillInBlank)\n",
    "q_fib = fib_chain.invoke(input=\"difficulty: 3\\ntopic: python for loops\")\n",
    "q_fib[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58740361-7616-47ea-9cf0-45cfb4021fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6897230e-f9ad-4892-ad00-7a0f924d39c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What is the purpose of a for loop in Python?\n",
       "\n",
       "- [ ] To repeat a block of code a specific number of times\n",
       "- [x] To iterate over a sequence of elements\n",
       "- [ ] To define a function\n"
      ],
      "text/plain": [
       "What is the purpose of a for loop in Python?\n",
       "\n",
       "- [ ] To repeat a block of code a specific number of times\n",
       "- [x] To iterate over a sequence of elements\n",
       "- [ ] To define a function"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib_chain = build_llm_for_pydantic_model(SingleSelection)\n",
    "q_fib = fib_chain.invoke(input=\"difficulty: 1 \\n topic: python for loops\")\n",
    "q_fib[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38c3afde-d859-4302-93a6-6c9808c5e62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What is the purpose of the `groupby` function in pandas?\n",
       "\n",
       "- [x] To split a DataFrame into groups based on specified criteria\n",
       "- [ ] To combine multiple DataFrames into a single DataFrame\n",
       "- [ ] To sort a DataFrame in ascending order\n"
      ],
      "text/plain": [
       "What is the purpose of the `groupby` function in pandas?\n",
       "\n",
       "- [x] To split a DataFrame into groups based on specified criteria\n",
       "- [ ] To combine multiple DataFrames into a single DataFrame\n",
       "- [ ] To sort a DataFrame in ascending order"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib_chain = build_llm_for_pydantic_model(SingleSelection)\n",
    "q_fib = fib_chain.invoke(input=\"difficuty: 3 \\n topic: groupby\")\n",
    "q_fib[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a4e70d-9a70-41bb-bdc4-3ea5cd51047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Prompt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13e248a9-9cc4-4f30-83b8-fba2512920f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What is the meaning of life?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"What is the best programming language?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97e69397-b44b-491b-91d8-04e97657b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv(\"/home/jupyteach-msda/jupyteach-ai/.env\")\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.schema import LLMResult\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "class JupyteachQuestionChain(LLMChain):\n",
    "    \"\"\"\n",
    "    necessary for memory and PydanticOutputParser to work at the same time. \n",
    "    \n",
    "    Notice that we set `ConversationBufferMemory.output_key` to `\"original_text_response\"`\n",
    "    and we use `\"original_text_response\"` as a key in `create_outputs` below.\n",
    "    \"\"\"\n",
    "\n",
    "    def create_outputs(self, llm_result: LLMResult) -> List[Dict[str, Any]]:\n",
    "        out = super().create_outputs(llm_result)\n",
    "        return [\n",
    "            {**d, \"original_text_response\": g[0].text}\n",
    "             for (d, g) in zip(out, llm_result.generations)\n",
    "        ]\n",
    "\n",
    "\n",
    "def build_llm_for_pydantic_model(model_class):\n",
    "    parser = PydanticOutputParser(pydantic_object=model_class)\n",
    "    system = SystemMessagePromptTemplate.from_template(prompt1)\n",
    "    human = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate(\n",
    "        messages = [system, MessagesPlaceholder(variable_name=\"history\"), human],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        # output_parser=parser,\n",
    "    )\n",
    "    \n",
    "    model = ChatOpenAI(temperature=1)\n",
    "    \n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"history\", \n",
    "        return_messages=True,\n",
    "        output_key=\"original_text_response\",\n",
    "    )\n",
    "    return JupyteachQuestionChain(\n",
    "        memory=memory,\n",
    "        llm=model,\n",
    "        prompt=prompt,\n",
    "        output_parser=parser,\n",
    "        output_key=\"questions\",\n",
    "        return_final_only=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14288dd2-38b9-4e90-8df1-9143ef836a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1= \"\"\" For each message you will be given 3 inputs\n",
    "\n",
    "number of questions to generator: integer\n",
    "topic: string\n",
    "difficulty: integer \n",
    "\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cbf62495-39b8-480f-b87c-f4e0f042619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"    Question where user is presented a prompt in `question_text` and \\n    a list of `choices`. They are supposed to provide the single best\\n    answer (`solution`) as an integer, which is the index into `choices.\\n\\n    All questions must have a minimum of 3 options\\n\\n    Examples\\n    --------\\n    {\\n      \\\"question_text\\\": \\\"What does `.loc` do?\\n\\nBelow is an example of how it might be used\\n\\n```python\\ndf.loc[1995, \\\"NorthEast\\\"]\\n```\\\",\\n      \\\"difficulty\\\": 2,\\n      \\\"topics\\\": [\\\"pandas\\\", \\\"loc\\\", \\\"indexing\\\"],\\n      \\\"choices\\\": [\\n        \\\"The `.loc` method allows a user to select rows/columns by name\\\",\\n        \\\"The `.loc` method allows a  user to select rows/columns by their position\\\",\\n        \\\"The `.loc` method is for aggregating data\\\"\\n      ],\\n      \\\"solution\\\": 0\\n    }\\n    \", \"properties\": {\"question_text\": {\"description\": \"The main text of the question. Markdown formatted\", \"title\": \"Question Text\", \"type\": \"string\"}, \"difficulty\": {\"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\", \"title\": \"Difficulty\", \"type\": \"integer\"}, \"topics\": {\"description\": \"A list of one or more topics that the question is testing\", \"items\": {\"type\": \"string\"}, \"title\": \"Topics\", \"type\": \"array\"}, \"choices\": {\"description\": \"A list of markdown formatted strings representing the options for the student. Minimum of length 3\", \"items\": {\"type\": \"string\"}, \"title\": \"Choices\", \"type\": \"array\"}, \"solution\": {\"description\": \"Index into choices representing correct answer. Zero based\", \"title\": \"Solution\", \"type\": \"integer\"}}, \"required\": [\"question_text\", \"difficulty\", \"topics\", \"choices\", \"solution\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=SingleSelection)\n",
    "system = SystemMessagePromptTemplate.from_template(prompt1)\n",
    "human = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a499b9b3-0cc4-4fc2-9004-04a19700c3f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "5 validation errors for SingleSelection\nquestion_text\n  Field required [type=missing, input_value={'questions': [{'question...erry'], 'solution': 0}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ndifficulty\n  Field required [type=missing, input_value={'questions': [{'question...erry'], 'solution': 0}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ntopics\n  Field required [type=missing, input_value={'questions': [{'question...erry'], 'solution': 0}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nchoices\n  Field required [type=missing, input_value={'questions': [{'question...erry'], 'solution': 0}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nsolution\n  Field required [type=missing, input_value={'questions': [{'question...erry'], 'solution': 0}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m fib_chain \u001b[38;5;241m=\u001b[39m build_llm_for_pydantic_model(SingleSelection)\n\u001b[0;32m----> 2\u001b[0m q_fib \u001b[38;5;241m=\u001b[39m \u001b[43mfib_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumber of questions generated: 3 \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdifficulty: 2 \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mtopic: python for loops\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m q_fib[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/chains/base.py:87\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28minput\u001b[39m: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m     83\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     85\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m     86\u001b[0m     config \u001b[38;5;241m=\u001b[39m config \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/chains/base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    309\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    311\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    312\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    314\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/chains/base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    297\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    298\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    299\u001b[0m     inputs,\n\u001b[1;32m    300\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    301\u001b[0m )\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 304\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    309\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/chains/llm.py:109\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    105\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    106\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    107\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    108\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate([inputs], run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[44], line 28\u001b[0m, in \u001b[0;36mJupyteachQuestionChain.create_outputs\u001b[0;34m(self, llm_result)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_outputs\u001b[39m(\u001b[38;5;28mself\u001b[39m, llm_result: LLMResult) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m---> 28\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     30\u001b[0m         {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_text_response\u001b[39m\u001b[38;5;124m\"\u001b[39m: g[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext}\n\u001b[1;32m     31\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (d, g) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(out, llm_result\u001b[38;5;241m.\u001b[39mgenerations)\n\u001b[1;32m     32\u001b[0m     ]\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/chains/llm.py:263\u001b[0m, in \u001b[0;36mLLMChain.create_outputs\u001b[0;34m(self, llm_result)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_outputs\u001b[39m(\u001b[38;5;28mself\u001b[39m, llm_result: LLMResult) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create outputs from response.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Get the text of the top generated string.\u001b[39;49;00m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_key\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull_generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgeneration\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mllm_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerations\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_final_only:\n\u001b[1;32m    272\u001b[0m         result \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key: r[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]} \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/chains/llm.py:266\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_outputs\u001b[39m(\u001b[38;5;28mself\u001b[39m, llm_result: LLMResult) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create outputs from response.\"\"\"\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     result \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;66;03m# Get the text of the top generated string.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m         {\n\u001b[0;32m--> 266\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    267\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_generation\u001b[39m\u001b[38;5;124m\"\u001b[39m: generation,\n\u001b[1;32m    268\u001b[0m         }\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m generation \u001b[38;5;129;01min\u001b[39;00m llm_result\u001b[38;5;241m.\u001b[39mgenerations\n\u001b[1;32m    270\u001b[0m     ]\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_final_only:\n\u001b[1;32m    272\u001b[0m         result \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key: r[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]} \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/schema/output_parser.py:226\u001b[0m, in \u001b[0;36mBaseOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, result: List[Generation], \u001b[38;5;241m*\u001b[39m, partial: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    214\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m    The return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m        Structured output.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:28\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     26\u001b[0m         json_str \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup()\n\u001b[1;32m     27\u001b[0m     json_object \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(json_str, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpydantic_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (json\u001b[38;5;241m.\u001b[39mJSONDecodeError, ValidationError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     31\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/typing_extensions.py:2360\u001b[0m, in \u001b[0;36mdeprecated.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2357\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(arg)\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2359\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, category\u001b[38;5;241m=\u001b[39mcategory, stacklevel\u001b[38;5;241m=\u001b[39mstacklevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 2360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/pydantic/main.py:1010\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;129m@typing_extensions\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated(\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39mPydanticDeprecatedSince20\n\u001b[1;32m   1007\u001b[0m )\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_obj\u001b[39m(\u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[Model], obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Model:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/pydantic/main.py:503\u001b[0m, in \u001b[0;36mBaseModel.model_validate\u001b[0;34m(cls, obj, strict, from_attributes, context)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    502\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 5 validation errors for SingleSelection\nquestion_text\n  Field required [type=missing, input_value={'questions': [{'question...erry'], 'solution': 0}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ndifficulty\n  Field required [type=missing, input_value={'questions': [{'question...erry'], 'solution': 0}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ntopics\n  Field required [type=missing, input_value={'questions': [{'question...erry'], 'solution': 0}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nchoices\n  Field required [type=missing, input_value={'questions': [{'question...erry'], 'solution': 0}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nsolution\n  Field required [type=missing, input_value={'questions': [{'question...erry'], 'solution': 0}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing"
     ]
    }
   ],
   "source": [
    "fib_chain = build_llm_for_pydantic_model(SingleSelection)\n",
    "q_fib = fib_chain.invoke(input=\"number of questions generated: 3 \\ndifficulty: 2 \\ntopic: python for loops\")\n",
    "q_fib[\"questions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18542b9a-c0e9-4e45-ad17-c91ddd527cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyteach)",
   "language": "python",
   "name": "jupyteach"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
