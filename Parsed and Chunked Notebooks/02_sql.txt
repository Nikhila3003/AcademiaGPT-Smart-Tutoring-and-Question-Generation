[[{'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'slide'}}, 'source': '# SQL Introduction\n\nWe will learn how to use SQL today (mostly by example)\n\nOur example data comes from the [Instacart dataset](./01_data_description.ipynb) we discussed previously'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'import os\nimport pandas as pd\nimport sqlalchemy as sa\nimport zipfile\nimport requests\nfrom io import BytesIO\n\nfrom sqlalchemy.ext.declarative import declarative_base'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'slide'}}, 'source': '## SQL (structured query language)\n\nSQL is a "query language" that can be used to communicate with (relational) databases.\n\nSQL itself is more of a standard for a language to communicate with databases rather than an implemented programming language which means that each database creates their own implementation of how SQL commands get translated into queries.'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'subslide'}}, 'source': '**What problem does SQL solve?**\n\n1. Straightforward way to ingest data from a database\n2. Industry standard to make database code/requirements (nearly) compatible\n3. The implementations often provide great ways to provide multiple levels of "access" to a dataset\n  - Some users will be "data users" and will use the data in their projects -- These users can get away with "read only access" to the database\n  - Other users will be "data creators" and will maintain and update the data stored in the database -- These users will need to be able to either add data or participate through other administration roles\n4. Allows administrators to impose strict requirements across the data -- For example, could impose a uniqueness constraint if we did not want an email to correspond to more than one user etc...'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Our focus today**\n\nOur main focus for this class will be on introducing how to be "database users" rather than "database administrators"'}], [{'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'slide'}}, 'source': '## SQL and SQLAlchemy\n\nWe\'ll now discuss a few details of SQL and SQLAlchemy:\n\n`sqlalchemy` is a Python package that allows one to generically interface with many different "flavors" of SQL (PostgreSQL, MySQL, SQLite, etc...) using Python code.\n\nWe will only discuss it briefly today because it isn\'t the focus of this lecture.'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'subslide'}}, 'source': '### SQL Tables and Types\n\nAs we mentioned, one of the benefits of SQL is that it allows those who are creating the databases to impose tight requirements on what is contained in the data:\n\n* **Tables**: SQL allows one to specify a table with pre-defined columns, cross-table restrictions, and more\n* **Types**: Each column in a SQL table must have a specified type. These types are mostly the "usual suspects"\n  - Boolean\n  - Date\n  - Numeric (Float, Integer, ...)\n  - String'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'subslide'}}, 'source': '### Declaring table structures\n'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'Base = declarative_base()\n\n\nclass Aisles(Base):\n    __tablename__ = "aisles"\n    aisle_id = sa.Column(sa.Integer, primary_key=True)\n    aisle = sa.Column(sa.String)\n\n\nclass Departments(Base):\n    __tablename__ = "departments"\n    department_id = sa.Column(sa.Integer, primary_key=True)\n    department = sa.Column(sa.String)\n\n\nclass Products(Base):\n    __tablename__ = "products"\n    product_id = sa.Column(sa.Integer, primary_key=True)\n    product_name = sa.Column(sa.String)\n    aisle_id = sa.Column(sa.Integer)  # One can set these to reference the aisles/departments tables\n    department_id = sa.Column(sa.Integer)\n\n\nclass Orders(Base):\n    __tablename__ = "orders"\n    order_id = sa.Column(sa.Integer, primary_key=True)\n    user_id = sa.Column(sa.Integer)\n    eval_set = sa.Column(sa.String)\n    order_number = sa.Column(sa.Integer)\n    order_dow = sa.Column(sa.Integer)\n    order_hour_of_day = sa.Column(sa.Integer)\n    days_since_prior_order = sa.Column(sa.Integer)\n\n\nclass ProductsOrdered(Base):\n    __tablename__ = "products_ordered"\n    order_id = sa.Column(sa.Integer, primary_key=True)\n    product_id = sa.Column(sa.Integer, primary_key=True)\n    add_to_cart_order = sa.Column(sa.Integer)\n    reordered = sa.Column(sa.Boolean)'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': "### Dump data into database\n\nWe're going to postpone a detailed discussion on what happens next for now...\n\nThe tl;dr is that the code cell below is completely commented out. That cell takes the csv files that we previously saw and loads them in to a SQLite database\n\nIt isn't a very effiicent operation, so we've done it for you and uploaded the results.\n\nThe code cell two beneath this one will check the database already exists, if not it will download it for you."}], [{'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': '# %%time\n# # Uncomment if the data needs to be fixed or updated\n# # Create a SQL alchemy engine and add table information to the engine\n# os.remove("~/Data/instacart/instacart.db")\n# eng = sa.create_engine("sqlite:///instacart.db")\n# Base.metadata.create_all(eng)\n\n# Session = sa.orm.sessionmaker(bind=eng)\n\n# # Create table -> filename pairs\n# table_to_file = [\n#     (Aisles, "~/Data/instacart/aisles.parquet"),\n#     (Departments, "~/Data/instacart/departments.parquet"),\n#     (Products, "~/Data/instacart/products.parquet"),\n#     (Orders, "~/Data/instacart/orders.parquet"),\n#     (ProductsOrdered,  "~/Data/instacart/order_products_all.parquet"),\n# ]\n\n# session = Session()\n# # Delete any data from previous inserts\n# for (_t, _csv) in table_to_file:\n#     session.execute(_t.__table__.delete())\n#     session.commit()\n\n# # Insert data\n# for (_t, _f) in table_to_file:\n#     # Read parquet file and put into the list of dictionaries\n#     _rows = pd.read_parquet(_f).to_sql(\n#         _t.__tablename__, eng, if_exists="append", index=False\n#     )\n'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': 'def download_db():\n    if os.path.exists("instacart.db"):\n        print("Already have file")\n        return\n    url = "https://compsosci-resources.s3.amazonaws.com/instacart/instacart.db.zip"\n    res = requests.get(url)\n    if not res.ok:\n        raise Exception("Could not download database")\n    \n    with zipfile.ZipFile(BytesIO(res.content)) as z:\n        z.extract("instacart.db")\n    \ndownload_db()'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'subslide'}}, 'source': '### A SQLAlchemy Engine\n\nIn order to access the data in the database, we need a sqlalchemy engine\n\nThis is a type provided by sqlalchemy that (1) knows how to interact with a database and (2) abstracts over the type of database so we can use the same Python code to interact with multiple database types.'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': '# Create a SQL alchemy engine and add table information to the engine\neng = sa.create_engine("sqlite:///instacart.db")\n\nSession = sa.orm.sessionmaker(bind=eng)'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'slide'}}, 'source': '## Reading data from a SQL database\n\nUnless you end up becoming a data engineer, you will spend most of your time interacting with an already created database that others manage...\n\nBecause of this, we will spend most of our time focused on reading data from a database'}], [{'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '### SQL Read Commands\n\nWe will run the raw SQL commands into the SQLAlchemy engine, but you could interact with the engine using SQLAlchemy\n\n**Note**: It is good practice to capitalize the SQL keywords -- For example, rather than write `select` or `from`, you should write `SELECT` and `FROM`'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'def run_query(eng, query, str_length=30):\n    with eng.connect() as conn:\n        result = conn.execute(query)\n        cols = result.keys()\n        vals = result.fetchmany(5)\n\n        fmter = ("{" + f":<{str_length}" + "}") * len(cols)\n        print(fmter.format(*cols))\n        for _vals in vals:\n            _pvals = map(lambda x: str(x)[:str_length], _vals)\n            print(fmter.format(*_pvals))'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'subslide'}}, 'source': '#### SELECT/FROM\n\nThe most fundamental read command in SQL combines the `SELECT` statement with the `FROM` statement.\n\n* `SELECT` specifies what data to read (and what to call it)\n* `FROM` specifies where that data can be read from'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Select all columns from a single table**'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT *\n        FROM products\n        """\n\nrun_query(eng, query)\n'}], [{'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Select certain columns**'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT product_id, aisle_id, department_id\n        FROM products\n        """\n\nrun_query(eng, query)\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Select and rename certain columns**'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT product_id AS pid, aisle_id AS aid, department_id AS did\n        FROM products\n        """\n\nrun_query(eng, query)\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Reference table using abbreviation**'}], [{'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT p.product_id AS pid, p.aisle_id, p.department_id\n        FROM products p\n        """\n\nrun_query(eng, query)\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Select functions of columns**'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT product_id AS pid, aisle_id, department_id, aisle_id + department_id AS a_d_id\n        FROM products p\n        """\n\nrun_query(eng, query)\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'subslide'}}, 'source': "#### JOIN\n\nSQL is a relational database which means that\n\n1. We will typically store data in multiple tables\n2. We'd like to be able to combine and manipulate data from multiple tables\n\n`JOIN` allows us bring together two (or more) datasets into a single query"}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Select all columns from two tables**'}], [{'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT *\n        FROM products p\n        JOIN aisles a ON (p.aisle_id=a.aisle_id)\n        """\n\nrun_query(eng, query, 18)\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Select subset of columns from each table**'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT p.product_name, p.aisle_id, p.department_id, a.aisle\n        FROM products p\n        JOIN aisles a ON (p.aisle_id=a.aisle_id)\n        """\n\nrun_query(eng, query, 30)\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': "**Select data with different joins**\n\nThe merges that we've done using pandas use the same notation as SQL joins:\n\n- `LEFT`: Use values from the left table to merge datasets\n- `RIGHT`: Use values from the right table to merge datasets\n- `INNER`: Only keep values contained in both the left and right datasets\n- `OUTER`: Keep all values contained in either the left or right dataset."}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT p.product_name, p.aisle_id, p.department_id, a.aisle\n        FROM products p\n        INNER JOIN aisles a ON (p.aisle_id=a.aisle_id)\n        """\n\n# In this case they\'re all the same because there is no\n# missing data...\nrun_query(eng, query, 30)\n'}], [{'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': "**Select data with multiple joins**\n\nWe don't have to restrict ourselves to only combining two datasets -- We can combine as many as we'd like!"}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT p.product_name, a.aisle, d.department\n        FROM products p\n        LEFT JOIN aisles a ON (p.aisle_id=a.aisle_id)\n        LEFT JOIN departments d ON (p.department_id=d.department_id)\n        """\n\n# In this case they\'re all the same because there is no\n# missing data...\nrun_query(eng, query, 30)\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'subslide'}}, 'source': '#### WHERE\n\nWe are often interested in working with subsets of the data rather than selecting all of the rows.\n\nSQL allows us to specify certain conditions to restrict the set of observations that are returned using the `WHERE` clause.'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Retrieve certain groups** (compare  strings)'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT p.product_name, a.aisle, d.department\n        FROM products p\n        LEFT JOIN aisles a ON (p.aisle_id=a.aisle_id)\n        LEFT JOIN departments d ON (p.department_id=d.department_id)\n        WHERE d.department = \'snacks\'\n        """\n\nrun_query(eng, query, 30)\n'}], [{'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Retrieve certain groups** (compare numbers)'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT p.product_name, a.aisle, d.department, a.aisle_id\n        FROM products p\n        LEFT JOIN aisles a ON (p.aisle_id=a.aisle_id)\n        LEFT JOIN departments d ON (p.department_id=d.department_id)\n        WHERE a.aisle_id > 132\n        """\n\nrun_query(eng, query, 30)\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Multiple conditions**\n\nWe use `AND` and `OR` to specify the boolean condition'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT p.product_name, a.aisle, d.department, a.aisle_id, d.department_id\n        FROM products p\n        LEFT JOIN aisles a ON (p.aisle_id=a.aisle_id)\n        LEFT JOIN departments d ON (p.department_id=d.department_id)\n        WHERE a.aisle_id > 100 OR d.department_id<10\n        """\n\nrun_query(eng, query, 30)\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Retrieve the most recent data** (compare datetime)\n\nImagine we had a table that contained quarterly sales\n\n| dt | store_id | sales |\n| ---- | ---- | ---- |\n| 2020-03-31 | 1 | 100 |\n| 2020-06-30 | 1 | 200 |\n| 2020-09-30 | 1 | 300 |\n| 2020-12-31 | 1 | 400 |\n| 2020-03-31 | 2 | 1000 |\n| 2020-06-30 | 2 | 2000 |\n| 2020-09-30 | 2 | 3000 |\n| 2020-12-31 | 2 | 4000 |'}], [{'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': '-'}}, 'source': "If we wanted to select only the observations from quarter 1, we could write\n\n```sql\nSELECT *\nFROM sales\nWHERE dt<'2020-04-01'\n```\n\n| dt | store_id | sales |\n| ---- | ---- | ---- |\n| 2020-03-31 | 1 | 100 |\n| 2020-03-31 | 2 | 1000 |"}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': '-'}}, 'source': "If we wanted to select observations from Q3 and Q4, we could write\n\n```sql\nSELECT *\nFROM sales\nWHERE dt>'2020-06-31'\n```\n\n| dt | store_id | sales |\n| ---- | ---- | ---- |\n| 2020-09-30 | 1 | 300 |\n| 2020-12-31 | 1 | 400 |\n| 2020-09-30 | 2 | 3000 |\n| 2020-12-31 | 2 | 4000 |"}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'subslide'}}, 'source': '#### GROUP BY\n\nThe `GROUP BY` argument allows us to aggregate certain groups of values (much like the pandas `groupby` method).\n\nWhen you perform a `GROUP BY`, any column that is not an element of the "group" must have a reduction function applied to it'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Group by single column**'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT order_dow, COUNT(user_id) AS norder\n        FROM orders o\n        GROUP BY order_dow\n        """\n\nrun_query(eng, query, 15)\n'}], [{'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Group by multiple columns**'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT user_id, order_dow, COUNT(order_id) AS norder\n        FROM orders o\n        GROUP BY user_id, order_dow\n        """\n\nrun_query(eng, query, 15)\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Aggregate multiple columns**'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT user_id, order_dow,\n               COUNT(order_id) AS norder,\n               AVG(days_since_prior_order) AS avg_days_since_order\n        FROM orders o\n        GROUP BY user_id, order_dow\n        """\n\nrun_query(eng, query, 15)\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'subslide'}}, 'source': '#### ORDER BY\n\n`ORDER BY` allows us to sort the output of a query'}], [{'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Order by single column**'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT order_id, user_id, order_number, days_since_prior_order\n        FROM orders o\n        ORDER BY user_id\n        """\n\nrun_query(eng, query, 15)\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Order by multiple columns**'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT order_id, user_id, order_number, days_since_prior_order\n        FROM orders o\n        ORDER BY user_id, order_number\n        """\n\nrun_query(eng, query, 15)\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Order by ascending/descending**\n\nThe keywords for specifying the order of ordering are `ASC` (for ascending) and `DESC` (for descending)'}], [{'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT order_id, user_id, order_number, days_since_prior_order\n        FROM orders o\n        WHERE days_since_prior_order < 30\n        ORDER BY days_since_prior_order DESC, user_id ASC\n        """\n\nrun_query(eng, query, 15)\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'subslide'}}, 'source': '#### LIMIT\n\n`LIMIT` is a SQL clause that specifies the (maximum) number of rows that should be returned.\n\nIt performs the same role as the pandas dataframe `head` method -- It allows you to select the $n$ largest/smallest values or simply get a preview of your data\n'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'fragment'}}, 'source': '**Retrieve first n rows**'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': '%%time\n\nquery_l10 = """\n        SELECT *\n        FROM orders o\n        LIMIT 10\n        """\n\n_ = eng.execute(query_l10).fetchall()\n'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': '%%time\n\nquery_all = """\n        SELECT *\n        FROM orders o\n        """\n\n_ = eng.execute(query_all).fetchall()\n'}], [{'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'subslide'}}, 'source': "### Reading with pandas\n\nWe have directly used SQLAlchemy's engine to read in data up until this point, but we can also read from the engine using pandas!"}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n        SELECT order_id, user_id, order_number, days_since_prior_order\n        FROM orders o\n        ORDER BY days_since_prior_order DESC, user_id ASC\n        """\n\npd.read_sql(query, eng)'}, {'cell_type': 'markdown', 'metadata': {'slideshow': {'slide_type': 'slide'}}, 'source': '## Redoing our reorder example in SQL using a `WITH` clause\n\n`WITH` clauses allow us to define a "temporary table" that can be used in a subsequent query'}, {'cell_type': 'code', 'execution_count': None, 'metadata': {'jupyter': {'outputs_hidden': False}, 'slideshow': {'slide_type': '-'}}, 'outputs': [], 'source': 'query = """\n    WITH agg_po AS (\n        SELECT po.product_id,\n               COUNT(po.add_to_cart_order) AS norder,\n               SUM(po.reordered) AS nreorder\n        FROM products_ordered po\n        LEFT JOIN orders o ON po.order_id=o.order_id\n        WHERE o.days_since_prior_order IS NOT NULL\n        GROUP BY po.product_id\n    )\n    SELECT apo.product_id, apo.norder, apo.nreorder,\n           (apo.nreorder*1.0 / apo.norder) AS frac_reorder,\n           p.product_name, p.aisle_id, p.department_id\n    FROM agg_po as apo\n    LEFT JOIN products p ON apo.product_id=p.product_id\n    WHERE apo.nreorder > 10\n    ORDER BY frac_reorder DESC\n"""\n\ndf = pd.read_sql(query, eng)'}]]