{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d108f5-b821-49f0-87be-bfabaa70733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vecs\n",
    "\n",
    "DB_CONNECTION = \"postgresql://postgres:supa-jupyteach@192.168.0.77:54328/postgres\"\n",
    "\n",
    "# create vector store client\n",
    "vx = vecs.create_client(DB_CONNECTION)\n",
    "\n",
    "# create a collection of vectors with 3 dimensions\n",
    "docs = vx.get_or_create_collection(name=\"documents\", dimension=1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf3f4b8-1274-4445-820f-e916fb36df91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vecs.Collection(name=\"documents\", dimension=1536)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db642e-5946-479c-a97d-f73688fb6b37",
   "metadata": {},
   "source": [
    "## with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df8b3da-8ab3-45eb-84f5-dd7907887127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dbd92ec-a4c8-42a5-a81a-4eaf965fb5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d915c1b8-3de1-472e-b08a-28734aa973d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m         d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mold, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_number\u001b[39m\u001b[38;5;124m\"\u001b[39m: i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotebook\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n\u001b[0;32m---> 14\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_chunks_for_notebook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./Parsed Notebooks/01.1_pandas_intro.md\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mcreate_chunks_for_notebook\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_chunks_for_notebook\u001b[39m(path):\n\u001b[0;32m----> 2\u001b[0m     loader \u001b[38;5;241m=\u001b[39m \u001b[43mTextLoader\u001b[49m(path)\n\u001b[1;32m      3\u001b[0m     documents \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m      4\u001b[0m     text_splitter \u001b[38;5;241m=\u001b[39m CharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TextLoader' is not defined"
     ]
    }
   ],
   "source": [
    "## Main Chunk function created by Dr. Lyon\n",
    "def create_chunks_for_notebook(path):\n",
    "    loader = TextLoader(path)\n",
    "    documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # add a chunk number and document type\n",
    "    for i, d in enumerate(docs):\n",
    "        old = d.metadata\n",
    "        d.metadata = {**old, \"chunk_number\": i, \"type\": \"notebook\"}\n",
    "        \n",
    "    return docs\n",
    "\n",
    "docs = create_chunks_for_notebook(\"./Parsed Notebooks/01.1_pandas_intro.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc384040-503a-4b1e-bed3-61ef9512994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2698, which is longer than the specified 1000\n",
      "Created a chunk of size 1143, which is longer than the specified 1000\n",
      "Created a chunk of size 1118, which is longer than the specified 1000\n",
      "Created a chunk of size 2131, which is longer than the specified 1000\n",
      "Created a chunk of size 1168, which is longer than the specified 1000\n",
      "Created a chunk of size 1167, which is longer than the specified 1000\n",
      "Created a chunk of size 1084, which is longer than the specified 1000\n",
      "Created a chunk of size 1855, which is longer than the specified 1000\n",
      "Created a chunk of size 1006, which is longer than the specified 1000\n",
      "Created a chunk of size 1361, which is longer than the specified 1000\n",
      "Created a chunk of size 3073, which is longer than the specified 1000\n",
      "Created a chunk of size 1006, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "## Main Chunk function created by me(Jainam)\n",
    "import os\n",
    "def create_chunks_for_notebook(path):\n",
    "    loader = TextLoader(path)\n",
    "    documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # add a chunk number and document type\n",
    "    for i, d in enumerate(docs):\n",
    "        old = d.metadata\n",
    "        d.metadata = {**old, \"chunk_number\": i, \"type\": \"notebook\"}\n",
    "        \n",
    "    return docs\n",
    "\n",
    "parsed_notebooks_folder = \"./Parsed Notebooks/\"\n",
    "\n",
    "# Listing all markdown files in the folder\n",
    "markdown_files = [f for f in os.listdir(parsed_notebooks_folder) if f.endswith(\".md\")]\n",
    "\n",
    "all_docs = []\n",
    "\n",
    "# Processing each markdown file in the folder\n",
    "for markdown_file in markdown_files:\n",
    "    file_path = os.path.join(parsed_notebooks_folder, markdown_file)\n",
    "    docs = create_chunks_for_notebook(file_path)\n",
    "    all_docs.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337ea6c6-cc09-47d9-afb2-4616ea49ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import embed_documents, get_vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cacfdebb-2612-4163-8ca0-f8077f3d7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_notebook(path):\n",
    "    # step 1: parse notebook to convert .ipynb to .md\n",
    "    # TODO: need to implement this in a function\n",
    "    \n",
    "    # step 2: split markdown into chunks\n",
    "    docs = create_chunks_for_notebook(path)\n",
    "\n",
    "    # step 3: create and store embeddings for chunks\n",
    "    return embed_documents(docs)\n",
    "\n",
    "\n",
    "def process_video(path_to_mp4):\n",
    "    # step 1: generate srt content from mp4 using whisper\n",
    "    # step 2: call `chunk_srt_files` (from srt_chunking_example.ipynb) on the srt_content\n",
    "    # step 3: convert the (start, end, txt) tuples you get back from `chunk_srt_files`\n",
    "    #         into langchain.schema.document.Document with metadata set properly\n",
    "    # step 4: call `embed_documents` to create/store emebddings for the video\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25762a1d-6da4-4209-98d6-311ebd7190c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2698, which is longer than the specified 1000\n",
      "Created a chunk of size 1143, which is longer than the specified 1000\n",
      "Created a chunk of size 1118, which is longer than the specified 1000\n",
      "Created a chunk of size 2131, which is longer than the specified 1000\n",
      "Created a chunk of size 1168, which is longer than the specified 1000\n",
      "Created a chunk of size 1167, which is longer than the specified 1000\n",
      "Created a chunk of size 1084, which is longer than the specified 1000\n",
      "Created a chunk of size 1855, which is longer than the specified 1000\n",
      "Created a chunk of size 1006, which is longer than the specified 1000\n",
      "Created a chunk of size 1361, which is longer than the specified 1000\n",
      "Created a chunk of size 3073, which is longer than the specified 1000\n",
      "Created a chunk of size 1006, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "for fn in glob.glob(\"Parsed Notebooks/*.md\"):\n",
    "    db = process_notebook(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967444d9-c6c7-4c4e-bf1b-ba5d9cc6f0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import embed_documents, get_vectorstore\n",
    "\n",
    "query = \"What is the split strategy?\"\n",
    "\n",
    "# retrieve documents related to query\n",
    "db = get_vectorstore()\n",
    "docs_with_score = db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf05f01-82c9-49ba-a4d6-dee898d939c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content=\"In addition, we'll also be using Matplotlib to show some charts. We'll import the base Python random library and then we'll use QEDS to help us style our charts. We'll run this cell to import the libraries now. Begin by talking about the split apply combined strategy. As you might guess, there are three steps to this strategy. First is the split stage. Here we take our entire data set and based on the values in one or more columns, we will split the data set into different subsets. One subset is similar in the sense that these key columns all have the same value as any other row in the subset. After we've created these split data sets, we then apply some function or logic or operation on each of the subsets. This will work through each set one of the time and it will apply the chosen function to each of them. Finally once we're done applying our operation to each subset of data, pandas will then combine all the data sets or all the outputs for us into a final data frame that we can continue our analysis with.\", metadata={'source': 'videos/transcripts_tiny/2.5.1 Groupby Operations.srt', 'chunk_number': 3, 'timestamps': '00:03:26 --> 00:04:40'}),\n",
       "  0.181599725389496),\n",
       " (Document(page_content=\"We're going to use this example data set to demonstrate the three steps in split apply combine. To begin, we'll start with the split step. In order to ask pandas to split the data for us, we use the group by method of a data frame. You see here that we're calling DF dot group by and we're passing the string A. This instructs pandas to construct groups of our data using the values from the A column. This is the most basic and often most used form of the group by method to split on the values of a single column. We can check the type of this GBA object. And we see here a very long type name but we're just going to refer to this as a group by for short. Once we have a group by object, there are a few things we can do with it. One thing we could do is we could ask to get the subset of data for a particular group. So here we're going to ask to get, we're going to say DBA dot get group and we're going to pass one and then we'll pass two. And notice when we do this, that the data we get in return has all the rows of our original\", metadata={'source': 'videos/transcripts_tiny/2.5.1 Groupby Operations.srt', 'chunk_number': 5, 'timestamps': '00:05:40 --> 00:06:59'}),\n",
       "  0.221849143505091),\n",
       " (Document(page_content=\"why to long format, as well as how we can compute things like pivot tables and other summary forms of the data. Finally, we've learned how to merge two different data sets, different about related data sets on one or more key columns. Today we continue with what in my view is the kind of crowning functionality of pandas. It will help us utilize all the tools we've developed thus far and do some really compelling analysis. And that functionality we'll learn about today is called group bi. Our plan for today and the way the class will unfold is that we will be first understanding the split apply combined strategy for analyzing data. If you haven't heard of this before, don't worry. We're going to be learning a lot about it as we move the lecture today. Well then, learn once we've split the data, we'll learn how we can use some of the built-in pandas routines for computing aggregate values based on subsets or groups of our data. Some of these built-in routines were already familiar with. They are things like the mean, median or variance.\", metadata={'source': 'videos/transcripts_tiny/2.5.1 Groupby Operations.srt', 'chunk_number': 1, 'timestamps': '00:01:14 --> 00:02:22'}),\n",
       "  0.224360916094671),\n",
       " (Document(page_content=\"Yeah, I just think it's pretty tough to tell, in any case, except for the most obvious. So, if you were making the case that Charlie ate too much of the pie, and should pay more than his equal split, split, the pie chart can help you make this point. The bar plot also makes that point. In general, avoid pie charts. When you create line charts, you should try and avoid fitting too much information into a single line plot. We see lots of people do this, and the thing that we think is important that a visualization should have one main message, and you should not dilute or pollute your message with extra information. So, in an example below, we're going to come back and revisit our age dependency ratio, and this is going to be the number of individuals aged 65 plus divided by the number of individuals who are aged 15 to 64. So if you have a high age dependency ratio, the government will have a smaller tax base to collect from, but we'll have higher health and pension expenditures to pay from the old.\", metadata={'source': 'videos/transcripts_tiny/2.7.2 Visualization Rules.srt', 'chunk_number': 38, 'timestamps': '00:48:21 --> 00:49:37'}),\n",
       "  0.228178010691522)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_with_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e12df-543d-4e76-bd8f-a064b632490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "given the follwoing context, answer the question at the end\n",
    "\n",
    "```context\n",
    "{doc1}\n",
    "\n",
    "{doc2}\n",
    "\n",
    "{doc3}\n",
    "\n",
    "{doc4}\n",
    "``` \n",
    "\n",
    "```Question \n",
    "{question}\n",
    "```\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6edfed-3971-4168-9272-831d167970a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main Chunk function created by me(Steph)\n",
    "import os\n",
    "def create_chunks_for_video(path):\n",
    "    loader = TextLoader(path)\n",
    "    documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # add a chunk number and document type\n",
    "    for i, d in enumerate(docs):\n",
    "        old = d.metadata\n",
    "        d.metadata = {**old, \"chunk_number\": i, \"type\": \"notebook\"}\n",
    "        \n",
    "    return docs\n",
    "\n",
    "parsed_notebooks_folder = \"./Parsed Notebooks/\"\n",
    "\n",
    "# Listing all markdown files in the folder\n",
    "markdown_files = [f for f in os.listdir(parsed_notebooks_folder) if f.endswith(\".md\")]\n",
    "\n",
    "all_docs = []\n",
    "\n",
    "# Processing each markdown file in the folder\n",
    "for markdown_file in markdown_files:\n",
    "    file_path = os.path.join(parsed_notebooks_folder, markdown_file)\n",
    "    docs = create_chunks_for_notebook(file_path)\n",
    "    all_docs.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72957205-f6c7-4899-a55c-9e91b337ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def create_chunks_for_video(path):\n",
    "  loader = TextLoader(path)\n",
    "  documents = loader.load()\n",
    "  text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "\n",
    "  # Add a chunk number and document type.\n",
    "  for i, d in enumerate(docs):\n",
    "    old = d.metadata\n",
    "    d.metadata = {**old, \"chunk_number\": i, \"type\": \"video\"}\n",
    "\n",
    "  return docs\n",
    "\n",
    "\n",
    "parsed_video_files_folder = \"./Embedded Videos/\"\n",
    "\n",
    "# Listing all Python files in the folder\n",
    "python_files = [f for f in os.listdir(parsed_video_files_folder) if f.endswith(\".ipynb\")]\n",
    "\n",
    "all_docs = []\n",
    "\n",
    "# Processing each Python file in the folder\n",
    "for python_file in python_files:\n",
    "  file_path = os.path.join(parsed_video_files_folder, python_file)\n",
    "  docs = create_chunks_for_video(file_path)\n",
    "  all_docs.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fac81-6153-4a2d-810f-6e8304d41669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyteach)",
   "language": "python",
   "name": "jupyteach"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
