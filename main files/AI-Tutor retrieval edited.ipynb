{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aba1844-53a8-4f59-acab-57718409a609",
   "metadata": {},
   "source": [
    "## What is missing in this notebook:\n",
    "1. Conversational Retreivals Chain\n",
    "\n",
    "## What have been completed: \n",
    "1. Retreiving AI tutor\n",
    "2. Creating Prompt using `StrOutputParser`\n",
    "3. Creating Prompt using `JsonOutputFunctionsParser`\n",
    "4. Simplifying inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612a1025-8f2c-4c58-aebf-79614dba34fe",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03cb98b9-fdc2-4c7e-8cf0-4474f89ebeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "import langchain\n",
    "import supabase\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8f0a2bc-1558-482d-9978-e5927ff29cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2278060-eb56-4af1-bf55-6da426a8f83c",
   "metadata": {},
   "source": [
    "supabase vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2db26c3d-4c7a-462c-a984-47dffddd249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vecs\n",
    "\n",
    "DB_CONNECTION = \"postgresql://postgres:supa-jupyteach@192.168.0.77:54328/postgres\"\n",
    "\n",
    "# create vector store client\n",
    "vx = vecs.create_client(DB_CONNECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70c121f3-dcfd-4304-abba-d8cf934d6412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 22:56:57,673:INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2023-11-03 22:56:57,857:INFO - Use pytorch device: cpu\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What is your question?  what are dataframes?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 113.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loading sentence embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "\n",
    "user_question = input(\"What is your question? \")\n",
    "\n",
    "# Creating embedding for user's question\n",
    "user_embedding = embedding_model.encode(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01493aa1-d2ae-4acd-94df-aed50589250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94afe6ad-eef9-4d4d-8fdf-c5850f2fc37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorstore():\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    db = PGVector(embedding_function=embeddings,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        connection_string=DB_CONNECTION,\n",
    "    )\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9772896-f17e-44b9-8d41-158a496077cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = get_vectorstore()\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0b9356-566b-43da-a0f9-e8492c51da94",
   "metadata": {},
   "source": [
    "## Similarity Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b83931e5-4061-4a03-b62a-c15f7b091539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content=\"So this will find us the minimum one, and the maximum one could be done just like it. And then unemployment.detite tells us float 64. So if we look at our unemployment series, just notice that the values themselves are float 64, so unemployment.detite is just telling us what kind of values are being stored inside of our series. Great. So now we've talked about what a series is, and we'll now talk about what a data frame is. So a data frame is just going to be how pandas will store multiple columns of data. You could think about data frames as simply just multiple series stacked side by side. You'll notice that we still have an index, and now the index is zero, we'll just call this column zero, one and two. So index zero is associated with the A in columns zero, the A in column one and the A in column two. Index one is associated with the B in column zero, the B in column one and the B in column two. And the index two is associated with the C in column zero, et cetera, et cetera. So on the next slide, we're going to create a data frame that contains the unemployment rate\", metadata={'source': 'videos/transcripts_tiny/2.1.1 pandas intro.srt', 'chunk_number': 7, 'timestamps': '00:09:18 --> 00:10:59'}),\n",
       "  0.157125927716715),\n",
       " (Document(page_content=\"So this will find us the minimum one, and the maximum one could be done just like it. And then unemployment.detite tells us float 64. So if we look at our unemployment series, just notice that the values themselves are float 64, so unemployment.detite is just telling us what kind of values are being stored inside of our series. Great. So now we've talked about what a series is, and we'll now talk about what a data frame is. So a data frame is just going to be how pandas will store multiple columns of data. You could think about data frames as simply just multiple series stacked side by side. You'll notice that we still have an index, and now the index is zero, we'll just call this column zero, one and two. So index zero is associated with the A in columns zero, the A in column one and the A in column two. Index one is associated with the B in column zero, the B in column one and the B in column two. And the index two is associated with the C in column zero, et cetera, et cetera. So on the next slide, we're going to create a data frame that contains the unemployment rate\", metadata={'source': 'videos/transcripts_tiny/2.1.1 pandas intro.srt', 'chunk_number': 7, 'timestamps': '00:09:18 --> 00:10:59'}),\n",
       "  0.157125927716715),\n",
       " (Document(page_content=\"So this will find us the minimum one, and the maximum one could be done just like it. And then unemployment.detite tells us float 64. So if we look at our unemployment series, just notice that the values themselves are float 64, so unemployment.detite is just telling us what kind of values are being stored inside of our series. Great. So now we've talked about what a series is, and we'll now talk about what a data frame is. So a data frame is just going to be how pandas will store multiple columns of data. You could think about data frames as simply just multiple series stacked side by side. You'll notice that we still have an index, and now the index is zero, we'll just call this column zero, one and two. So index zero is associated with the A in columns zero, the A in column one and the A in column two. Index one is associated with the B in column zero, the B in column one and the B in column two. And the index two is associated with the C in column zero, et cetera, et cetera. So on the next slide, we're going to create a data frame that contains the unemployment rate\", metadata={'source': 'videos/transcripts_tiny/2.1.1 pandas intro.srt', 'chunk_number': 7, 'timestamps': '00:09:18 --> 00:10:59'}),\n",
       "  0.157125927716715),\n",
       " (Document(page_content=\"So this will find us the minimum one, and the maximum one could be done just like it. And then unemployment.detite tells us float 64. So if we look at our unemployment series, just notice that the values themselves are float 64, so unemployment.detite is just telling us what kind of values are being stored inside of our series. Great. So now we've talked about what a series is, and we'll now talk about what a data frame is. So a data frame is just going to be how pandas will store multiple columns of data. You could think about data frames as simply just multiple series stacked side by side. You'll notice that we still have an index, and now the index is zero, we'll just call this column zero, one and two. So index zero is associated with the A in columns zero, the A in column one and the A in column two. Index one is associated with the B in column zero, the B in column one and the B in column two. And the index two is associated with the C in column zero, et cetera, et cetera. So on the next slide, we're going to create a data frame that contains the unemployment rate\", metadata={'source': 'videos/transcripts_tiny/2.1.1 pandas intro.srt', 'chunk_number': 7, 'timestamps': '00:09:18 --> 00:10:59'}),\n",
       "  0.157125927716715)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = get_vectorstore()\n",
    "docs_with_score = db.similarity_search_with_score(user_question)\n",
    "docs_with_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be568d6a-de38-42d7-bc71-3bd83aea7e45",
   "metadata": {},
   "source": [
    "## PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad272e58-983c-49db-a834-dbf3a28b6ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_temp = ChatPromptTemplate.from_template(\"tell me more about pandas {topic}\")\n",
    "model = ChatOpenAI()\n",
    "chain_temp = prompt_temp | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8823c3ac-0961-411b-8938-d90ebe5758af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Pandas is not an AI entity. Pandas is actually a popular open-source Python library used for data manipulation and analysis. It provides data structures and functions for efficiently handling and analyzing structured data, primarily in tabular form.\\n\\nPandas is built on top of NumPy, another Python library for numerical computing. It offers powerful tools for data cleaning, preprocessing, merging, reshaping, and aggregating. Pandas also provides easy-to-use data structures like DataFrames, which allow users to organize and manipulate data in a tabular format, similar to spreadsheets or relational databases.\\n\\nOne of the key features of Pandas is its ability to handle missing data. It provides methods to detect, remove, or fill missing values in a dataset. Pandas also supports various data input and output formats, including CSV, Excel, SQL databases, and more.\\n\\nIn addition to data manipulation, Pandas also offers statistical analysis capabilities. It includes functions for computing descriptive statistics, correlation, covariance, and various other summary statistics. Pandas can also be integrated with other libraries like Matplotlib and Seaborn for data visualization.\\n\\nAlthough Pandas is not an AI itself, it is often used as a part of the AI workflow. Data scientists and AI practitioners use Pandas to preprocess and analyze data before feeding it into machine learning algorithms. It helps in tasks like feature engineering, data exploration, and data preprocessing, making it an essential tool for AI development.')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_temp.invoke({\"topic\": \"AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b613b80d-8349-4745-9692-ed84c849e5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Pandas is an open-source data analysis and manipulation library for Python. It provides easy-to-use data structures and data analysis tools to perform various operations on structured data. While pandas itself is not an AI library, it is often used in conjunction with AI and machine learning frameworks to preprocess and analyze data.')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_temp = prompt_temp | model.bind(stop=[\"\\n\"])\n",
    "chain_temp.invoke({\"topic\": \"AI\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4548d9-611a-4496-806c-80a49ae84d15",
   "metadata": {},
   "source": [
    "### Function Call Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7d9fca0-1cc7-409a-aec7-3f725419f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"datascience\",\n",
    "        \"description\": \"pandas\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"setup\": {\"type\": \"string\", \"description\": \"Describe Pandas\"},\n",
    "                \"punchline\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Describe Pandas\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"setup\", \"punchline\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "chain_temp = prompt_temp | model.bind(function_call={\"name\": \"datascience\"}, functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31c9f2a0-f406-4600-8efa-57e8f82a91c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'datascience', 'arguments': '{\\n  \"setup\": \"Pandas is a powerful open-source data manipulation and analysis library for Python.\",\\n  \"punchline\": \"It provides data structures and functions necessary to manipulate and analyze structured data.\"\\n}'}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_temp.invoke({\"topic\": \"AI\"}, config={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3cff78-114f-4594-8cfb-fc05d375ae06",
   "metadata": {},
   "source": [
    "Prompt Using `StrOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c51e8a2-b0eb-4bab-913f-1103fedac96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"what is a pandas {topic}\"\n",
    ")\n",
    "model = ChatOpenAI()\n",
    "output_pars = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10d85a22-fcbe-48f2-b341-68d9324fbae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pandas AI refers to the combination of two technologies: pandas, a popular open-source data manipulation library in Python, and artificial intelligence (AI). \\n\\nPandas is primarily used for data analysis and manipulation tasks, offering data structures and functions to efficiently handle large datasets. It provides tools for cleaning, transforming, and analyzing data, making it a valuable tool for data scientists.\\n\\nOn the other hand, AI involves the development of intelligent machines that can perform tasks that typically require human intelligence. This includes technologies like machine learning, natural language processing, computer vision, and more.\\n\\nWhen pandas is combined with AI techniques, it allows for more advanced data analysis and decision-making capabilities. For example, pandas AI can be used to develop predictive models, automate data processing tasks, perform sentiment analysis on text data, build recommendation systems, and much more.\\n\\nOverall, pandas AI enables the use of AI techniques on pandas data structures and functions, enhancing data analysis and enabling more intelligent decision-making.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | output_pars\n",
    "chain.invoke({\"topic\": \"AI\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1eb9a9-b92d-4295-86cd-042ef6a77d07",
   "metadata": {},
   "source": [
    "#### Output Parser using `jsonOutputFunctionsParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb5cff2a-3497-4280-9ab5-b1fa1514bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "chain_json = (\n",
    "    prompt\n",
    "    | model.bind(function_call={\"name\": \"datascience\"}, functions=functions)\n",
    "    | JsonOutputFunctionsParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db106974-21d2-4563-afdf-cf2f47d11873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Pandas is a powerful open-source data manipulation and analysis library for Python.',\n",
       " 'punchline': 'It provides data structures and functions for efficiently handling and analyzing structured data.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_json.invoke({\"topic\": \"AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb147114-b021-495c-b8a8-ca00fe17d777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pandas is a powerful open-source data manipulation and analysis library for Python.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "chain_json = (\n",
    "    prompt\n",
    "    | model.bind(function_call={\"name\": \"datascience\"}, functions=functions)\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"setup\")\n",
    ")\n",
    "chain_json.invoke({\"topic\": \"AI\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f5c93b-f713-47af-96a0-32863c4dc8a0",
   "metadata": {},
   "source": [
    "## Simplifying input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c5db0ed-d959-4c5d-a8f8-81dc2f64065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableMap, RunnablePassthrough\n",
    "chain_simple = (\n",
    "    {\"topic\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model.bind(function_call={\"name\": \"datascience\"}, functions=functions)\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"setup\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef8f7e0b-da07-49a4-b8fc-71ca04c861e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pandas is a fast, powerful, and flexible open-source data manipulation and analysis library for Python.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_simple.invoke(\"AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc9bad-0d4d-4156-82e2-f31f99ea311a",
   "metadata": {},
   "source": [
    "## Conversational Retrievals Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0febec96-c5d3-4758-b274-42e2795c886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import format_document\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d81f07b-2c62-42f4-b74a-da8b76e111b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db63997-00da-4d53-8ccc-cd4f42a541a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyteach)",
   "language": "python",
   "name": "jupyteach"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
