# Cleaning Data

**Prerequisites**

- [Intro](../p01_pandas_intro/v01_pandas_intro.ipynb)  
- [Boolean selection](../p01_pandas_intro/v02_pandas_basics.ipynb)  
- [Indexing](../p02_organizing_data_with_pandas_1/01_the_index.ipynb)  


**Outcomes**

- Be able to use string methods to clean data that comes as a string  
- Be able to drop missing data  
- Use cleaning methods to prepare and analyze a real dataset  


**Data**

- Item information from about 3,000 Chipotle meals from about 1,800
  Grubhub orders  

```python
import pandas as pd
import numpy as np
```

## Outline

- [Cleaning Data](#Cleaning-Data)  
  - [Cleaning Data](#Cleaning-Data)  
  - [String Methods](#String-Methods)  
  - [Type Conversions](#Type-Conversions)  
  - [Missing Data](#Missing-Data)  
  - [Case Study](#Case-Study)  
  - [Appendix: Performance of `.str` Methods](#Appendix:-Performance-of-`.str`-Methods)  

## Cleaning Data

For many data projects, a [significant proportion of
time](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#74d447456f63)
is spent collecting and cleaning the data — not performing the analysis.

This non-analysis work is often called “data cleaning”.

pandas provides very powerful data cleaning tools, which we
will demonstrate using the following dataset.

```python
df = pd.DataFrame({"numbers": ["#23", "#24", "#18", "#14", "#12", "#10", "#35"],
                   "nums": ["23", "24", "18", "14", np.nan, "XYZ", "35"],
                   "colors": ["green", "red", "yellow", "orange", "purple", "blue", "pink"],
                   "other_column": [0, 1, 0, 2, 1, 0, 2]})
df

```

What would happen if we wanted to try and compute the mean of
`numbers`?

```python
df["numbers"].mean()

```

It throws an error!

Can you figure out why?

Hint: When looking at error messages, start at the very
bottom.

The final error says, `TypeError: Could not convert #23#24... to numeric`.


The problem is that if we look at the `dtypes` of the DataFrame that the elements of the `numbers` column are strings!

We learned how to modify strings in one of the lectures about Python fundamentals. Let's modify one of the strings contained in the `numbers` column as a reminder:

```python
numbers_str = "#35"

numbers_num = int(numbers_str.replace("#", ""))

print(numbers_str)
print(numbers_num)
print(type(numbers_num))
```

## String Methods

Our solution to the previous exercise was to remove the `#` by using
the `replace` string method: `int(numbers_str.replace("#", ""))`.

One way to make this change to every element of a column would be to
loop through all elements of the column and apply the desired string
methods…

```python
%%time

# Iterate over all rows
for row in df.iterrows():

    # `iterrows` method produces a tuple with two elements...
    # The first element is an index and the second is a Series with the data from that row
    index_value, column_values = row

    # Apply string method
    clean_number = int(column_values["numbers"].replace("#", ""))

    # The `at` method is very similar to the `loc` method, but it is specialized
    # for accessing single elements at a time... We wanted to use it here to give
    # the loop the best chance to beat a faster method which we show you next.
    df.at[index_value, "numbers_loop"] = clean_number
```

While this is fast for a small dataset like this, this method slows for larger datasets.

One *significantly* faster (and easier) method is to apply a string
method to an entire column of data.

Most methods that are available to a Python string (we learned a
few of them in the [strings lecture](../python_fundamentals/basics.ipynb)) are
also available to a pandas Series that has `dtype` object.

We access them by doing `s.str.method_name` where `method_name` is
the name of the method.

When we apply the method to a Series, it is applied to all rows in the
Series in one shot!

Let’s redo our previous example using a pandas `.str` method.

```python
%%time

# ~2x faster than loop... However, speed gain increases with size of DataFrame. The
# speedup can be in the ballpark of ~100-500x faster for big DataFrames.
# See appendix at the end of the lecture for an application on a larger DataFrame
df["numbers_str"] = df["numbers"].str.replace("#", "")

df.dtypes
```

We can use `.str` to access almost any string method that works on
normal strings. (See the [official
documentation](https://pandas.pydata.org/pandas-docs/stable/text.html)
for more information.)

```python
df["colors"].str.contains("p")
```

```python
df["colors"].str.capitalize()
```

## Type Conversions

In our example above, the `dtype` of the `numbers_str` column shows that pandas still treats
it as a string even after we have removed the `"#"`.

We need to convert this column to numbers.

The best way to do this is using the `pd.to_numeric` function.

This method attempts to convert whatever is stored in a Series into
numeric values

For example, after the `"#"` removed, the numbers of column
`"numbers"` are ready to be converted to actual numbers.

```python
df["numbers_numeric"] = pd.to_numeric(df["numbers_str"])
```

```python
df.dtypes
```

```python
df.head()
```

We can convert to other types well.

Using the `astype` method, we can convert to any of the supported
pandas `dtypes` (recall the [intro lecture](intro.ipynb)).

Below are some examples. (Pay attention to the reported `dtype`)

```python
df["numbers_numeric"].astype(str)
```

```python
df["numbers_numeric"].astype(float)
```

## Missing Data

Many datasets have missing data.

In our example, we are missing an element from the `"nums"` column.

```python
df
```

We can find missing data by using the `isnull` method.

```python
df.isnull()
```

We might want to know whether particular rows or columns have any
missing data.

To do this we can use the `.any` method on the boolean DataFrame
`df.isnull()`.

```python
df.isnull().any(axis=0)
```

```python
df.isnull().any(axis=1)
```

Many approaches have been developed to deal with missing data, but the two most commonly used (and the corresponding DataFrame method) are:

- Exclusion: Ignore any data that is missing (`.dropna`).  
- Imputation: Compute “predicted” values for the data that is missing
  (`.fillna`).  


For the advantages and disadvantages of these (and other) approaches,
consider reading the [Wikipedia
article](https://en.wikipedia.org/wiki/Missing_data).

For now, let’s see some examples.

```python
# drop all rows containing a missing observation
df.dropna(axis=1)
```

```python
# fill the missing values with a specific value
df.fillna(value=100)
```

```python
# use the _next_ valid observation to fill the missing data
df.fillna(method="bfill")
```

```python
# use the _previous_ valid observation to fill missing data
df.fillna(method="ffill")
```

We will see more examples of dealing with missing data in future
chapters.

## Case Study

We will now use data from an
[article](https://www.nytimes.com/interactive/2015/02/17/upshot/what-do-people-actually-order-at-chipotle.html)
written by The Upshot at the NYTimes.

This data has order information from almost 2,000 Chipotle orders and
includes information on what was ordered and how much it cost.

```python
url = "https://datascience.quantecon.org/assets/data/chipotle_raw.csv.zip"
chipotle = pd.read_csv(url)
chipotle.head()
```

```python
chipotle.head()
```

**Exercise**

We'd like you to use this data to answer the following questions.

- What is the average price of an item with chicken?  
- What is the average price of an item with steak?  
- Did chicken or steak produce more revenue (total)?  
- How many missing items are there in this dataset? How many missing
  items in each column?  


Hint: before you will be able to do any of these things you will need to
make sure the `item_price` column has a numeric `dtype` (probably
float)


```python

```

```python

```

```python

```

```python

```

## Appendix: Performance of `.str` Methods

Let’s repeat the “remove the `#`” example from above, but this time on
a much larger dataset.

```python
import numpy as np
test = pd.DataFrame({"floats": np.round(100*np.random.rand(100_000), 2)})
test["strings"] = test["floats"].astype(str) + "%"
test.head()
```

```python
%%time

for row in test.iterrows():
    index_value, column_values = row
    clean_number = column_values["strings"].replace("%", "")
    test.at[index_value, "numbers_loop"] = clean_number
```

```python
%%time
test["numbers_str_method"] = test["strings"].str.replace("%", "")
```

```python
test["numbers_str_method"].equals(test["numbers_loop"])
```

We got the exact same result in a fraction of the time!

