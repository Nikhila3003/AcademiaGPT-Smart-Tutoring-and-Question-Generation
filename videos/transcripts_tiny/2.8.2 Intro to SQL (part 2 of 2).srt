1
00:00:00,000 --> 00:00:02,000
Hi everyone, this is Chase.

2
00:00:02,000 --> 00:00:07,000
We're going to continue today by discussing SQL.

3
00:00:07,000 --> 00:00:13,000
We're going to focus in particular on heavy usage of SQL

4
00:00:13,000 --> 00:00:18,000
and learn through many different examples.

5
00:00:18,000 --> 00:00:22,000
The data that we're going to use to motivate SQL

6
00:00:22,000 --> 00:00:27,000
comes from the Instacart data set that we discussed previously

7
00:00:27,000 --> 00:00:31,000
and has the feature of it that we're interested in

8
00:00:31,000 --> 00:00:34,000
is that there are multiple tables that all reference one

9
00:00:34,000 --> 00:00:37,000
another. It's a relational data set.

10
00:00:37,000 --> 00:00:42,000
As usual, we'll start today by importing the packages

11
00:00:42,000 --> 00:00:45,000
some of which you're familiar with.

12
00:00:45,000 --> 00:00:48,000
The one that's new is SQL Alchemy.

13
00:00:48,000 --> 00:00:54,000
And we'll talk about why we import that in the coming slides.

14
00:00:55,000 --> 00:01:02,000
So SQL or SQL stands for structured query language.

15
00:01:02,000 --> 00:01:06,000
A query language is a programming language that can be used

16
00:01:06,000 --> 00:01:09,000
to communicate with databases.

17
00:01:09,000 --> 00:01:13,000
As we've mentioned, SQL is going to focus on ways to communicate

18
00:01:13,000 --> 00:01:16,000
with relational databases.

19
00:01:16,000 --> 00:01:20,000
And rather than being a particular piece of software,

20
00:01:20,000 --> 00:01:25,000
SQL itself is more of a standard for a programming language

21
00:01:25,000 --> 00:01:27,000
to communicate with databases.

22
00:01:27,000 --> 00:01:32,000
So it sets particular protocols and particular syntaxes

23
00:01:32,000 --> 00:01:35,000
for how one should communicate with a database.

24
00:01:35,000 --> 00:01:40,000
And then the database itself needs to create their own

25
00:01:40,000 --> 00:01:44,000
implementation of how to translate SQL commands

26
00:01:44,000 --> 00:01:46,000
into their backend.

27
00:01:47,000 --> 00:01:52,000
Because of this, there have emerged multiple variants of SQL.

28
00:01:52,000 --> 00:01:56,000
Today, we're going to be using one called SQL Light.

29
00:01:56,000 --> 00:01:59,000
And SQL Light, the reason it's convenient,

30
00:01:59,000 --> 00:02:03,000
especially for a first introduction to SQL,

31
00:02:03,000 --> 00:02:06,000
is that it comes packaged with Python.

32
00:02:06,000 --> 00:02:11,000
In production, you wouldn't typically use something like SQL Light.

33
00:02:11,000 --> 00:02:14,000
One of the ones that I'm particularly fond of

34
00:02:14,000 --> 00:02:19,000
is called PostgresQL or Postgres.

35
00:02:19,000 --> 00:02:21,000
And we won't talk about that today,

36
00:02:21,000 --> 00:02:25,000
but we may talk about that later in the semester.

37
00:02:25,000 --> 00:02:28,000
So what problem does SQL solve?

38
00:02:28,000 --> 00:02:32,000
We think there are kind of four bullet points.

39
00:02:32,000 --> 00:02:34,000
There's probably other problems it solves,

40
00:02:34,000 --> 00:02:37,000
but we wanted to talk about these ones.

41
00:02:37,000 --> 00:02:39,000
So the first one, and most importantly,

42
00:02:39,000 --> 00:02:44,000
is it creates a language to ingest data from a database.

43
00:02:44,000 --> 00:02:45,000
It's a query language.

44
00:02:45,000 --> 00:02:49,000
It creates queries and interacts with the database

45
00:02:49,000 --> 00:02:52,000
to return new data.

46
00:02:52,000 --> 00:02:55,000
The second is it sets an industry standard.

47
00:02:55,000 --> 00:03:01,000
That helps make database code and requirements very close to compatible.

48
00:03:01,000 --> 00:03:06,000
So as we mentioned, there are a few different variants and flavors of SQL

49
00:03:06,000 --> 00:03:08,000
that are commonly used.

50
00:03:08,000 --> 00:03:14,000
And while they're very similar, there are slight differences.

51
00:03:14,000 --> 00:03:21,000
But it's relatively low cost to change from one database to another,

52
00:03:21,000 --> 00:03:27,000
because SQL has made the commands similar.

53
00:03:27,000 --> 00:03:32,000
Next, the database implementations in some of the standards in SQL

54
00:03:32,000 --> 00:03:39,000
and we can use it to make it really easy to provide multiple levels of data set access.

55
00:03:39,000 --> 00:03:45,000
For example, in this class, we're going to assume that we are mostly data users

56
00:03:45,000 --> 00:03:51,000
and are only objective is to take a SQL database as given

57
00:03:51,000 --> 00:03:55,000
and use the database for our analysis.

58
00:03:55,000 --> 00:04:01,000
Because of that, we can be read only users to the database,

59
00:04:01,000 --> 00:04:06,000
which allows us to set permission so that we couldn't mess something up on the database

60
00:04:06,000 --> 00:04:09,000
even if we wanted to.

61
00:04:09,000 --> 00:04:13,000
On the other side, there are data creators or administrators.

62
00:04:13,000 --> 00:04:18,000
And their job is to maintain an update data that is stored in the database.

63
00:04:18,000 --> 00:04:23,000
Of course, they're going to need the permissions necessary to add data

64
00:04:23,000 --> 00:04:27,000
or participate in other administration roles.

65
00:04:28,000 --> 00:04:33,000
And the final one is that it allows administrators or the database manager

66
00:04:33,000 --> 00:04:36,000
to impose strict requirements across the data.

67
00:04:36,000 --> 00:04:40,000
For example, we can impose things like a uniqueness constraint

68
00:04:40,000 --> 00:04:45,000
that if we don't want an email to correspond to more than one user,

69
00:04:45,000 --> 00:04:50,000
we could throw an error if someone tried to add another user

70
00:04:50,000 --> 00:04:53,000
with the email that had already been used.

71
00:04:54,000 --> 00:05:00,000
And in fact, on many websites, Facebook and others,

72
00:05:00,000 --> 00:05:07,000
this is how their requirements are being secured.

73
00:05:07,000 --> 00:05:14,000
So our focus today, like we said, is going to be really on how to be

74
00:05:14,000 --> 00:05:19,000
data-based users rather than being database administrators.

75
00:05:19,000 --> 00:05:28,000
We want you to be able to be given a SQL database and to extract data from that database.

76
00:05:28,000 --> 00:05:34,000
And we think that's the use case that you are more likely to fall into.

77
00:05:34,000 --> 00:05:42,000
So let's now discuss a few thematic details of SQL and SQL Alchemy.

78
00:05:42,000 --> 00:05:48,000
SQL Alchemy is a Python package that allows one to generically interface

79
00:05:48,000 --> 00:05:50,000
with many different flavors of SQL.

80
00:05:50,000 --> 00:05:54,000
Like we said, Postgres, MySQL, SQL Light, etc.

81
00:05:54,000 --> 00:06:00,000
And SQL Alchemy allows us to do this using Python code.

82
00:06:00,000 --> 00:06:04,000
We've discussed it only briefly today because it's not the focus

83
00:06:04,000 --> 00:06:10,000
at the lecture, but we did want to introduce it to you so that you could interact with it.

84
00:06:10,000 --> 00:06:16,000
We're going to be writing all of our SQL code in Python today

85
00:06:16,000 --> 00:06:22,000
because it's convenient, it's a medium that we've used previously.

86
00:06:22,000 --> 00:06:28,000
But in another setting, you might interact directly with a SQL database.

87
00:06:28,000 --> 00:06:32,000
And we wanted to show you what that might look like as well.

88
00:06:32,000 --> 00:06:37,000
So this is a tool called PostgresAdmin for a project that's been

89
00:06:37,000 --> 00:06:39,000
Serenia working on.

90
00:06:39,000 --> 00:06:43,000
And it allows us to write and you'll review these statements later.

91
00:06:43,000 --> 00:06:51,000
So it allows us to write SQL commands rather than Python code and spits out data below.

92
00:06:51,000 --> 00:07:01,000
So like I said, we're going to be using Python code today, but Python is not the necessary ingredient here.

93
00:07:01,000 --> 00:07:08,000
Now, as we've mentioned, one of the benefits of SQL is that it allows those who are creating the databases

94
00:07:08,000 --> 00:07:13,000
to impose tight requirements on what is contained in the data.

95
00:07:13,000 --> 00:07:18,000
Additionally, that means if you're a user of the data set or the database,

96
00:07:18,000 --> 00:07:23,000
you have a very good idea of what data is contained in that database,

97
00:07:23,000 --> 00:07:30,000
and you know which columns are defined and what values they can take.

98
00:07:30,000 --> 00:07:40,000
SQL is going to require you to specify each of your tables up front and set predefined columns.

99
00:07:40,000 --> 00:07:52,000
You could also impose cross-table restrictions and other restrictions such as unique values or things like that.

100
00:07:52,000 --> 00:07:58,000
Additionally, every column in a SQL table is going to have a specified type.

101
00:07:58,000 --> 00:08:06,000
These types are the usual ones that we've come across in Python, so there are things like a Boolean.

102
00:08:06,000 --> 00:08:09,000
Some kind of a date time representation.

103
00:08:09,000 --> 00:08:12,000
New Merrick types, they have float integer.

104
00:08:12,000 --> 00:08:21,000
They allow you to specify different sizes, so you could do smaller integers or a bigger integer than in Python.

105
00:08:21,000 --> 00:08:32,000
And what that just means is a smaller integer isn't integer that is less precise, so a small int can't represent numbers above approximately 32,000.

106
00:08:32,000 --> 00:08:39,000
Whereas a big int can represent much larger numbers.

107
00:08:39,000 --> 00:08:45,000
And the last type is going to be strings.

108
00:08:45,000 --> 00:08:55,000
So we're going to declare the table structure that we reviewed in the previous notebook using SQL Alchemy.

109
00:08:55,000 --> 00:08:58,000
We don't want to spend too much time on this again.

110
00:08:58,000 --> 00:09:03,000
We view this as mostly a task for database administrators.

111
00:09:03,000 --> 00:09:11,000
But as a data user, it's helpful to know how to explore the table definitions.

112
00:09:12,000 --> 00:09:16,000
So each table is going to have a name.

113
00:09:16,000 --> 00:09:19,000
So we've named this table Isles.

114
00:09:19,000 --> 00:09:25,000
And if you recall Isles has two values, it has an ILID.

115
00:09:25,000 --> 00:09:32,000
And another column called IL that contains a string description of what is in that IL.

116
00:09:32,000 --> 00:09:39,000
The other thing you'll note here is that we've imposed that ILID is a primary key.

117
00:09:39,000 --> 00:09:43,000
So it's an integer and a primary key.

118
00:09:43,000 --> 00:09:47,000
And all primary key means is that we can't duplicate this value.

119
00:09:47,000 --> 00:09:56,000
So if we had an ILID one defined, we could not insert another ILID one value into this table.

120
00:09:56,000 --> 00:10:02,000
Likewise, we'll define the department's table, the product's table.

121
00:10:03,000 --> 00:10:07,000
So in the product's table, we had product ID, which was the primary key.

122
00:10:07,000 --> 00:10:12,000
Product name, just like in departments and Iles.

123
00:10:12,000 --> 00:10:15,000
But then we had two additional columns.

124
00:10:15,000 --> 00:10:22,000
We had an ILID and a department ID, which were integers.

125
00:10:22,000 --> 00:10:31,000
If we wanted to, we could define these such that they referenced the ILID in department ID from the other tables.

126
00:10:32,000 --> 00:10:34,000
And you could not.

127
00:10:34,000 --> 00:10:43,000
And these restrictions would say that you can not insert a value for products unless the ILID and department ID exist in these other tables.

128
00:10:43,000 --> 00:10:55,000
We're not going to talk about it today, like I said, but we wanted you to know that things such as foreign keys is the word you should Google if you're interested exist.

129
00:10:55,000 --> 00:11:04,000
And then there's the orders table and the products order table.

130
00:11:04,000 --> 00:11:09,000
Let me make sure I ran this.

131
00:11:09,000 --> 00:11:24,000
Then to create a SQL alchemy engine, which is just going to be some kind of an interface into the SQL database that Python can use is we're going to use the SQL alchemy create engine function.

132
00:11:24,000 --> 00:11:29,000
And again, we're going to be using SQL light.

133
00:11:29,000 --> 00:11:31,000
We're going to use it.

134
00:11:31,000 --> 00:11:36,000
We're going to save the SQL light database into a file called Instacart.db.

135
00:11:36,000 --> 00:11:39,000
Then we're going to create.

136
00:11:39,000 --> 00:11:43,000
We're going to specify that all of the tables we mentioned exist.

137
00:11:43,000 --> 00:11:51,000
And we're going to create a session maker, which we're not going to talk about today.

138
00:11:52,000 --> 00:11:59,000
We wanted to leave the data that we used to create our Instacart.db database here.

139
00:11:59,000 --> 00:12:07,000
If you're interested, we specified kind of amapping from tables to files.

140
00:12:07,000 --> 00:12:17,000
And then we just read the parquet files and dump everything from the parquet file into each table.

141
00:12:17,000 --> 00:12:24,000
But again, this takes a few minutes to run, so we're not going to do it again.

142
00:12:24,000 --> 00:12:25,000
Okay.

143
00:12:25,000 --> 00:12:30,000
Now this sets the stage for reading data from a SQL database.

144
00:12:30,000 --> 00:12:35,000
So like we've said, unless you end up becoming a data engineer or a database administrator,

145
00:12:35,000 --> 00:12:44,000
most of your time interacting with a database is going to be reading data that someone else has created for you.

146
00:12:44,000 --> 00:12:54,000
And so what we're going to do is we're going to walk through all of the different things that you can do with a SQL query.

147
00:12:54,000 --> 00:12:59,000
We're going to run these raw SQL commands in the SQL alchemy engine.

148
00:12:59,000 --> 00:13:06,000
But like we showed you on the other tab, you could interact directly with a SQL database.

149
00:13:06,000 --> 00:13:11,000
You don't need Python to be the intermediary.

150
00:13:12,000 --> 00:13:16,000
We're going to define a helper function called RunQuery.

151
00:13:16,000 --> 00:13:23,000
And RunQuery is just going to take one of our SQL alchemy engines and a raw SQL query.

152
00:13:23,000 --> 00:13:27,000
And it's going to execute that query.

153
00:13:27,000 --> 00:13:35,000
And then it's going to print the column names and each of the rows returned from that query.

154
00:13:35,000 --> 00:13:40,000
We'll see how this works on the next slide.

155
00:13:40,000 --> 00:13:47,000
The last thing we wanted to note is that it's good practice to capitalize your SQL keywords.

156
00:13:47,000 --> 00:13:54,000
The first two we're going to talk about are selecting from, so rather than writing select lower case,

157
00:13:54,000 --> 00:14:02,000
and from lower case, you should write select and from in all caps.

158
00:14:02,000 --> 00:14:05,000
And now we're ready to get started.

159
00:14:05,000 --> 00:14:14,000
So the most fundamental read command and SQL is the command select from.

160
00:14:14,000 --> 00:14:20,000
Select is going to specify what data to read in, and as we'll see what to call it,

161
00:14:20,000 --> 00:14:25,000
and from is going to specify where that data can be read from.

162
00:14:25,000 --> 00:14:33,000
So our first, our first SQL command is going to be select star,

163
00:14:33,000 --> 00:14:37,000
and star is just a shortcut for every column.

164
00:14:37,000 --> 00:14:43,000
So select every column from the table products.

165
00:14:43,000 --> 00:14:51,000
And if we do that, we get the product ID, the product name, the ILID, and the department ID.

166
00:14:51,000 --> 00:14:58,000
And just like we're specified in the table definition.

167
00:14:59,000 --> 00:15:06,000
Now you don't always want every column from a particular table.

168
00:15:06,000 --> 00:15:11,000
So notice this product name is a little bit long, and it's making our printing ugly

169
00:15:11,000 --> 00:15:14,000
because it collides with our next column.

170
00:15:14,000 --> 00:15:22,000
So we could specify that we wanted to select the product ID, the ILID,

171
00:15:22,000 --> 00:15:27,000
and the department ID from the products table.

172
00:15:27,000 --> 00:15:39,000
And then we're just going to get three of the columns that we specified.

173
00:15:39,000 --> 00:15:50,000
Now the data in your database isn't always named according to conventions that match the rest of your code,

174
00:15:50,000 --> 00:15:54,000
or just sometimes you need a shorter name.

175
00:15:54,000 --> 00:16:00,000
So SQL allows you to rename columns that you're reading in.

176
00:16:00,000 --> 00:16:04,000
So in this case, we're going to select three columns.

177
00:16:04,000 --> 00:16:06,000
We're going to select products.

178
00:16:06,000 --> 00:16:12,000
We're going to select product ID, ILID, and the department ID.

179
00:16:12,000 --> 00:16:19,000
And what we've done is violated our all caps rule first.

180
00:16:19,000 --> 00:16:24,000
We've said we're selecting the product ID, and we'd like you to name it PID.

181
00:16:24,000 --> 00:16:28,000
We're selecting the ILID, and we'd like you to name it AID,

182
00:16:28,000 --> 00:16:32,000
the department ID to DID.

183
00:16:32,000 --> 00:16:48,000
And now what we see is that the column names that were returned are PID, AID, and DID.

184
00:16:48,000 --> 00:16:56,000
The next thing that we can do, and we're going to use this much more heavily in the coming sections,

185
00:16:56,000 --> 00:17:00,000
but you can reference tables using an abbreviation.

186
00:17:00,000 --> 00:17:08,000
So in this case, we've said from the products table, which we're going to nickname P,

187
00:17:08,000 --> 00:17:17,000
we'd like to select P. Product ID, which specifies we're getting the product ID column

188
00:17:17,000 --> 00:17:21,000
from the P table.

189
00:17:21,000 --> 00:17:35,000
We'd like to select the PID ILID and P. Department ID, and we can run that query as well.

190
00:17:35,000 --> 00:17:43,000
And notice this has been the same data each time once we stopped tracking the product name.

191
00:17:43,000 --> 00:17:50,000
And so we can see that it winds up.

192
00:17:50,000 --> 00:18:00,000
And in addition to being able to reference this in abbreviation or rename columns,

193
00:18:00,000 --> 00:18:06,000
we can also combine columns. So in this case, we're going to select Product ID,

194
00:18:06,000 --> 00:18:11,000
we're going to select the ILID, the department ID,

195
00:18:11,000 --> 00:18:19,000
and then we're going to select the sum of the ILID and the department ID.

196
00:18:19,000 --> 00:18:29,000
And we're going to store that as IL department ID.

197
00:18:29,000 --> 00:18:37,000
And just like we promised, we have the product ID, we have the ILID, the department ID,

198
00:18:37,000 --> 00:18:43,000
and then in the last column we've taken the ILID, which is 61 in the department ID,

199
00:18:43,000 --> 00:18:54,000
which is 19, and we sum to those together to get 80.

200
00:18:54,000 --> 00:19:00,000
Next we're going to talk about joins. So as we've discussed,

201
00:19:00,000 --> 00:19:07,000
SQL is a relational database, which means that we will typically store data across multiple tables.

202
00:19:07,000 --> 00:19:14,000
And we often want to be able to combine and manipulate the data from these multiple tables.

203
00:19:14,000 --> 00:19:23,000
Join will allow us to bring together two or more data sets into a single query.

204
00:19:24,000 --> 00:19:36,000
So in this first example, what we're going to do is we're going to select all of the columns from the products table.

205
00:19:36,000 --> 00:19:44,000
And we're going to join, so we're going to select all of the columns from products,

206
00:19:44,000 --> 00:19:54,000
joined with ILls. And the way that we're going to join these two data sets is we're going to join them on places where the products.

207
00:19:54,000 --> 00:20:01,000
ILID is equal to the ILls.ioid.

208
00:20:01,000 --> 00:20:12,000
And so if we combine this, notice we have our original products table, which has product ID, product name, ILID, and department ID.

209
00:20:12,000 --> 00:20:21,000
But we've now added ILID and IL from the ILls table. So this is now a duplicate.

210
00:20:21,000 --> 00:20:28,000
And we can see that it matches everywhere.

211
00:20:28,000 --> 00:20:40,000
Now, at the very least, we don't want to be returning ILID twice unless we're checking to see whether the code is performing as we expect.

212
00:20:40,000 --> 00:20:45,000
So we'd like to be able to select that subsets of columns from each table.

213
00:20:45,000 --> 00:20:53,000
And this is where the column nick naming or the table nick naming rather becomes more useful.

214
00:20:53,000 --> 00:21:06,000
So we can do things now like select p.product name, p.ioid, p. department ID, and a.io.

215
00:21:06,000 --> 00:21:19,000
And we're going to select those from the products table and the ILls table, which we are joining on the ILID ILID.

216
00:21:19,000 --> 00:21:34,000
And so we can see we no longer have the duplicate ILID, but we've added the IL names.

217
00:21:34,000 --> 00:21:44,000
So the merges we've done so far have just used the join command.

218
00:21:44,000 --> 00:21:53,000
But there's actually four different merges that we can do and maybe maybe more. I know a four merges that we can do.

219
00:21:53,000 --> 00:22:00,000
And they're going to line up closely to the merging that we've done using pandas.

220
00:22:00,000 --> 00:22:10,000
So there's the left merge, the right merge, the inner merge, and the outer merge.

221
00:22:10,000 --> 00:22:16,000
We think it's best to describe these using a then diagram.

222
00:22:16,000 --> 00:22:36,000
So if we have dataset X and dataset Y and both dataset X and Y have ID, little X and ID and Y.

223
00:22:36,000 --> 00:22:45,000
And what we're trying to do is we're trying to create a dataset that has ID, X and Y.

224
00:22:45,000 --> 00:22:56,000
Then these two circles represent the values of ID that exist in each of the datasets.

225
00:22:56,000 --> 00:22:59,000
So a left join.

226
00:22:59,000 --> 00:23:02,000
So let's write a small example.

227
00:23:02,000 --> 00:23:19,000
So in table X we have ID X we have one, one, two, two, three, three, four, four.

228
00:23:19,000 --> 00:23:44,000
And then table Y we have ID and Y and we have one, 11, two, 12, five, 15, and six, 16.

229
00:23:44,000 --> 00:23:53,000
So we're going to review each of the four merges that we can do. So what is a left merge?

230
00:23:53,000 --> 00:24:06,000
A left merge is going to look at the left table or dataset and it's going to find all of the values for ID that exist in the left dataset.

231
00:24:06,000 --> 00:24:14,000
So that's this shaded area right here, including the intersection.

232
00:24:14,000 --> 00:24:28,000
And so that will create the ID X and Y, one, two, three, four because we're keeping the ID values from the left dataset.

233
00:24:29,000 --> 00:24:33,000
The X is are going to just match.

234
00:24:33,000 --> 00:24:37,000
They're going to come straight from the X dataset itself.

235
00:24:37,000 --> 00:24:46,000
And the Y values are going to be the ID, the ID, one, for X, ID, one, for Y.

236
00:24:46,000 --> 00:24:50,000
The little value of Y is 11.

237
00:24:50,000 --> 00:24:55,000
The value two for X matches the value two for Y. We get 12.

238
00:24:55,000 --> 00:25:06,000
The value three for X matches no value from Y and the value four for X matches no value and Y.

239
00:25:06,000 --> 00:25:14,000
So we'd end up with a dataset that looks like this.

240
00:25:14,000 --> 00:25:25,000
Now similarly, right would do a similar case.

241
00:25:25,000 --> 00:25:33,000
But it would now have one, two, five and six.

242
00:25:33,000 --> 00:25:39,000
And we would end up with a dataset that looked like this.

243
00:25:39,000 --> 00:25:43,000
I'll let you work through the details.

244
00:25:44,000 --> 00:25:50,000
And then we could look at an inner join.

245
00:25:50,000 --> 00:25:55,000
And an inner join is it only finds the values of ID.

246
00:25:55,000 --> 00:26:00,000
So it's this section of the Venn diagram right here.

247
00:26:00,000 --> 00:26:05,000
It's only going to find values of ID, which are in both datasets.

248
00:26:05,000 --> 00:26:09,000
So inner would give us one, two.

249
00:26:10,000 --> 00:26:15,000
And when ID is one, X is one, and Y is 11.

250
00:26:15,000 --> 00:26:22,000
When ID is two, X is two, and Y is 12.

251
00:26:22,000 --> 00:26:28,000
And so we would say when ID is three, there's no three and Y.

252
00:26:28,000 --> 00:26:35,000
So we don't include it, same with four, same with five, same with six.

253
00:26:36,000 --> 00:26:42,000
Now we could do the opposite, in some sense, which is an outer.

254
00:26:42,000 --> 00:26:46,000
And the outer join is going to be all of both circles.

255
00:26:46,000 --> 00:26:52,000
So it's going to be every value of ID that's either in X or Y.

256
00:26:52,000 --> 00:26:58,000
So we end up with one, two, three, four, five, six.

257
00:26:58,000 --> 00:27:04,000
And X is one, two, three, four.

258
00:27:05,000 --> 00:27:13,000
And Y would be 11, 12, missing, missing, 15, 16.

259
00:27:13,000 --> 00:27:23,000
And this is what we would end up with with the outer join.

260
00:27:23,000 --> 00:27:26,000
So that's what these words say.

261
00:27:26,000 --> 00:27:31,000
And in the case of the data that we're working with right now,

262
00:27:31,000 --> 00:27:41,000
this is, I don't know why right joint didn't work.

263
00:27:41,000 --> 00:27:56,000
I see right and outer joins are not currently supported by SQL light.

264
00:27:56,000 --> 00:28:05,000
So if you were working with a different flavor of SQL, right and outer would work.

265
00:28:05,000 --> 00:28:15,000
But because we're working with SQL light, we aren't able to run the right and outer joins.

266
00:28:15,000 --> 00:28:20,000
Again, because the data that we're working with is clean,

267
00:28:20,000 --> 00:28:28,000
they're just all returning the same subset of data.

268
00:28:28,000 --> 00:28:33,000
And we don't actually have to restrict ourselves to only combining two data sets.

269
00:28:33,000 --> 00:28:36,000
We can combine as many as we'd like.

270
00:28:36,000 --> 00:28:41,000
So in this case, we're going to take the same selection.

271
00:28:41,000 --> 00:28:47,000
But now we're going to select the product name, the IEL, and the department,

272
00:28:47,000 --> 00:28:53,000
which is just going to give us all of the string representations of the products description.

273
00:28:53,000 --> 00:28:59,000
So we're going to select the product name, the IEL, the department from the products table,

274
00:28:59,000 --> 00:29:05,000
which is left joined with the IEL's table on the IEL ID.

275
00:29:05,000 --> 00:29:11,000
And then all of that is left joined on the department's table on the department ID.

276
00:29:11,000 --> 00:29:18,000
And we end up with all of the string representations of this data.

277
00:29:18,000 --> 00:29:23,000
And notice we can do this join using the IEL ID and the department ID,

278
00:29:23,000 --> 00:29:30,000
even though we're not returning that data.

279
00:29:30,000 --> 00:29:33,000
Next, we're going to talk about the wear statement.

280
00:29:33,000 --> 00:29:38,000
And the wear statement is used when we're interested in working with particular subsets of the data,

281
00:29:38,000 --> 00:29:42,000
rather than selecting all of the rows at once.

282
00:29:42,000 --> 00:29:53,000
Sequel is going to allow us to specify certain conditions that are going to do this restriction for us using the wear class.

283
00:29:53,000 --> 00:29:58,000
So let's look at a simple starting example.

284
00:29:58,000 --> 00:30:05,000
So we're going to take the multiple joined table that we looked at previously.

285
00:30:05,000 --> 00:30:08,000
So it's selecting product name, IEL, and department.

286
00:30:08,000 --> 00:30:17,000
And up until now, we keep selecting this chocolate sandwich cookies first.

287
00:30:18,000 --> 00:30:25,000
And so what we're going to do is we're going to look for a place where the department is not equal to snacks.

288
00:30:25,000 --> 00:30:36,000
And so notice the cookies no longer come first because they were filtered out due to not being due to us not wanting snacks.

289
00:30:36,000 --> 00:30:42,000
Similarly, we could check for where the snacks are.

290
00:30:42,000 --> 00:30:46,000
So now this is going to give us products that are in the snacks department.

291
00:30:46,000 --> 00:30:56,000
And the thing to note here is that there is no, there's not much variable assignment in terms of sequel.

292
00:30:56,000 --> 00:31:03,000
It's not entirely true, but you can use one equal sign to denote equality.

293
00:31:03,000 --> 00:31:10,000
So we're saying here that we're looking for product, IEL department values,

294
00:31:10,000 --> 00:31:15,000
here that department is equal to snacks and that gave us the chocolate sandwich cookies that we had before.

295
00:31:15,000 --> 00:31:25,000
And also gave us a mint chocolate flavored syrup and not your cheese white bean dips chips.

296
00:31:25,000 --> 00:31:32,000
Similarly, we could ask for particular IELs.

297
00:31:32,000 --> 00:31:38,000
So in this case, we're restricting to places where the IEL ID is greater than 132.

298
00:31:38,000 --> 00:31:43,000
So in addition to comparing strings, we can compare numbers.

299
00:31:43,000 --> 00:31:50,000
And that gives us specialty wines, champagne, and muscle joints pain relief.

300
00:31:50,000 --> 00:31:53,000
And those are an IELs 134 and 133.

301
00:31:53,000 --> 00:31:57,000
So we can confirm that they satisfy our requirement.

302
00:31:57,000 --> 00:32:02,000
We could also check for less than 132.

303
00:32:02,000 --> 00:32:07,000
But that's the same data set we've been getting in our other queries.

304
00:32:08,000 --> 00:32:16,000
And of course, we can specify multiple conditions.

305
00:32:16,000 --> 00:32:23,000
So in this case, we're running the same query to get the product name, the IEL and the department.

306
00:32:23,000 --> 00:32:26,000
Left joint to the IELs and department's data.

307
00:32:26,000 --> 00:32:36,000
And now we're going to specify we want the IEL ID to be greater than 100, but the department ID to be less than 10.

308
00:32:36,000 --> 00:32:40,000
And notice this is specified with an AND.

309
00:32:40,000 --> 00:32:46,000
So let's go ahead and.

310
00:32:46,000 --> 00:32:54,000
These values.

311
00:32:54,000 --> 00:32:59,000
So what we see is the IEL IDs are all greater than 100.

312
00:32:59,000 --> 00:33:02,000
And the department IDs are less than 10.

313
00:33:02,000 --> 00:33:10,000
So when we write AND here, we mean it in the same sense that we mean it in Python of both things must be true.

314
00:33:10,000 --> 00:33:18,000
Similarly, we could check for where the IEL ID was greater than 100, or the department ID was less than 10.

315
00:33:18,000 --> 00:33:25,000
And as long as either of these conditions are satisfied, the data can show up in this query.

316
00:33:25,000 --> 00:33:28,000
So notice the IEL.

317
00:33:28,000 --> 00:33:31,000
Here IEL ID here is greater than 100.

318
00:33:31,000 --> 00:33:34,000
But the department ID is greater than 10.

319
00:33:34,000 --> 00:33:37,000
So the first condition was satisfied.

320
00:33:37,000 --> 00:33:45,000
The second row, the first condition was not satisfied because the IEL ID is 94, which is less than 100.

321
00:33:45,000 --> 00:33:51,000
But the second condition, department ID less than 10, is satisfied.

322
00:33:51,000 --> 00:33:52,000
Same for the next two.

323
00:33:52,000 --> 00:33:58,000
And then in the last row, the first condition is satisfied, but not the second.

324
00:34:02,000 --> 00:34:15,000
Now, as we mentioned, the data set that we're working with right now does not have a notion of dates or time other than the number of days since the last order.

325
00:34:15,000 --> 00:34:26,000
So we just wanted to highlight that you can use where to retrieve to subset data based on the date time.

326
00:34:26,000 --> 00:34:41,000
So if we had a table that had a date time, so this is March 31, 2020, for store ID 1, they had a hundred thousand dollars in sales.

327
00:34:41,000 --> 00:34:54,000
And so on and so forth, we could do the select star from our sales table, where the date time is less than April.

328
00:34:54,000 --> 00:35:04,000
And what that would give us is it would give us this first row, and it would give us this second, this fifth row.

329
00:35:04,000 --> 00:35:12,000
And the thing to note is when you do this comparison, you put the date in strings.

330
00:35:12,000 --> 00:35:22,000
Likewise, if we wanted to get the observations from quarter three and four, we could write greater than June 31.

331
00:35:22,000 --> 00:35:37,000
And we would end up with the observation three and four and seven and eight.

332
00:35:37,000 --> 00:35:50,000
Again, this is this is just a toy data set meant to show you that we can impose restrictions based on the date times as well.

333
00:35:50,000 --> 00:35:56,000
The next argument we'll talk about is the group by.

334
00:35:56,000 --> 00:36:05,000
So group by is going to allow us to aggregate certain groups of values, much like the Pandas group by method.

335
00:36:05,000 --> 00:36:19,000
The thing to especially note, which is true in Pandas as well, is that any column that is not an element of the grouping must have a reduction function applied to it.

336
00:36:19,000 --> 00:36:34,000
So we're now going to start working with the order's data and just so we can remember what that looks like.

337
00:36:34,000 --> 00:36:38,000
Select, we'll do star.

338
00:36:38,000 --> 00:36:59,000
So we have seven columns, we have the order ID, the user ID, which set the data belong to to the order number, the order day of week, the order hour of day, and the days since the previous order.

339
00:36:59,000 --> 00:37:12,000
So what we're going to do is we're going to select the day of week that an order was made and then we're going to count how many non missing values of user ID there are.

340
00:37:12,000 --> 00:37:18,000
And we're going to store that as a new column called number of orders.

341
00:37:18,000 --> 00:37:27,000
That's going to be from the orders table and we're going to group by the order day of week.

342
00:37:27,000 --> 00:37:35,000
So what this is going to give us is in the data set that.

343
00:37:35,000 --> 00:37:38,000
We were given.

344
00:37:38,000 --> 00:37:42,000
There were 600,000 orders placed on Sunday.

345
00:37:43,000 --> 00:37:55,000
And about 425 to 450,000 orders placed on Tuesday, Wednesday and Thursday.

346
00:37:55,000 --> 00:37:58,000
We're only looking at the first five rows.

347
00:37:58,000 --> 00:38:08,000
So we could see Thursday Friday Saturday if we wanted.

348
00:38:08,000 --> 00:38:14,000
Now, just like in pandas, we can group by more than one column.

349
00:38:14,000 --> 00:38:20,000
So we can, we're going to select the user ID and the order day of week.

350
00:38:20,000 --> 00:38:26,000
And then we're going to count the number of order IDs that are not missing.

351
00:38:26,000 --> 00:38:35,000
We're going to do that from the orders table and now we're going to group by the user ID and the order day of week.

352
00:38:35,000 --> 00:38:44,000
And so what this tells us is that user one, only ever ordered on Monday Tuesday Wednesday or Thursday.

353
00:38:44,000 --> 00:38:51,000
Because otherwise there would be another user one ID here.

354
00:38:51,000 --> 00:39:04,000
And they ordered three times on Monday, two times on Tuesday, two times on Wednesday and four times on Thursday.

355
00:39:06,000 --> 00:39:13,000
And we can also aggregate, so we've only been counting the order numbers in the previous two cases.

356
00:39:13,000 --> 00:39:16,000
We can also aggregate multiple columns.

357
00:39:16,000 --> 00:39:21,000
So here we're going to select the user ID and order day of week again.

358
00:39:21,000 --> 00:39:26,000
And then we're going to count the order IDs for the number of orders.

359
00:39:26,000 --> 00:39:33,000
And these as, this should be all caps.

360
00:39:34,000 --> 00:39:38,000
And then what we're going to do is we're going to use a different reduction function average.

361
00:39:38,000 --> 00:39:43,000
And we're going to find out the average days since the prior order.

362
00:39:43,000 --> 00:39:48,000
And so if we run this query, what we're going to read is that,

363
00:39:48,000 --> 00:40:00,000
user one, when they order on Mondays, they have an average of 11 days since their previous order.

364
00:40:00,000 --> 00:40:05,000
When they order on Tuesdays, it's been almost to three weeks.

365
00:40:05,000 --> 00:40:11,000
And Wednesdays, almost three weeks and on Thursdays, almost three weeks.

366
00:40:11,000 --> 00:40:18,000
One hypothesis that you might put to the test if you had more data is that individual one,

367
00:40:18,000 --> 00:40:25,000
only orders on Mondays when they realize that they have something missing.

368
00:40:26,000 --> 00:40:29,000
Again, that's something we would have to test.

369
00:40:29,000 --> 00:40:40,000
But, and we don't have enough data necessarily to do it for this data set.

370
00:40:40,000 --> 00:40:51,000
Now we're going to talk about the order by, which will allow us to sort the output of a particular SQL query.

371
00:40:51,000 --> 00:40:54,000
So we can order by a single column.

372
00:40:54,000 --> 00:41:02,000
So here we're going to select the order ID user ID order number and days since prior order.

373
00:41:02,000 --> 00:41:06,000
And that will give us user ID one.

374
00:41:06,000 --> 00:41:12,000
And the data is kind of out of order here.

375
00:41:12,000 --> 00:41:18,000
These order numbers should be the order that they put in their dates.

376
00:41:18,000 --> 00:41:22,000
So we can order by more than one column.

377
00:41:22,000 --> 00:41:29,000
So now we're going to select order ID user ID order number and days since the previous order.

378
00:41:29,000 --> 00:41:34,000
And we're going to order by user ID and order number.

379
00:41:34,000 --> 00:41:38,000
And that will give us the order set of orders.

380
00:41:38,000 --> 00:41:46,000
So user ID user one, their first order happened, their second order happened about two weeks later.

381
00:41:46,000 --> 00:41:51,000
Their third order happened about three weeks after that.

382
00:41:51,000 --> 00:42:00,000
Another three or four weeks, four weeks, and so on and so forth.

383
00:42:00,000 --> 00:42:10,000
In addition to ordering by one or multiple columns, we can specify what order we'd like things to be ordered.

384
00:42:10,000 --> 00:42:16,000
So we can either have the data ordered in an ascending format or a descending format.

385
00:42:16,000 --> 00:42:24,000
So here we right select our columns the same ones we've been using in the previous queries.

386
00:42:24,000 --> 00:42:30,000
But now we're going to be ordered by the days since the prior order.

387
00:42:30,000 --> 00:42:34,000
And we want that to be descending.

388
00:42:34,000 --> 00:42:42,000
So we should have the highest values from the day since prior order first.

389
00:42:42,000 --> 00:42:48,000
And the lowest numbers, the lowest values for user ID first.

390
00:42:48,000 --> 00:42:52,000
So we can run this query and notice the day since prior order is 30.

391
00:42:52,000 --> 00:42:55,000
Which is the maximum value in this data set.

392
00:42:55,000 --> 00:43:00,000
And then you can see that the user ID is also ordered one, two, four.

393
00:43:00,000 --> 00:43:10,000
We could add a wear statement if we wanted a day since prior order less than 30.

394
00:43:10,000 --> 00:43:15,000
And we would end up with a set of orders.

395
00:43:15,000 --> 00:43:18,000
So we can add a set of orders.

396
00:43:18,000 --> 00:43:21,000
So we can add a set of orders.

397
00:43:21,000 --> 00:43:26,000
And we would end up with a 29 here.

398
00:43:26,000 --> 00:43:28,000
That's less than 30.

399
00:43:28,000 --> 00:43:34,000
And user ID again is increasing.

400
00:43:34,000 --> 00:43:42,000
The final clause that we're going to talk about is the limit clause.

401
00:43:42,000 --> 00:43:48,000
And limit is going to play the same rule as the head method did for a pandas data frame.

402
00:43:48,000 --> 00:43:53,000
So we're going to allow you to select the enlarged or smallest values.

403
00:43:53,000 --> 00:43:58,000
And you can use it to simply get a preview of your data.

404
00:43:58,000 --> 00:44:09,000
So what we're going to do is we're going to run a small horse race.

405
00:44:09,000 --> 00:44:13,000
So we're going to query with a limit 10.

406
00:44:13,000 --> 00:44:19,000
So the database is only going to find the first 10 values that satisfy our criteria.

407
00:44:19,000 --> 00:44:23,000
You'll notice that took about a millisecond.

408
00:44:23,000 --> 00:44:30,000
And now what we're going to do is we're going to query all of the values.

409
00:44:30,000 --> 00:44:36,000
And that's going to take about 3 to 3.5 seconds.

410
00:44:36,000 --> 00:44:42,000
So if you're just looking for a small subset of data that you can start playing with before you.

411
00:44:42,000 --> 00:44:44,000
Move on to your full analysis.

412
00:44:44,000 --> 00:44:49,000
Limit can be a helpful clause.

413
00:44:49,000 --> 00:44:57,000
Up until this point we've been using SQL Alchemies engine directly to read data.

414
00:44:57,000 --> 00:45:02,000
But we'd like to also point out that you can read directly from a pandas.

415
00:45:02,000 --> 00:45:06,000
So here we've defined a particular query.

416
00:45:06,000 --> 00:45:12,000
And if we pass this query along with the SQL Alchemy engine,

417
00:45:12,000 --> 00:45:23,000
pandas will go ahead and execute this query and put it into a data frame, which can be convenient.

418
00:45:23,000 --> 00:45:32,000
And now to conclude, we wanted to wrap up to show you kind of what type of flexibility SQL can achieve.

419
00:45:32,000 --> 00:45:44,000
So in the Instacart data description, we had a, we had a command at the bottom that built up the fraction of,

420
00:45:44,000 --> 00:45:52,000
Reorders that a particular, the fraction of orders that were reorders that a particular product had.

421
00:45:52,000 --> 00:45:58,000
We're going to do the same thing here, but we're only going to use SQL.

422
00:45:59,000 --> 00:46:05,000
In order to do this, we found it helpful to use a with clause.

423
00:46:05,000 --> 00:46:13,000
And a with clause allows you to define a temporary table that can then be used in a subsequent query.

424
00:46:13,000 --> 00:46:17,000
So let's think about how we're going to break this up.

425
00:46:17,000 --> 00:46:26,000
So in our with clause, what we're going to do is we're going to create the number of orders

426
00:46:26,000 --> 00:46:31,000
and the number of reorders for a particular product.

427
00:46:31,000 --> 00:46:39,000
And we'll do this by selecting the product ID by counting the number of add to cart orders,

428
00:46:39,000 --> 00:46:45,000
and by summing the number of reordered values.

429
00:46:45,000 --> 00:46:51,000
Additionally, we're going to, so this is coming from the products ordered table.

430
00:46:52,000 --> 00:46:59,000
We're going to left join the products ordered table on the orders table.

431
00:46:59,000 --> 00:47:05,000
And we're going to join that on the order ID column.

432
00:47:05,000 --> 00:47:19,000
Then we're going to only look at values where the orders dot the day's sense prior order column from the orders table is not missing,

433
00:47:19,000 --> 00:47:28,000
because remember the first time that an individual made an order, they had a missing value for days since the prior order,

434
00:47:28,000 --> 00:47:33,000
and they could not have ordered it prior to that event.

435
00:47:33,000 --> 00:47:41,000
Then we're going to group by the product ID, and we're going to compute this end order and reorder.

436
00:47:41,000 --> 00:47:50,000
So we've now defined this as a new table called aggregate product ordered.

437
00:47:50,000 --> 00:48:01,000
And so we can do select from this new table, the product ID, the end order, and the end reorder.

438
00:48:01,000 --> 00:48:07,000
We can do end reorder divided by end order, and because these are both integers,

439
00:48:07,000 --> 00:48:12,000
we needed to multiply by a float so that we didn't do integer division.

440
00:48:12,000 --> 00:48:19,000
And integer division, if you have two divided by four, that equals zero.

441
00:48:19,000 --> 00:48:32,000
And so we multiplied by a 1.0 in order to get float division where that becomes a 1.5.

442
00:48:32,000 --> 00:48:43,000
So that's what that does, and then we're also going to select the product name, the ILID and the Department ID, like we did in the previous pandas version.

443
00:48:43,000 --> 00:48:49,000
This is going to come from the aggregate products ordered table that we created from the with statement.

444
00:48:49,000 --> 00:48:56,000
We're going to join it on the products table using the product ID column.

445
00:48:56,000 --> 00:49:02,000
And we're only going to look at products which had at least 10 reorders.

446
00:49:02,000 --> 00:49:18,000
We're then going to order this query by the frack reorder column, and we want it to be descending so that the highest values are at the top.

447
00:49:18,000 --> 00:49:28,000
Now, if all goes well, we should be able to run this command and get back the same answer that we had in the previous notebook.

448
00:49:28,000 --> 00:49:36,000
And the thing that I'll be looking for is we had a product that we investigated called orange energy shots.

449
00:49:36,000 --> 00:49:42,000
And so if orange energy shots shows up, it was ordered, reordered 100% at the time.

450
00:49:42,000 --> 00:49:46,000
It was only by one person, but they continually reordered it.

451
00:49:46,000 --> 00:49:56,000
And we see we have our orange energy shots. They were 12 orders, 12 reorders, for a 100% fraction reordered.

452
00:49:56,000 --> 00:50:07,000
We saw this one as well. So at first glance, this looks like we were able to produce the exact same answer we did in pandas, but directly with SQL.

453
00:50:07,000 --> 00:50:13,000
This wraps up we're going to talk about for SQL today. Hopefully you learned something.

454
00:50:13,000 --> 00:50:25,000
If this was new, this is a lot to take in, and the only way to master a tool like this, or even become literate in a tool like this, is to practice.

455
00:50:25,000 --> 00:50:33,000
So we'd encourage you to come back to these examples and to ask yourselves questions and ask this data questions.

456
00:50:33,000 --> 00:50:37,000
And that wraps up everything we have. Bye now.

