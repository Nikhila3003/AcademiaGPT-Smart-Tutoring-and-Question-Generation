1
00:00:00,000 --> 00:00:05,360
So this video, we're going to keep reviewing pandas and we're going to use an example

2
00:00:05,360 --> 00:00:12,160
using UN population data. Originally a lot of this material came from some work that

3
00:00:12,160 --> 00:00:18,160
Spencer and I did with Dave Backez who was that NYU and Brian LeBlock.

4
00:00:18,160 --> 00:00:27,120
And let's get started. So the data that we're going to use in this notebook to review

5
00:00:27,120 --> 00:00:32,160
pandas is we're going to look at the UN's population data. And in particular we're going to be

6
00:00:32,160 --> 00:00:40,240
focusing on the age distribution of the population. So there's going to be two types of data

7
00:00:40,240 --> 00:00:45,040
that are in input to what we do. There's going to be what the UN calls estimates,

8
00:00:45,680 --> 00:00:51,280
which are estimates of the population at a point in the past and there's going to be

9
00:00:51,280 --> 00:00:55,760
projections which are forecasts about what the population might be for given year.

10
00:00:57,120 --> 00:01:02,000
Furthermore, the UN's going to provide us with a few different forecasts using some different

11
00:01:02,000 --> 00:01:07,760
modeling assumptions. And so under projections there will be three potential population models.

12
00:01:08,240 --> 00:01:12,480
We'll have low variant which is going to assume a low fertility,

13
00:01:13,360 --> 00:01:18,880
medium variant which assumes medium fertility and high variant which assumes high fertility.

14
00:01:19,280 --> 00:01:30,320
So let's go ahead and load the data. So what we do in this first code cell is the data is going to

15
00:01:30,320 --> 00:01:38,080
be stored at this URL. And we're going to use the URL joint to make sure this is joined appropriately.

16
00:01:40,320 --> 00:01:44,000
We also probably could have just added these strings together but this is just to be safe.

17
00:01:44,000 --> 00:01:52,480
And so what that gives us is it gives us this URL. And so if we were to click this URL,

18
00:01:52,480 --> 00:01:59,520
it should take us to this Excel file. And so now what we're going to do is we're going to read

19
00:01:59,520 --> 00:02:03,920
a subset of the columns in particular. We're interested in the column of variant.

20
00:02:05,120 --> 00:02:12,320
Regents sub-region country or area country code type reference date. And then there's going to be

21
00:02:12,320 --> 00:02:21,600
a bunch of columns that are things like 0 to 4, 5 to 9, etc. all the way up to 100 plus.

22
00:02:22,160 --> 00:02:25,680
And so we're going to create these and just this little list comprehension.

23
00:02:26,240 --> 00:02:29,920
And then we're going to add these columns to the columns we've already written now.

24
00:02:31,680 --> 00:02:37,520
Once we've done that, we'll use pandas read Excel function and we're going to read a URL

25
00:02:37,600 --> 00:02:46,080
which is the URL we created above. And then we're going to read four sheets from this Excel file.

26
00:02:46,080 --> 00:02:50,720
We're going to read the estimates, the low variant, the median variant and the high variant.

27
00:02:51,600 --> 00:02:58,160
At the top of the top of the Excel file, there's 16 rows of kind of garbage, just

28
00:02:59,360 --> 00:03:05,120
citations or notations. So we're going to skip those rows. We're only going to select

29
00:03:05,200 --> 00:03:12,720
the subset of rows to work with. And then anything that is a dot dot dot is going to get read in

30
00:03:12,720 --> 00:03:19,280
as a missing value. And what this will do is if you read in one sheet, it gives you back a data frame.

31
00:03:20,080 --> 00:03:25,280
But if you read in multiple sheets by passing in a list, it gives you back a dictionary. So it's

32
00:03:25,280 --> 00:03:32,480
going to give us a dictionary with the keys, estimates, low variant, median variant and high variant.

33
00:03:32,480 --> 00:03:40,400
And so all we're going to do is go ahead and unpack these. And then we're going to stack these

34
00:03:40,400 --> 00:03:45,280
data frames, one on top of another. So remember, can cat take the data frames and just

35
00:03:46,320 --> 00:03:51,520
puts them together. There's kind of no clever merging back and forth. It's just literally going to

36
00:03:51,520 --> 00:03:57,280
stack them. And we're going to do this axis equals zero, which is going to be one on top of another.

37
00:03:57,280 --> 00:04:05,200
And we're going to ignore the index. So this will take a minute. The data sets about 10 megabytes.

38
00:04:06,400 --> 00:04:13,120
So, which isn't that big. It just sometimes takes a minute for the server. Okay, perfect. So

39
00:04:14,240 --> 00:04:19,600
now we've read in our data. So what does it look like? So because we specified which columns we

40
00:04:19,600 --> 00:04:24,240
were going to read in, you should already have an idea of what the columns are going to be.

41
00:04:24,960 --> 00:04:32,080
So variant, we can now see is going to specify estimates. Or if we look at the tail,

42
00:04:32,080 --> 00:04:37,600
we can notice it's going to have high variant. So the variant is going to tell us whether the data

43
00:04:37,600 --> 00:04:43,600
in this row is an estimate that's coming from kind of previous data or whether it's a forecast

44
00:04:43,600 --> 00:04:49,760
of what could happen in the future. The region sub-region country or area is going to tell us

45
00:04:50,400 --> 00:04:57,360
what region we're working with. So at the top it says world. So these are world population estimates.

46
00:04:57,920 --> 00:05:03,840
And at the bottom we have United States of America. And so we could also kind of infer that somewhere

47
00:05:03,840 --> 00:05:10,560
in between some of these countries will, the countries will be named. Country code is going to

48
00:05:10,560 --> 00:05:16,160
use the, what they call the alpha three standard, which is just, there's a three digit country,

49
00:05:16,240 --> 00:05:22,080
there's a three digit code for each country in the world. And this is just a standardized notation.

50
00:05:23,600 --> 00:05:28,640
Type is going to tell us what kind of data point it is. So again, if we look at the bottom,

51
00:05:29,520 --> 00:05:34,960
anytime it has a country's name, it's going to call it a country slash area.

52
00:05:37,280 --> 00:05:43,920
Reference date is going to give us a year and we've specified that this, the population is an estimate

53
00:05:43,920 --> 00:05:52,720
as of July 1. So here this row would read the population for the entire world, which is country

54
00:05:52,720 --> 00:06:03,360
code 900, on 1st of July 1950 was X. And then there's all of these columns that denote the age

55
00:06:03,360 --> 00:06:11,520
brackets of the different individuals. So we have, and these are in thousands of people. So the

56
00:06:11,520 --> 00:06:25,760
world in 1950, July 1st had 338,496,000 of people. So that's really 338,5 million, 0 to 4

57
00:06:25,760 --> 00:06:36,320
year olds. Okay, so let's check the shape of the data and what types are in it to make sure

58
00:06:36,400 --> 00:06:42,720
everything is what we expect. So there's the 26 columns and we've kind of visually inspected these,

59
00:06:42,720 --> 00:06:51,760
they're approximate, they're what we expect. And the details are going to be, this is an object,

60
00:06:51,760 --> 00:06:59,280
so strings, also strings, this is an integer, that's good. The type is a string again,

61
00:07:00,080 --> 00:07:06,160
and then the year comes in as an integer, that's good and all of these numbers are floating point.

62
00:07:06,960 --> 00:07:13,600
So that looks good. So our data is clean enough and now we kind of know what's in it.

63
00:07:15,200 --> 00:07:22,000
So the next step is kind of let's start cleaning the data. Let's put the data in a format in which we

64
00:07:22,000 --> 00:07:28,000
would be able to use it to answer some questions. So remember, this is what our data starts like.

65
00:07:28,800 --> 00:07:34,480
And so the first thing we're going to do is kind of any of the questions that we're asking today,

66
00:07:35,360 --> 00:07:40,800
I'm going to focus on just country data. So they have things like, so if we came in here,

67
00:07:40,800 --> 00:07:53,200
we could do DF type.unique. And what this will tell us is each of the different values that type

68
00:07:53,280 --> 00:07:59,360
could have taken. So we could ask for anywhere where type was equal to

69
00:08:01,760 --> 00:08:14,560
region. Oh, there we go. And so if this is going to say, is this going to say things like

70
00:08:15,360 --> 00:08:21,920
this region is Africa, and so what's the population of Africa as a whole or OSEAN as a whole?

71
00:08:22,640 --> 00:08:29,520
Um, etc. And so I think we've seen this in the past, but if not, just a quick reminder,

72
00:08:30,160 --> 00:08:38,480
query is a way that we can apply filters to the data. So this would be equivalent to writing

73
00:08:38,480 --> 00:08:51,840
DF.lock, DF type equal equals region and all columns. So you'll notice that we're getting

74
00:08:51,840 --> 00:09:01,440
truths everywhere. We could kind of up the ante and check for all.all. And this tells us every value

75
00:09:01,440 --> 00:09:09,040
is equivalent to one to another. So yeah, so the query is just a short hand notation and it does

76
00:09:09,040 --> 00:09:15,920
some things that make it a little faster like not creating copies of the data frame, but it's just a

77
00:09:15,920 --> 00:09:23,760
faster way to do Boolean selection. Okay, so like I said, we're going to focus on country data

78
00:09:23,760 --> 00:09:29,200
rather than looking at kind of regions or you know, high development, low development, any of the

79
00:09:29,200 --> 00:09:38,800
other classifications that the UN or any of the other world organizations uses. Okay, so here's our data.

80
00:09:38,800 --> 00:09:45,840
We notice now the heads starts at the index of 390 because it's eliminated the first 300

81
00:09:45,840 --> 00:09:56,800
and 89 rows and it only has country data now. Okay, so if you look at this data frame and you're

82
00:09:56,800 --> 00:10:02,960
trying to kind of combine this data or reshape this data, you'll run into a bit of a headache that

83
00:10:03,360 --> 00:10:10,080
the column names aren't necessarily in the best format. They're not easily typeable or easily usable.

84
00:10:10,960 --> 00:10:17,360
So what we're going to do is we're going to kind of use common naming conventions for our

85
00:10:17,360 --> 00:10:23,040
pandas columns and we're going to rename the data that's been in, that's been ingested from the UN.

86
00:10:24,000 --> 00:10:30,640
So some kind of naming tips is typically you want to name your column something short and memorable

87
00:10:33,200 --> 00:10:36,800
and there's kind of standard conventions about how to do this. You want,

88
00:10:37,760 --> 00:10:42,320
so I typically like, I won't say that this is kind of a world standard, but I like my

89
00:10:42,800 --> 00:10:49,520
data frame columns to be named with lowercase letters and then when there's multiple words,

90
00:10:49,520 --> 00:10:56,160
I want to include in a single name. You use underscores. So if this was going to be something like

91
00:10:56,160 --> 00:11:04,080
variant type, I might have added an underscore to separate variant and type. But kind of beyond any

92
00:11:04,080 --> 00:11:10,880
other conventions, it's most important that you're internally consistent. So choose whatever

93
00:11:10,880 --> 00:11:17,760
conventions you want but make sure that you follow them. So what we're going to do is we're going to

94
00:11:17,760 --> 00:11:26,160
rename our columns and the input to rename is a dictionary and it's going to take a dictionary with

95
00:11:26,160 --> 00:11:33,040
keys that are the current column names and values that are the column names that you'd like to replace

96
00:11:33,040 --> 00:11:39,120
it with. And once we've renamed all of our columns, we're going to go ahead and drop the column

97
00:11:39,120 --> 00:11:46,800
type from the data frame because we've already limited it to only having one type. So it only has

98
00:11:46,800 --> 00:11:55,040
country slash area information and none of the sub regions. Okay, and so you can see that we've now

99
00:11:55,040 --> 00:12:00,880
renamed our columns. So we left the age brackets the same. Those are kind of easy enough to work with.

100
00:12:01,840 --> 00:12:09,040
Variant and country. So variant was made lower case. All of this information about this was

101
00:12:09,040 --> 00:12:14,480
condensed into the word country because we're only working with country data. We've converted

102
00:12:14,480 --> 00:12:22,320
the word country code into alpha 3 because they're the alpha 3 country codes. And then reference date

103
00:12:22,320 --> 00:12:35,360
as of July has been converted into year. So now the data has one column for each age group.

104
00:12:36,080 --> 00:12:42,880
Kind of if you remember what we talked about in terms of tidy is you want to kind of want the data

105
00:12:42,880 --> 00:12:50,720
to be tall. You want each column to be a variable. And in this in some ways I guess the interpretation

106
00:12:50,880 --> 00:13:00,000
of our data is that a variable that the variable we're working with is population. And these things

107
00:13:00,000 --> 00:13:06,160
zero to four are more identifiers for the variable rather than their own variables. And so what we're

108
00:13:06,160 --> 00:13:12,720
going to do is we're going to move our data from a wide form to long form to make it more tidy than

109
00:13:12,720 --> 00:13:18,240
what we have right now. And if you remember we could do this with dataframe.milth.

110
00:13:19,200 --> 00:13:32,560
So melt is going to move data from is going to change this into a dataframe that has

111
00:13:33,200 --> 00:13:41,600
the columns variant country alpha 3 year. It will have a new column that has these values in it.

112
00:13:42,560 --> 00:13:47,200
And then it will have a final column called values that will have the actual values. So

113
00:13:47,680 --> 00:13:55,520
a row of this dataframe will be estimates for Burundi which is country code 108 in the year

114
00:13:55,520 --> 00:14:07,040
1950 for the age group 04 has the value 377,000. Okay, so let's go ahead and run that code.

115
00:14:08,080 --> 00:14:15,520
And just like we said one row is now an identifier which contains the information about the variant,

116
00:14:15,600 --> 00:14:21,120
the country, the alpha 3 code which is equivalent to two countries. So we could have potentially

117
00:14:21,120 --> 00:14:28,160
dropped one or the other the year and then what age group are focusing on and what value that age

118
00:14:28,160 --> 00:14:36,000
group had. So this melt function I'm a big fan you'll you'll often use it when you're trying to

119
00:14:36,000 --> 00:14:45,440
tidy up your data. Okay, and so then towards the end of what we're going to do in class

120
00:14:45,840 --> 00:14:53,760
we're going to focus on countries that had more than 50 million people in the years 2010, 2015 and 2020.

121
00:14:54,480 --> 00:15:01,440
So if a country kind of 50 million people in 2020 they will not be included in our data set.

122
00:15:02,480 --> 00:15:07,440
And so the way we're going to do this is we're going to use a pivot table to determine how many

123
00:15:07,440 --> 00:15:12,720
people were in each country during each year and then we're going to do some Boolean selection.

124
00:15:13,680 --> 00:15:22,880
So you'll notice we're only going to look at the estimates data because 2010, 2015 and 2020,

125
00:15:22,880 --> 00:15:29,920
our years that we already have data for. Then we're going to put country names on the index.

126
00:15:29,920 --> 00:15:38,640
So we're going to have countries running down the index. There's going to be the years

127
00:15:39,440 --> 00:15:47,840
across the columns and then in each value we want to put the total population of that country in that

128
00:15:47,840 --> 00:15:54,320
particular year. And so what we're going to do is remember the default aggregator function is taking the

129
00:15:54,320 --> 00:16:00,720
mean, but what are going to be the values that go in each of these? It's going to be each of the age groups.

130
00:16:00,720 --> 00:16:08,000
And so what we want to do is we want to sum up over all of the age groups, which has the data stored in

131
00:16:08,000 --> 00:16:17,200
value. Okay, so that's going to give us our population sizes. And let's go ahead and look what

132
00:16:17,920 --> 00:16:25,360
look at what that looks like. Okay, perfect. So we can see we have years running along the columns

133
00:16:25,360 --> 00:16:32,080
and we have countries running along the index. And we have this number right here. How could we check

134
00:16:32,160 --> 00:16:41,600
that number? As we could go back and we could say DF.Query country is equal to Albania, for example,

135
00:16:43,760 --> 00:17:00,720
and we want to look at just, um, and let's say and year is equal to 1950. And so this should only give

136
00:17:00,720 --> 00:17:12,160
us, you know, 15 or 20 rows. Okay, so we have all of these values to notice there for these age

137
00:17:12,160 --> 00:17:20,560
columns. And now if we took this sum, it should give us the same value. We only want to sum the

138
00:17:22,480 --> 00:17:28,880
values column because everything else is meaningless. And let's make sure we're displaying

139
00:17:29,600 --> 00:17:40,720
this. Okay, so the population in 1950 of Algeria was 1,263,000, according to our pivot table.

140
00:17:41,680 --> 00:17:50,400
And if we do the only get the data from Albania in 1950 and take that sum, we confirm that it's

141
00:17:50,400 --> 00:17:59,520
1,263,000. Okay, so it looks like our pivot table is doing what we would expect. And so now we need

142
00:17:59,520 --> 00:18:07,760
to find a way to only use countries that have more than 50 million people. And the way we can do that

143
00:18:07,760 --> 00:18:14,480
is just create some kind of a Boolean selector. So we're going to do population sizes, which is

144
00:18:14,480 --> 00:18:20,480
this data frame here. We're going to look at all of the countries and we're going to look at the

145
00:18:20,480 --> 00:18:28,880
years 2010 to 2020. It only, they only have population data every five years, so this is going to

146
00:18:28,880 --> 00:18:34,240
work, but if we wanted to be explicit about what years we also could have passed in a list. And we're

147
00:18:34,240 --> 00:18:42,800
going to check whether those values are greater than 50,000, which is 50 million because the

148
00:18:42,880 --> 00:18:48,640
population data is reported in thousands. And then we're going to ask whether all of those values

149
00:18:49,200 --> 00:18:55,440
were true. And that's going to give us some Boolean's. And then we're going to look at the

150
00:18:55,440 --> 00:19:03,600
index and we're only going to take the true values. And we're going to put that into a list.

151
00:19:05,520 --> 00:19:11,280
And if that's going to give us countries population greater than 50 million, which is just this

152
00:19:11,360 --> 00:19:17,760
list of countries. So Bangladesh, Brazil, China, Democratic Republic of Congo, dot dot dot.

153
00:19:19,040 --> 00:19:25,040
So if you kind of look through this list of countries, you're not surprised that these countries

154
00:19:25,040 --> 00:19:32,320
have 50 million people. Okay, great. So now if we wanted to just have a data frame with the

155
00:19:32,320 --> 00:19:38,240
countries that have greater than 50 million people, we could just do DF dot query. So we're going to

156
00:19:38,320 --> 00:19:47,920
query again. And we're going to ask whether country is in this list. And so this app is kind of magic,

157
00:19:47,920 --> 00:19:53,120
is that it allows you to pass a variable. So we've created this variable right here.

158
00:19:54,160 --> 00:19:59,600
And the at sign tells it that we're not expecting this to be a column name or anything else. But

159
00:19:59,600 --> 00:20:07,680
rather this is a variable that's defined in the scope of what this query call should be able to see.

160
00:20:07,680 --> 00:20:12,960
So because we've already defined this, it will know how to hunt that down. So if we delete it,

161
00:20:12,960 --> 00:20:20,000
it'll give us an error. But once we put at it knows to go get this. And if you looked at the

162
00:20:23,840 --> 00:20:32,000
country dot unique, you'd kind of line up that these are the same countries that we just saw in that other

163
00:20:32,000 --> 00:20:43,280
list. Great. So later on, we'll use this data set of using just the countries with greater than 50 million

164
00:20:43,280 --> 00:20:51,600
people. Excellent. So let's start exploring our data. This is kind of the fun part. So we've done some cleaning

165
00:20:53,440 --> 00:20:58,560
and so I have a confession. You know, the cleaning always looks better when you're presenting

166
00:20:58,560 --> 00:21:03,120
it to someone else. Really kind of these last 15 minutes that I've been talking,

167
00:21:03,840 --> 00:21:08,880
probably took me, you know, four or five times as long to do on my own just because there's a lot of

168
00:21:08,880 --> 00:21:14,160
trial and error. And so this is the same way as when you read kind of an academic paper,

169
00:21:14,800 --> 00:21:21,280
it looks beautiful, it looks polished. But that's because someone has taken the effort to clean it up

170
00:21:21,280 --> 00:21:28,320
and to make it nice and it will automatically make sense. And so it takes practice to develop this

171
00:21:28,640 --> 00:21:35,200
skill. So it really is if you find chances to work with data, we highly encourage you to do it

172
00:21:35,200 --> 00:21:42,720
because cleaning the data is going to be a skill that's acquired through practice, not just by watching

173
00:21:44,480 --> 00:21:49,680
kind of data science and statistics and economics are all very much hands on learning.

174
00:21:50,320 --> 00:21:57,520
Okay. So you know, slash end rant, we'll go on and start looking at some visualizations.

175
00:21:59,200 --> 00:22:05,360
Okay. So one of the things that I kind of hinted at is that what we're going to be interested in

176
00:22:05,760 --> 00:22:14,160
is looking at the age distribution. And so let's go ahead and look at the age distribution

177
00:22:14,160 --> 00:22:22,880
in China. We're going to use the variant estimates so that we have the old data and then for any

178
00:22:22,880 --> 00:22:29,840
data that's in the future, namely for 2050 and 2080, we're going to get the medium variant.

179
00:22:29,840 --> 00:22:35,600
So this is going to be kind of the the medium version of the population forecasts.

180
00:22:36,880 --> 00:22:42,880
So we're going to find all of the rows that satisfy these criteria.

181
00:22:44,000 --> 00:22:48,160
We're going to do a pivot table and we're going to put the ages down the index

182
00:22:49,040 --> 00:22:54,320
and then on the columns we're going to put the different years and values and to value.

183
00:22:56,160 --> 00:23:06,480
And then we're going to take all of those rows but only the columns 1960 1990 2020, 2050 and 2008.

184
00:23:10,080 --> 00:23:14,720
Okay. So let's see whether that worked. I guess let's uh,

185
00:23:15,440 --> 00:23:28,000
so DF China and it has 1960, 90, 2020, 2050 and 2080 and then the ages down the, down the index.

186
00:23:28,000 --> 00:23:35,760
So, oh. So that's what we wanted. Okay. So let's go ahead and plot this.

187
00:23:35,840 --> 00:23:46,400
So if you take a minute and stare at this graph, there's actually something that's not quite

188
00:23:46,400 --> 00:23:53,440
right. And I'll give you a second, just stare for a minute and there should be a couple of things that

189
00:23:54,000 --> 00:24:01,760
that look funny to you and you're you're not sure why. But once you do notice it, it will become obvious.

190
00:24:02,240 --> 00:24:14,640
So what's happened is that if you look at the x-axis of our bar chart, the ages have gotten out of order.

191
00:24:14,640 --> 00:24:22,000
So because we have a number dash, another number, this hat to be stored in a string. So we ended up with the

192
00:24:22,000 --> 00:24:30,560
ages 0 to 4, then 10 to 14. So something's missing there. So 5 to 9. Oh, and got put over here.

193
00:24:31,760 --> 00:24:41,840
And then 100 plus which should be at the end. And then I actually think everything else is in order.

194
00:24:41,840 --> 00:24:49,520
So there's just a few that are out of order. So how can we get these back in order? Well,

195
00:24:50,480 --> 00:24:55,680
we can just kind of directly pass an order. So if you remember when we constructed the eight columns,

196
00:24:55,680 --> 00:25:02,880
we constructed the them in order using a list comprehension. And so let's just remake this chart and

197
00:25:03,760 --> 00:25:11,360
look at this. So this should look much better. So what do we have now on the y-axis, which should be the same

198
00:25:11,440 --> 00:25:23,920
for each chart. We have the thousands of people running up and down the y-axis. So what this says is that

199
00:25:23,920 --> 00:25:34,320
in 1960, there were almost 100 million, 100 million people in China aged 0 to 4.

200
00:25:34,640 --> 00:25:45,600
And there were approximately 50 million. We'll call this one the 50 million bar of age 30 to 34.

201
00:25:47,360 --> 00:25:56,960
And so what we can see is that over time, and this is probably not a surprising or new fact to you,

202
00:25:57,520 --> 00:26:02,560
the population in China has aged. So in the kind of the 60s and 90s,

203
00:26:03,200 --> 00:26:08,880
there was a very young population. You see this population kind of in 2020 and 2050,

204
00:26:09,760 --> 00:26:17,120
advance into their middle aged. And then in 2050 and especially in 2080, you see this population

205
00:26:17,120 --> 00:26:25,280
retire and then potentially die off. And so the other thing you notice is that as these people

206
00:26:25,360 --> 00:26:31,920
have died off, there have been less births. And we'll talk about why something like that might be

207
00:26:31,920 --> 00:26:42,800
important next. So but rather than kind of seeing total population, we might just be interested in

208
00:26:42,800 --> 00:26:48,720
seeing the fraction of the population in each age group. So we've done kind of a lot here.

209
00:26:48,720 --> 00:26:55,200
So let's go ahead and walk through it. So we've taken our data frame and we've divided by

210
00:26:55,360 --> 00:27:03,920
the entire sum of the population. So first we sum this gives us the total population in each year.

211
00:27:04,720 --> 00:27:11,040
And then we're going to take that and we're going to divide along the rows to tell you kind of

212
00:27:11,680 --> 00:27:17,760
what fraction of the population in 1950 was aged 0 to 4, etc.

213
00:27:18,320 --> 00:27:23,600
Okay, so then we're going to look at the age call. So we need to put them in order.

214
00:27:24,480 --> 00:27:29,680
And then we're going to do this same plot command. We've added a few more arguments. So in

215
00:27:29,680 --> 00:27:37,920
particular, we're only going to look at kind of 0 to 0.2 on the y-axis. And we've added a title,

216
00:27:37,920 --> 00:27:44,880
which is population share by age bracket. And then so when you do a plot command in pandas,

217
00:27:44,880 --> 00:27:53,520
it returns either in matte plot lib access or an array of them. So because we chose to do subplots

218
00:27:53,520 --> 00:28:02,320
equals true, it created one plot per year. And so what we're going to do is figure out what was the

219
00:28:02,320 --> 00:28:11,760
population in that year in millions. For each age group. Yes, sorry total. What was the total

220
00:28:12,320 --> 00:28:18,560
population? Then we're going to add another title. And that title is going to have the year,

221
00:28:18,560 --> 00:28:26,720
which is what we get from dfchina.collumslmthi. And then we're going to also put in the population.

222
00:28:27,600 --> 00:28:37,200
And this colon period 2f is kind of a string formatting syntax that adds two decimal places. So

223
00:28:37,200 --> 00:28:44,000
you'll notice this is 660.41. If we changed this to 4, these decimal places would have

224
00:28:44,000 --> 00:28:51,440
4 numbers instead. So 0.4081. There's a few different things that you can do with string with kind

225
00:28:51,440 --> 00:28:58,960
of number formatting and strings. If you type up Python string number formatting, you can read all about it.

226
00:28:59,920 --> 00:29:05,600
For some reason, when I was setting the title, it was getting confused. So first, I set the title to

227
00:29:05,600 --> 00:29:13,440
nothing. And then I set the title to this string, which has the year and what the population was in

228
00:29:13,440 --> 00:29:20,640
that year. And I want it to be lined up on the right. And then I'm going to get rid of the spines

229
00:29:20,640 --> 00:29:26,640
on the right and top axis just because I think it looks better. And then this title layout when you

230
00:29:26,640 --> 00:29:31,840
have a lot of data like this, sometimes the graphs overlap. And so title layout makes sure that they

231
00:29:32,000 --> 00:29:38,960
don't overlap. But now we have kind of the same graph as we had before, except things are expressed

232
00:29:38,960 --> 00:29:46,960
in population shares. And we can see what the total population was in each year. And so in 2020,

233
00:29:46,960 --> 00:29:54,240
there were one and a half billion people living in China. And in 2050, they expected that to

234
00:29:54,240 --> 00:30:03,200
be slightly lower. And then they expected to be even lower in 2080. So what if we wanted to make this

235
00:30:03,200 --> 00:30:11,840
graph for other countries? Or for other variants? We could potentially copy and paste this code from

236
00:30:11,840 --> 00:30:17,440
right here. But when you do that, there's a really good chance that you start making errors.

237
00:30:18,720 --> 00:30:24,160
One of the stories I like to tell is when I was replicating a paper during the second

238
00:30:24,160 --> 00:30:31,280
year of my PhD. I found a paper where the authors had written a utility function and had clearly copied

239
00:30:31,280 --> 00:30:36,560
and pasted it to a bunch of other places. But because of this, they had missed copy and pastes in the

240
00:30:36,560 --> 00:30:42,240
future as they changed it. And so there were at least three variations of their utility function.

241
00:30:43,680 --> 00:30:50,080
And so because of this, they're again, they weren't big deviations. I doubt it had any effect on

242
00:30:50,080 --> 00:30:57,680
their results. But it could have been a bug that was more malicious than just a small typo.

243
00:30:58,080 --> 00:31:04,320
And so whenever you get a chance to never you're doing something repeatedly, we highly encourage you to

244
00:31:05,360 --> 00:31:11,360
write a function to do it. So let's go ahead and write a function. It's going to take data

245
00:31:12,400 --> 00:31:17,760
which is going to be a data frame, which country we want to write for the years that we want to

246
00:31:17,840 --> 00:31:25,200
plot and then which forecast variant we want to use. And then all of this code is just the same as

247
00:31:25,200 --> 00:31:33,840
before. So we're going to skip it. We're going to look at the 80 90 2000 2020 and 2050 and just

248
00:31:33,840 --> 00:31:41,920
run through some graphs real quick. So here's the age distribution of China. If the model assumes

249
00:31:42,800 --> 00:31:51,360
low fertility. So with low fertility, the age distribution in China gets really old in by the year

250
00:31:51,360 --> 00:31:59,520
2,100 and only has 684 million people rather than more than a billion in 2020.

251
00:32:01,520 --> 00:32:10,560
Here's the graph that we've already seen. So things don't look quite so bad here. You see a larger

252
00:32:10,560 --> 00:32:18,720
population, especially in kind of this 35 to 55, I think. And then if you take the high variant,

253
00:32:18,720 --> 00:32:26,560
which is going to assume a higher fertility, you actually have much less aging in the population.

254
00:32:26,560 --> 00:32:35,040
So you get a relatively stable distribution across the ages with it tapering off at higher ages.

255
00:32:35,360 --> 00:32:43,600
We could do the same thing for India. So the low variant is going to look bad in terms of the age

256
00:32:43,600 --> 00:32:53,920
distribution by 2100 for pretty much any country we do. The medium variant is going to be

257
00:32:54,640 --> 00:33:04,560
less bad and the high variant is going to look. It's actually in some ways looks similar to the

258
00:33:04,640 --> 00:33:16,640
China graph. And then we can also do the United States. What you see is kind of

259
00:33:18,080 --> 00:33:25,600
in both the low variant and the medium variant, we're going to have a relatively aged population.

260
00:33:27,840 --> 00:33:33,760
One of the things that's interesting is that the US sees a much smaller, even percentage-wise,

261
00:33:33,760 --> 00:33:41,040
decrease in the population. And that could be, I don't know exactly why that is. I'd have to see

262
00:33:41,040 --> 00:33:45,200
what their model looks like. So I'm not going to, I'm not going to try and make a guess this.

263
00:33:47,120 --> 00:33:52,160
Okay, so we've made these graphs about the age distribution and kind of played around. So why do we

264
00:33:52,160 --> 00:33:56,960
care about it? I think there's lots of reasons we might care about it, but one reason we should be

265
00:33:56,960 --> 00:34:02,960
particularly concerned is social security programs. So in the US, the way the social security

266
00:34:02,960 --> 00:34:13,200
program is run is when you start working, you pay approximately 15% of your income to a government

267
00:34:13,200 --> 00:34:19,920
savings program they call social security. And when you retire at the age of, right now the retirement

268
00:34:19,920 --> 00:34:27,520
age is 65, you potentially start receiving payments from the government that are kind of

269
00:34:27,520 --> 00:34:34,800
hypothetically this money that you saved with the government. And so kind of, I like to think of

270
00:34:34,800 --> 00:34:40,640
myself as young working age and you certainly, everyone in this class is a young working age.

271
00:34:40,640 --> 00:34:44,880
So you should be really interested in this because there's a lot of countries across the world,

272
00:34:45,520 --> 00:34:50,640
which it's not clear that their social security programs are going to be solvent in

273
00:34:51,360 --> 00:34:56,640
40 years. I'm particularly concerned about this. I think it's very unlikely that the US social

274
00:34:56,720 --> 00:35:04,320
security system stays solvent. And one number that economists and other people use to kind of

275
00:35:04,320 --> 00:35:09,920
think about whether a social security program will be able to sustain itself in the case that

276
00:35:09,920 --> 00:35:14,000
the money that kind of the working people contributed through their lifetimes is gone,

277
00:35:14,560 --> 00:35:19,920
as is the case in the United States, is something they call the dependency ratio. And so the dependency

278
00:35:20,000 --> 00:35:27,040
ratio relates to a number of persons aged 65 or over per 100 persons aged 15 to 64.

279
00:35:27,680 --> 00:35:32,640
So why is this a helpful number? Is this this number tells us roughly how many working

280
00:35:32,640 --> 00:35:39,920
age people there are to support each person who has stopped working? So as the population distribution

281
00:35:39,920 --> 00:35:45,760
shifts to the right, which we kind of saw in a lot of the previous graphs, then there's going to

282
00:35:45,760 --> 00:35:50,240
be fewer individuals that are currently paying into social security programs that

283
00:35:51,120 --> 00:35:57,840
these social security programs are supposed to be making payments to the old who made payments to

284
00:35:57,840 --> 00:36:05,600
these programs while they were working age. So we're going to compute this age dependency ratio

285
00:36:06,240 --> 00:36:11,520
and we're going to do this by figuring out with two list comprehension. So this first one is going to

286
00:36:11,520 --> 00:36:18,240
give us all of the five times I to five times I plus four. So these are the age brackets.

287
00:36:19,040 --> 00:36:26,960
If the age is greater than 15 and less than 65 and then we're going to do the same thing if the

288
00:36:26,960 --> 00:36:33,600
age is greater than 65 and we're going to add the 100 plus category to the old age list.

289
00:36:35,280 --> 00:36:41,440
And so what we're going to do now is first we're going to create a column called age classification

290
00:36:42,400 --> 00:36:48,240
and we're going to assign the value young to every value in this age classification column.

291
00:36:49,760 --> 00:36:56,160
Next we're going to figure out whether the age bracket is in this list working age and that's

292
00:36:56,160 --> 00:37:04,960
going to give us a Boolean and everywhere that that Boolean is true we're going to give it work.

293
00:37:05,520 --> 00:37:13,440
And so if the age is 0 to 4 it will be false that person would still have a young.

294
00:37:13,440 --> 00:37:22,960
If that is 20 to 24 now that falls into our working age category and so the person is put as work

295
00:37:22,960 --> 00:37:29,920
and we'll do the same thing for old age. And so then we're going to so we're working with the

296
00:37:29,920 --> 00:37:35,600
medium variant of the four casts. We're going to pivot table and put the country in a year on the

297
00:37:35,600 --> 00:37:42,480
index and across the columns we're going to put the age classifications and in values we'll put value

298
00:37:42,480 --> 00:37:48,720
again and we're going to call this data frame dr for dependency ratio and then we're going to compute

299
00:37:48,720 --> 00:37:56,560
the dependency ratio which the way the UN defines it is 100 times the number of old divided by the

300
00:37:56,560 --> 00:38:03,680
number of working age and once we've done that we're going to save this back into the data frame

301
00:38:03,680 --> 00:38:09,920
dependency ratio we're only going to select that column and then we're going to unstack the level

302
00:38:09,920 --> 00:38:17,600
country so now we'll have year on the index and country across the columns and so let's see whether

303
00:38:18,560 --> 00:38:26,960
that works. If you get errors like this there is a reason that they give them to you

304
00:38:27,520 --> 00:38:33,120
but sometimes you get false warnings and so in this case we're getting a false warning.

305
00:38:37,600 --> 00:38:46,160
Okay so like I said we have the year on the index and we have the country names on the columns

306
00:38:46,960 --> 00:38:51,680
and then these values are actually the dependency ratios that we just talked about

307
00:38:54,240 --> 00:39:03,040
and so just this kind of a matter of benchmark a zero dependency ratio would mean that you have no

308
00:39:03,040 --> 00:39:10,640
old people to support and age dependency ratio of 50 means that you have two working people for every

309
00:39:10,640 --> 00:39:20,400
old person and then an age dependency ratio of 100 would mean that you have one working person

310
00:39:20,400 --> 00:39:28,000
for every old person and it can be over 100 but that just means you have more old people than working

311
00:39:28,000 --> 00:39:36,720
people. Okay so this next computation is obviously going to be wrong and the reason it's going to

312
00:39:36,800 --> 00:39:43,920
be wrong is because as the country ran into a crisis such as the one they might that we've kind of

313
00:39:43,920 --> 00:39:49,920
discussed is they would obviously increase their retirement age or there's other things that they could

314
00:39:49,920 --> 00:39:55,760
do but just as a thought experiment let's suppose that the dependency ratio that sustainable long term

315
00:39:56,400 --> 00:40:02,640
is 50 and so what this means is that there's going to be two workers for each person over 65 so

316
00:40:02,960 --> 00:40:07,680
of our countries with 50 million citizens how many of these countries are going to be sustainable

317
00:40:07,680 --> 00:40:17,920
in 2080 or 2100 and I think kind of this plot tells us a lot so this dotted line is our 50

318
00:40:19,120 --> 00:40:25,280
and you see kind of a lot of countries that kind of so you've seen this happening between

319
00:40:25,280 --> 00:40:32,800
2000 and 2020 we've got kind of four or five countries that had a very quick run from the 20 to 30 range

320
00:40:34,800 --> 00:40:41,280
to 80 90 and you see a bunch of countries that have just done it in kind of

321
00:40:42,240 --> 00:40:48,400
who are starting down that same path and could potentially cross over 50 from 2020 to 2040

322
00:40:49,600 --> 00:40:55,040
and then there's some other countries that are well below and so what are these countries?

323
00:40:55,040 --> 00:40:59,280
So let's go ahead and look at the number of years or in the index so we're going to look at

324
00:40:59,280 --> 00:41:04,160
2080 and all of the countries and let's see which of the countries have less than 50.

325
00:41:05,440 --> 00:41:15,680
So the Democratic Republic of Congo Egypt Ethiopia India South Africa Russia Indonesia the Philippines

326
00:41:16,880 --> 00:41:24,000
so these are all countries that have low age dependency ratios and 2100

327
00:41:25,120 --> 00:41:33,200
it's an even smaller list and Ethiopia the Democratic Republic of Congo and South Africa are still on it

328
00:41:33,200 --> 00:41:39,280
but kind of some of these other countries in India and Russia in particular and Indonesia have fallen off of this list

329
00:41:40,240 --> 00:41:46,320
so I don't know what to say about this other than if you believe this is kind of a good benchmark

330
00:41:46,320 --> 00:41:54,240
of a Solvitz social security program then you may want to go to one of these countries on these lists

331
00:41:54,320 --> 00:41:58,400
obviously there are other considerations that you would want to take into account that

332
00:41:58,400 --> 00:42:04,320
you know maybe these countries don't make your list but it's at least kind of hypothetical exercise

333
00:42:04,320 --> 00:42:11,120
this was actually something our friend Dave Baccus was really interested in five six years ago

334
00:42:11,840 --> 00:42:16,640
and he's been there and I had started working on a paper on this at one point but

335
00:42:17,680 --> 00:42:23,600
it never got finished but hopefully this has been a chance to we think this is a fun example

336
00:42:23,680 --> 00:42:27,840
hopefully this was a chance to refresh you on some of the pandas topics that we've covered

337
00:42:28,560 --> 00:42:34,880
especially the reshaping because we can't emphasize this enough reshaping and cleaning

338
00:42:34,880 --> 00:42:39,920
are things that you'll only learn to do by doing them yourself so hopefully this gives you a

339
00:42:39,920 --> 00:42:46,960
playground and some data where you can start trying to do the same so that's everything I have bye bye

