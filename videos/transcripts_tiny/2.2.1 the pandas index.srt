1
00:00:00,000 --> 00:00:10,000
Hello, this is Spencer Lyon and today we're going to be continuing to learn more about data analysis in Python using the Pandas library.

2
00:00:10,000 --> 00:00:15,000
And today we're going to focus on understanding the index.

3
00:00:15,000 --> 00:00:26,000
Our goals for today will be to understand how we can use the index to make sure that observations and data points are aligned when we do certain operations.

4
00:00:27,000 --> 00:00:34,000
We'll learn how we can set the index to something different as well as reset it to get back where we started.

5
00:00:34,000 --> 00:00:47,000
We'll take a closer look at how we can select subsets of the data by slicing and extracting values according to the index or row labels as well as the column labels.

6
00:00:47,000 --> 00:00:57,000
And finally we'll point out that for a data frame the column names are also used to align data and this will become very clear shortly.

7
00:01:01,000 --> 00:01:12,000
Our outline for today will be to do a high level overview of what the index is and talk about how we can set reset the index will have some examples throughout.

8
00:01:12,000 --> 00:01:23,000
And we'll have a few words of advice for how you should choose which columns or which variables go on the index and we'll finish with some exercises.

9
00:01:23,000 --> 00:01:35,000
We'll start by importing pandas as pd and numpy as np like we normally do so that we're prepared to use those libraries going forward.

10
00:01:35,000 --> 00:01:48,000
So let's take a step back and try to understand what the index is as we've told you before and as we've become a little familiar with every series and data frame has an index.

11
00:01:48,000 --> 00:02:02,000
And we have been referring to those as the row labels for the data we didn't lie this is still true, but the index in pandas is a lot more powerful and meaningful and just labeling the rows.

12
00:02:02,000 --> 00:02:14,000
And the purpose of our lecture today will be to help us understand these other properties and behaviors of the index for a series or data frame.

13
00:02:14,000 --> 00:02:27,000
So the pandas documentation reads that data alignment is intrinsic the link between labels and data will not be broken on this dense so explicitly by you.

14
00:02:27,000 --> 00:02:37,000
And so in the other words this means that the index and the column names are going to be used to make sure that the data is always properly aligned whenever you're operating on multiple data frames.

15
00:02:37,000 --> 00:02:44,000
This concept of pandas aligning data for us using the index and column names is a little abstract.

16
00:02:44,000 --> 00:02:50,000
So we'll load up some real data that will hopefully help us visualize and understand what's happening.

17
00:02:50,000 --> 00:02:57,000
The data set will be using comes from the World Bank and it is part of their world development indicators data set.

18
00:02:57,000 --> 00:03:11,000
And we have extracted and prepared a subset of that data that includes a few countries over a number of years and then some of the components of the expenditure form of GDP.

19
00:03:11,000 --> 00:03:19,000
So here we have columned country year government expenditure consumption exports imports and GDP.

20
00:03:19,000 --> 00:03:26,000
We'll just show the first few rows so that you can get a sense of what the data looks like.

21
00:03:26,000 --> 00:03:36,000
We'll also want to be able to visualize operation as a whole and to do so we'll want to have some smaller data frames that we can kind of keep track of a little bit easier.

22
00:03:36,000 --> 00:03:46,000
So DF small is just going to be the first five rows of our original data frame and then DF tiny is going to be four of those rows.

23
00:03:47,000 --> 00:04:03,000
But the what the rows will be a little bit out of order. So you'll see here that I selected row zero first and then three two four whereas in DF small it's in the proper order zero one two three four.

24
00:04:03,000 --> 00:04:15,000
Finally we will make another data set where we're going to start with the first five rows from DF small and then we'll only keep the columns imports and exports.

25
00:04:15,000 --> 00:04:28,000
Okay, so now let's take a look at what happens when we try to add the import export data frame to a copy of itself.

26
00:04:28,000 --> 00:04:40,000
If we look back at what we had each of these numbers was less than one it was somewhere between zero point five and one and now all the numbers are between one and two.

27
00:04:40,000 --> 00:05:07,000
What happened was when we asked pandas to add these two data frames it went and it added them element wise it would look up the zero row and import entry of the first data frame and add it to the zero row import column of the second data frame and it did this for each of these ten numbers.

28
00:05:08,000 --> 00:05:20,000
For mind ourselves what the F tiny looks like and relative to just the import export one notice a few things there is not a row labeled one here in DF tiny.

29
00:05:20,000 --> 00:05:33,000
And the rows that do appear zero three two four are not in the same order in the I am the import export data frame they are in numerical sorted order but here in DF tiny they're not.

30
00:05:33,000 --> 00:05:38,000
Also there are extra columns that appear in DF tiny.

31
00:05:39,000 --> 00:05:44,000
That don't appear in the other data frame for example the government expenditure consumption GDP.

32
00:05:45,000 --> 00:05:58,000
And the two columns that do overlap imports and exports are in different order so basically we have similar data in these two data frames but they're definitely not in the same order structure.

33
00:05:59,000 --> 00:06:05,000
Now let's see what happens when we try to add the DF tiny to the import export data frame.

34
00:06:06,000 --> 00:06:16,000
We'll execute this cell and we'll notice that relative to adding the import export data frame to itself things are quite different here in this output.

35
00:06:16,000 --> 00:06:32,000
The first thing to point out which is summarized on the slide following this for reference when you come back to this is that for all entries in this table where the row label or index value.

36
00:06:32,000 --> 00:06:42,000
And the column value appear in both DF tiny and import export the output cell contains the sum of the two numbers.

37
00:06:42,000 --> 00:06:48,000
This is similar to what we saw when we were adding import export data frame to itself.

38
00:06:48,000 --> 00:06:53,000
But now it's surrounded by a bunch of other things.

39
00:06:54,000 --> 00:07:11,000
So this same operation of looking up the row index and the column index for the first data frame and adding that to the exact same rowly index and column index for the second data frame was repeated for all eight of these operations.

40
00:07:12,000 --> 00:07:26,000
And I want to point out that this happened this type of a lining happened even though the rows were in different order from DF tiny and the import export data frame and the columns were in different order.

41
00:07:26,000 --> 00:07:31,000
This is exactly what we mean by pandas aligning the data for us.

42
00:07:31,000 --> 00:07:39,000
It wasn't our job to make sure that the rows were in the same position or order pandas handled that and took care of it for us.

43
00:07:39,000 --> 00:07:43,000
And if you're familiar with spreadsheets, this example might help.

44
00:07:43,000 --> 00:07:49,000
So let's think through how we might do something like this using Excel or a different spreadsheet program.

45
00:07:49,000 --> 00:07:58,000
So first the tiny data frame as well as the import export one would probably be in different sheets of our Excel workbook.

46
00:07:59,000 --> 00:08:06,000
Then the index would be the first row of each sheet and the column names would be the first column.

47
00:08:06,000 --> 00:08:13,000
Oh, sorry, the first row and the index would be the first column, forgive my miss mistake there.

48
00:08:14,000 --> 00:08:25,000
We would need to have a third sheet that can hold the output of our summation operation and then here's the tricky part we populate that third sheet.

49
00:08:25,000 --> 00:08:36,000
By looking at every label in the first column of either the DF tiny sheet or the import export sheet.

50
00:08:37,000 --> 00:08:44,000
Then we'll do an if else to see if the same label appears in the other sheet.

51
00:08:44,000 --> 00:08:49,000
And then we'll need to do a v look up to extract the associated values.

52
00:08:49,000 --> 00:08:52,000
That gave me a headache just thinking through it.

53
00:08:52,000 --> 00:08:56,000
And the nice thing is we'll ever have to think through that again now that we know pandas.

54
00:08:56,000 --> 00:09:09,000
And pandas this all happens for us automatically and behind the scenes and it's extremely efficient it's very well implemented and happens very fast.

55
00:09:09,000 --> 00:09:18,000
So the handling and of the aligning road in columns is one part of this operation, but there's also a second part.

56
00:09:18,000 --> 00:09:35,000
So we'll just hear that every entry in the row label one as well as columns consumption GDP government expenditure country and year have this kind of a two-slicking entry and a n.

57
00:09:35,000 --> 00:09:46,000
This is the computer science speak for not a number and it's how pandas she's just represents missing data.

58
00:09:46,000 --> 00:09:59,000
So the reason why pandas would note that these cells are missing is because when it was trying to look up to the associated value for anything in row one inside of DF tiny it came up empty.

59
00:09:59,000 --> 00:10:05,000
DF tiny does not have a row labeled one that data is missing from the data frame.

60
00:10:05,000 --> 00:10:14,000
Similarly when I was trying to look at any of these other columns that were not import your exports, it couldn't find it in the import export data frame.

61
00:10:14,000 --> 00:10:39,000
So because one half of this plus tradition operation was missing for each of these columns and row one pandas was forced to say that the operation tiny data frame plus import export data frame resulted in not a number or a missing observation for those rows and columns.

62
00:10:39,000 --> 00:10:49,000
We want to give you a chance to understand a little more how pandas will treat missing data by working through this exercise.

63
00:10:49,000 --> 00:10:56,000
I'll pause here for a few seconds and then we can look at it together.

64
00:10:56,000 --> 00:11:00,000
Let's regroup here and take a look at this exercise together.

65
00:11:00,000 --> 00:11:10,000
So let's look at what happens when we do the import export data frame tiny version and ask for the mean.

66
00:11:10,000 --> 00:11:21,000
So what we get here is that for any column that was completely filled with nands, the result of the mean will also be nand.

67
00:11:21,000 --> 00:11:25,000
This happens for everything except imports and exports.

68
00:11:25,000 --> 00:11:32,000
However even though row labeled one had a missing value for exports, and it's still computer the number here.

69
00:11:32,000 --> 00:11:35,000
So let's try to understand what pandas did for us.

70
00:11:35,000 --> 00:11:46,000
So one thing we might look at is what the hint said is what if we look at the sum of that row.

71
00:11:47,000 --> 00:11:51,000
And then we'll also look at.

72
00:11:51,000 --> 00:11:52,000
shape.

73
00:11:52,000 --> 00:12:03,000
So we understand how many rows. So here tells us that the data frame import exports had five rows and seven columns, but when we ask for the mean of exports.

74
00:12:03,000 --> 00:12:07,000
It gives us a number a little bit greater than one.

75
00:12:07,000 --> 00:12:13,000
If we look at the sum here it says that the sum of exports was 4.44.

76
00:12:14,000 --> 00:12:25,000
And if you just do the arithmetic quickly in your head and divide 4.44 divided by five the total number of rows, you would get something less than one because four is less than five.

77
00:12:25,000 --> 00:12:33,000
So what pandas is really doing behind the scenes is it will compute the sum of all non missing data points.

78
00:12:33,000 --> 00:12:36,000
And then divide by the number of non missing data points.

79
00:12:36,000 --> 00:12:43,000
In this case we went from five total rows to only four that had data in them.

80
00:12:43,000 --> 00:12:50,000
So in this case if we divided the 4.44 by four we'd end up with 1.11.

81
00:12:50,000 --> 00:12:56,000
So when pandas is dealing with missing data it almost skips over it as if it doesn't exist.

82
00:12:56,000 --> 00:13:01,000
It doesn't count in the total number of meaningful rows.

83
00:13:01,000 --> 00:13:08,000
It's not included in the additions when you're computing the sum.

84
00:13:08,000 --> 00:13:20,000
We'll see more examples of missing data going forward, but this was just to get you thinking about how pandas may be doing things behind the scenes.

85
00:13:20,000 --> 00:13:27,000
So we've seen how the index can help us align data and do certain operations.

86
00:13:27,000 --> 00:13:34,000
And the next natural step would be okay well what if we need to align based on certain properties or columns of the data.

87
00:13:34,000 --> 00:13:40,000
For example, maybe we would want to be able to align our entries based on the year.

88
00:13:40,000 --> 00:13:52,000
If we wanted to set the year is the index we would call the set index method on our data frame and we can pass it year either as a string or as the only item in a list.

89
00:13:52,000 --> 00:13:59,000
And now is that pandas has gotten rid of the 01234 labels on the left.

90
00:13:59,000 --> 00:14:05,000
And now the row labels are actually coming from the year column.

91
00:14:05,000 --> 00:14:11,000
We can also notice that the printed output looks slightly different than it used to.

92
00:14:11,000 --> 00:14:19,000
Before the year column was right up a little bit higher next to all these other column labels.

93
00:14:19,000 --> 00:14:33,000
Now it's down and a little bit to the left and it may be a little subtle to see on my computer, but if you're able to zoom in on yours, you'll see that the year column now has both numbers indicating that these are labels.

94
00:14:33,000 --> 00:14:48,000
All the cell values in between are all in normal font face whereas the column labels and the row labels are all given a bold font.

95
00:14:48,000 --> 00:14:58,000
So now that we have the year on the index, we can use the dot lock accessor to extract data using values from the index.

96
00:14:58,000 --> 00:15:08,000
For example, we can extract all the data for the year 2010 by doing DF year dot lock 2010.

97
00:15:08,000 --> 00:15:23,000
Notice here that the index value for each of these rows is indeed 2010, but now we have the observation for Canada, Germany, and the United States.

98
00:15:23,000 --> 00:15:37,000
Another thing that we might want to do is be able to compute the difference in the average variable across these countries for the year 2009 with those same values from year 2008.

99
00:15:37,000 --> 00:15:41,000
This would show us the change.

100
00:15:41,000 --> 00:15:53,000
This shows us here that on average when you consider these four countries without any type of waiting, government expenditures went up slightly in 2009 relative to their levels of 2008.

101
00:15:53,000 --> 00:15:59,000
Each of these other variables went down.

102
00:15:59,000 --> 00:16:19,000
As an economist, you might start thinking, well, why would this happen? And if you remember, late 2008 is when the financial crisis or the great recession took place or started where the US housing market and banks started to need a little bit of assistance from the government.

103
00:16:19,000 --> 00:16:27,000
But we quickly entered into a global recession afterwards, which will push the other components of GDP down.

104
00:16:30,000 --> 00:16:46,000
So let's take a step back and we'll notice a few things. After we compute the mean, if you remember, right, we end up with a series whose index, or these labels over here on the left, are the former column names that came from the data frame.

105
00:16:46,000 --> 00:16:51,000
So when we compute just the first half, we'll comment this out so we can take a look.

106
00:16:51,000 --> 00:17:02,000
We'll see here we have a series, all of the names from the former data frame are now on the index. So then when we do the minus on this side,

107
00:17:02,000 --> 00:17:10,000
Pandas is actually going to be doing more data alignment. It's going to be looking for on this term right here that I've highlighted.

108
00:17:11,000 --> 00:17:21,000
The government expenditure column, it will take that term from the first the that row from the first term and subtract that same row from the second term.

109
00:17:21,000 --> 00:17:25,000
And that's how it gave us that 0.03.

110
00:17:25,000 --> 00:17:39,000
Again, this data alignment and the importance of being aware of what is on the index, it will continue to surface over and over again as we work through examples and as you work through other things using Pandas.

111
00:17:41,000 --> 00:17:57,000
So now let's do an exercise or think of an example suppose that somebody came to you knowing that you are a a studio and skill data user and they asked what was the GDP in the United States for 2010.

112
00:17:57,000 --> 00:18:04,000
Well, if we wanted to do that using the DF year data frame that we have here's how we might do it.

113
00:18:04,000 --> 00:18:09,000
So first we'll use the dot lock.

114
00:18:09,000 --> 00:18:20,000
And the first thing we'll do is we'll filter out all of the rows where country is equal to the United States and we'll grab only the GDP column.

115
00:18:20,000 --> 00:18:33,000
Now that that's done and we're left with only observations of US GDP, we'll use dot lock a second time to extract the 2010 value from the index.

116
00:18:33,000 --> 00:18:37,000
And here we can see that in these units it was 14.99.

117
00:18:37,000 --> 00:18:42,000
It's kind of a lot of work to answer a fairly simple question or to get back a single number.

118
00:18:45,000 --> 00:18:53,000
So now suppose that they asked you, well, what about the GDP of Germany or the United Kingdom in 2010.

119
00:18:53,000 --> 00:19:02,000
Again, to answer this question, we might say, okay, let's do a similar operation where we're first going to filter all the rows that belong to either the United Kingdom or Germany.

120
00:19:02,000 --> 00:19:15,000
And then we will extract the using the index, we'll extract just the observations that apply to the year 2010.

121
00:19:15,000 --> 00:19:24,000
If we execute this, what we'll see here is instead of the number we get back a series because we asked for more than one row.

122
00:19:24,000 --> 00:19:29,000
But this time the index has the year 2010 and 2010.

123
00:19:30,000 --> 00:19:37,000
It's somewhat ambiguous if the first row corresponds to the United Kingdom or to Germany.

124
00:19:37,000 --> 00:19:50,000
You might think that the first row, the value equal to 3.41 corresponds to the United Kingdom because that's what came first in our list here.

125
00:19:50,000 --> 00:20:05,000
But it's uncertain if we go back and we check and we get all the data for your 2010, we'll see that it was indeed Germany's GDP, the how to value of 3.41 in 2010, where that of the UK was only 2.45.

126
00:20:05,000 --> 00:20:19,000
So we see here that it was insufficient to only have the year on the index, we needed a little bit more information to answer that question.

127
00:20:19,000 --> 00:20:35,000
Let's drive this point home a little bit further and now suppose that you are asked to use this data set to get an approximation for net exports as well as investment in the year 2009 for these four countries.

128
00:20:35,000 --> 00:20:54,000
And we'll remind you as a buddy in a economist that the expenditure formula for GDP can be written GDP or why, as it's often written in textbooks is equal to consumption plus investment plus government expenditure plus net exports.

129
00:20:54,000 --> 00:21:07,000
We can rearrange this expression, very equation to get an expression for investment which would be GDP minus consumption minus government expenditures and minus net exports.

130
00:21:07,000 --> 00:21:13,000
And we'll just make a note that net exports would be total exports minus total imports.

131
00:21:13,000 --> 00:21:30,000
So now our want again is to compute net exports and investment using the columns of our data frame we can directly compute net exports and then once we have that we can use this expression here to compute investment.

132
00:21:31,000 --> 00:21:43,000
So here we go let's look at just net exports we're going to use this DF year exports minus the DF year imports and we'll look at the first few rows.

133
00:21:43,000 --> 00:22:00,000
The reason I chose 19 was we have 18 years worth of data for each country so I wanted to show you that we went through 2017 back to 2000 for the first country and now we're starting over at 2017.

134
00:22:01,000 --> 00:22:14,000
Now suppose that we had a bug in our code and somehow the rows got out of order for Canada and Germany and their net exports in 2017.

135
00:22:15,000 --> 00:22:29,000
This example is completely contrived as you'll see by the code down here, but if you're having a more complicated problem or more code involved in your analysis this type of issue can become more and more likely.

136
00:22:29,000 --> 00:22:32,000
If you notice that the last row.

137
00:22:33,000 --> 00:22:41,000
Had a 2 0.26 whereas the first one had a minus 0.01 we're just going to swap those two.

138
00:22:41,000 --> 00:22:49,000
So now the last row has a small negative number whereas the first row has a positive 0.26.

139
00:22:49,000 --> 00:22:57,000
So now if we add back in this net exports as a column of the data frame.

140
00:22:57,000 --> 00:23:07,000
We can also add a column for investment by evaluating that expression GDP minus consumption minus government spending minus exports.

141
00:23:08,000 --> 00:23:16,000
Now if we look at this data frame, Panis competes everything without any problems, but.

142
00:23:16,000 --> 00:23:32,000
Because we didn't align our data on both the year and the country, we would have overstated Canada's investment by 281 billion dollars and understated Germany's by the same amount.

143
00:23:33,000 --> 00:23:47,000
So this one small issue led to a quarter of a trillion dollar difference in our statement of Germany versus Canada's GDP or sorry in net investment in the year 2017.

144
00:23:47,000 --> 00:23:59,000
So really to try to make this type of operation easier for us, it would have been nice if pandas were to align both on the year and on the country.

145
00:23:59,000 --> 00:24:17,000
And if you remember, pandas aligns the rows of our data and our operations using the index, so really to get the year and the country to be identifying a single observation, we need to put both year and country on the index.

146
00:24:17,000 --> 00:24:29,000
And that the pandas allow us to do that. And when you have multiple columns in an index, it's known as a hierarchical or multi index.

147
00:24:29,000 --> 00:24:45,000
So there are some situations where this might be necessary. One is when we want to extract data from more than one column and a second is when we need alignment will work through both of these right after this.

148
00:24:46,000 --> 00:24:52,000
So to get started, let's first set the index to be the country and the year.

149
00:24:52,000 --> 00:25:02,000
And once we've done this, you'll notice again that the columns are now just these five components of GDP or the four components plus GDP.

150
00:25:02,000 --> 00:25:14,000
And just below that visually, you'll see that pandas have separated the two levels of our index on the outer or left or first if you read left to right index.

151
00:25:14,000 --> 00:25:17,000
Index, you have the country.

152
00:25:17,000 --> 00:25:32,000
Here we'll see that Canada is the country for the first 18 rows. On the second level of the index, you have the year and this changes from 2017 down to 2000 like it has before.

153
00:25:32,000 --> 00:25:46,000
We'll refer to the country level as either the left level of the index because it appears left of year or as the outer level of the index.

154
00:25:46,000 --> 00:25:57,000
Conversely year would be referred to as the right level or the inner most level.

155
00:25:57,000 --> 00:26:11,000
And we'll see that there are two different frames such as this again pandas documentation and things you may find online if you're looking for help or refer to this either as a multi index or a hierarchical index.

156
00:26:11,000 --> 00:26:18,000
So now we remember when our friend asked us, hey, what was the GDP of the United States in 2010.

157
00:26:18,000 --> 00:26:23,000
So we're going to do this with a little bit easier. What we can do is we can use dot lock.

158
00:26:23,000 --> 00:26:36,000
And then remember how we have country on the left and then the year will pass these as a tuple and then we'll get the GDP column and doing this gives us back that 14.99 number.

159
00:26:36,000 --> 00:26:40,000
We did relatively more work to get earlier.

160
00:26:40,000 --> 00:26:46,000
So correctly answer our friend's follow up question about the GDP of the UK and Germany.

161
00:26:46,000 --> 00:26:57,000
Here what we'll do is we'll have a tuple where the first item, this is where we put the selection for the country, we'll have a list of United Kingdom and Germany.

162
00:26:57,000 --> 00:27:04,000
The second item of our tuple is the year 2010 and then we'll be selecting the GDP column.

163
00:27:04,000 --> 00:27:14,000
When we execute this we get back a series that has these two layers on the index and then this one column representing GDP.

164
00:27:14,000 --> 00:27:23,000
But now it's very unambiguous that the 2.45 corresponds to the United Kingdom and not to Germany.

165
00:27:23,000 --> 00:27:35,000
So as we just saw we can use the dot lock accessor with our multi indexed WDI data frame to get different slices of our national accounts data.

166
00:27:35,000 --> 00:27:40,000
It was very easy for us to extract data for both a country and a year.

167
00:27:40,000 --> 00:27:45,000
And this is a principle that holds more generally.

168
00:27:45,000 --> 00:27:54,000
Using dot lock with a hierarchically index data frame is very powerful and it's similar to how we've used dot lock previously.

169
00:27:54,000 --> 00:28:03,000
However the rules are a bit more subtle and elaborate now that we have a little more structure to our data.

170
00:28:03,000 --> 00:28:14,000
We'll go through and we'll talk about a couple main overarching concepts and then we'll get through and walk through what each of the rules are for how pandas will interpret.

171
00:28:14,000 --> 00:28:19,000
The expression given to dot lock for a multi index data frame.

172
00:28:19,000 --> 00:28:27,000
And we'll make sure to follow up each of these different rules with an example that will happen in the exercise.

173
00:28:27,000 --> 00:28:31,000
So first let's review some slicing rules or cover them.

174
00:28:31,000 --> 00:28:41,000
One of the important distinctions to be aware of when you're reading or writing pandas code is the distinction between a list or a tuple.

175
00:28:41,000 --> 00:28:52,000
As you remember a tuple is an ordered collection in Python where you create this using parentheses on either side and the items are separated by commas.

176
00:28:52,000 --> 00:28:59,000
List have a very similar structure, but they are created using square brackets instead of parentheses.

177
00:28:59,000 --> 00:29:07,000
This is very important distinction because pandas interprets these two data structures very differently.

178
00:29:07,000 --> 00:29:20,000
First a tuple when you're doing roselizing will be used to denote a single hierarchical index and you must include one tuple item for each level in your index.

179
00:29:20,000 --> 00:29:26,000
For example what we just saw was that we had the WDI.lock.

180
00:29:26,000 --> 00:29:38,000
We opened the square bracket here and the the row specification was a tuple where we passed united states comma 2010.

181
00:29:38,000 --> 00:29:49,000
This instructed pandas that we wanted the single row that corresponded to the country united states and the year 2010.

182
00:29:49,000 --> 00:30:00,000
We then closed within specified we'd like the GDP column and closed the dot lock accessor.

183
00:30:00,000 --> 00:30:06,000
Notice here that the tuple has kind of an implicit and.

184
00:30:06,000 --> 00:30:17,000
Connotation to it we have a row where the country is united states and the year is to you valentine.

185
00:30:17,000 --> 00:30:32,000
And when we're using a list with a dot lock expression this will act as an or operation and this is going to choose were choose rose where.

186
00:30:32,000 --> 00:30:35,000
Any of the items in the list is satisfied.

187
00:30:35,000 --> 00:30:37,000
Let's look back at our example.

188
00:30:37,000 --> 00:30:46,000
We have our WDI data frame we did dot lock to an an opening square bracket and here we again we have a tuple telling pandas that we would like.

189
00:30:46,000 --> 00:30:53,000
To specify two items one for the country and the second for the year because those are the levels of our index.

190
00:30:53,000 --> 00:30:58,000
This time however instead of just reporting the string united states.

191
00:30:58,000 --> 00:31:04,000
The first item of our tuple is the list united kingdom and Germany.

192
00:31:04,000 --> 00:31:14,000
Now this is telling pandas that we would like any row in the data frame where the country is either the united kingdom or Germany.

193
00:31:14,000 --> 00:31:26,000
We're still going to be looking for year equal to 1, 10 and country equal to GDP but now we're going to get back any row.

194
00:31:26,000 --> 00:31:36,000
Where the country is either unicendum or Germany and pandas did this because it saw that we passed in a list here.

195
00:31:36,000 --> 00:31:39,000
So we have those two rules in mind.

196
00:31:39,000 --> 00:31:49,000
We're going to go over the specific rules for how you can access data inside of a hierarchy data in next data frame.

197
00:31:49,000 --> 00:32:03,000
I'll give a little warning at this point these rules can be a little obtuse and I encourage you to pause the video as needed and to study these as well as experiment with the examples in the exercise following this discussion.

198
00:32:03,000 --> 00:32:15,000
So that you can really can understand how they work. Well this play I'm here I'll talk through them once but I encourage you again to study these materials later on.

199
00:32:15,000 --> 00:32:21,000
So first if I were to do WDI dot lock and pass only a string.

200
00:32:21,000 --> 00:32:29,000
Pandas would interpret this as I'm doing a selection based on the rows.

201
00:32:29,000 --> 00:32:42,000
And I only want to look for rows where the first level or the outer most level of my index is equal to the United States.

202
00:32:42,000 --> 00:32:57,000
In our example this would return a data frame that is 17 by five or by seven because there are 17 years between 2017 and 2017 and we had seven different variables in our data frame.

203
00:32:57,000 --> 00:33:05,000
So there were seven if there's not the number of columns would be equal to the number of columns of WDI.

204
00:33:05,000 --> 00:33:08,000
Okay second we've already kind of talked through this one.

205
00:33:08,000 --> 00:33:14,000
At least partially if we were to pass the tuple United States comma 2010.

206
00:33:14,000 --> 00:33:22,000
So give us all rows where the outer most level of the index or the left most index is equal to United States.

207
00:33:22,000 --> 00:33:40,000
In our level of the index or the right level is equal to 2010 again we don't have a second item within the square brackets so this would give us all rows whereas before we had a comma GDP here which gave us just GDP.

208
00:33:40,000 --> 00:33:50,000
So we have a tuple we're looking for United States and 2010 on the levels of the index.

209
00:33:50,000 --> 00:34:12,000
Next we can pass a list as the first item in dialogue and this will tell pandas that we would like all rows where the first level of the index or the left most level is equal to either the United States or Canada.

210
00:34:13,000 --> 00:34:15,000
Here's where it gets a little trick here.

211
00:34:15,000 --> 00:34:32,000
If we were to pass a tuple this is going to tell pandas we're going to provide one item per level of our index for the first level we want all rows where country or the outer level of the index is either United States or Canada.

212
00:34:32,000 --> 00:34:39,000
And the second level of our index is either 2010 or 2011.

213
00:34:40,000 --> 00:34:55,000
So we get the or behavior happening both at the country level and then again at the year level and then we get the and behavior from this tuple where we combine the two.

214
00:34:55,000 --> 00:35:11,000
So if we were to do this the number of rows in the output here would be four we would have one row for United States 2010 another row for United States 2011 and then we would have those same two rows for Canada.

215
00:35:11,000 --> 00:35:37,000
Okay, here we go so now notice here that we begin the dot lock with a list instead of beginning with the tuple this tells pandas that we should be looking for any rows that satisfy any of the items in the list.

216
00:35:37,500 --> 00:35:40,000
Each of the list items is itself a tuple.

217
00:35:41,500 --> 00:36:00,300
Where we pass one item for the first level of the index and a second item for the second level here this expression will tell pandas to extract all the rows where we have the United States and 2010 on the first and second level of the index.

218
00:36:01,300 --> 00:36:12,300
Or where we have Canada and 2011 on the first and second level of the index the number of rows in the output of this expression would be equal to two.

219
00:36:14,300 --> 00:36:17,300
One for this.

220
00:36:17,300 --> 00:36:20,300
Inside of this tuple and a second one for this tuple.

221
00:36:21,300 --> 00:36:29,300
You can see here how the interplay between a list and a tuple is significant and really influences what we get back.

222
00:36:31,300 --> 00:36:37,300
And again, I strongly encourage you to look back on these do some practice do some study.

223
00:36:38,300 --> 00:36:51,300
And I'll note that any of the things that we've done on the rows we can also do for the columns so if we use dot lock whatever we happen to be doing for rows we can use just.

224
00:36:52,300 --> 00:37:04,300
One string GDP and we'll get that column or we could use a list and we get back both the GDP and consumption columns see examples of this later on.

225
00:37:04,300 --> 00:37:11,300
But just note that we explained all five of these rules within the context of filtering out rows.

226
00:37:11,300 --> 00:37:18,300
But you could also use it to filter out columns by passing it as the second argument inside of dot lock.

227
00:37:20,300 --> 00:37:33,300
Okay, here's an exercise I'm going to go ahead and pause here you should pause the video also as you work through these exercises and we strongly encourage you as you will get each of them.

228
00:37:33,300 --> 00:37:43,300
And to try to understand what is returned by these and then put in writing what the answer is and kind of defend your thinking.

229
00:37:44,300 --> 00:37:48,300
Although and stop now please pause your video and attempt the exercise.

230
00:37:48,300 --> 00:37:57,300
Okay welcome back.

231
00:37:58,300 --> 00:38:03,300
So let's work through this together let's evaluate what I will do is I will.

232
00:38:04,300 --> 00:38:11,300
First all evaluate this this cell and then we'll talk through what's happening already in a comment so first.

233
00:38:11,300 --> 00:38:16,300
But we see here is if we do dot lock we pass it a list with United States and Canada.

234
00:38:17,300 --> 00:38:24,300
This is giving us all rows where outer index is either United States or Canada.

235
00:38:29,300 --> 00:38:39,300
Now I'm going to go ahead and I hope that you did this on your own I'm going to go ahead and attempt to guess what will happen before we evaluate just to see if I'm understanding what's going on.

236
00:38:39,300 --> 00:38:51,300
So here we have a tuple where we're passing in the United States and Canada as the first item and 2011 or 10 11 and 12 as the second item this will be.

237
00:38:52,300 --> 00:38:58,300
All rows where outer index is either US or Canada.

238
00:38:59,300 --> 00:39:00,300
And.

239
00:39:01,300 --> 00:39:03,300
Inner index.

240
00:39:03,300 --> 00:39:11,300
It's one of 2010 2011 2012.

241
00:39:12,300 --> 00:39:16,300
So my hunch is that we'll get six rows back from this operation.

242
00:39:17,300 --> 00:39:24,300
Looks like here we have rows where the outer level is Canada or the United States just as we specified.

243
00:39:25,300 --> 00:39:30,300
As well as the year is one of 2010 11 or 12 and indeed there are six rows.

244
00:39:31,300 --> 00:39:32,300
So great.

245
00:39:33,300 --> 00:39:38,300
This next one this will give us all rows where outer index level is United States.

246
00:39:40,300 --> 00:39:42,300
Notice here something interesting happened.

247
00:39:43,300 --> 00:39:53,300
Pandas chose to drop the first or left most level of the index because each of these observations has.

248
00:39:53,300 --> 00:40:07,300
It is unique to identify it only using the year we've told pandas that we want to work with only data for country equal to United States and now the year is sufficient to disambiguate what each of these rows means.

249
00:40:08,300 --> 00:40:14,300
You might seem a little off putting if you think about it in this way however it's actually quite helpful.

250
00:40:14,300 --> 00:40:22,300
So if we were to want to compare directly the level of these valuable variables for the United States and say Germany.

251
00:40:23,300 --> 00:40:43,300
We can now do this directly because this data frame only has here on the index as well as this data frame and now pandas can use just the year to align each of the rows and then the columns they still align up so it's able to compute a number for each of these.

252
00:40:44,300 --> 00:41:01,300
I will point out that if we were to pass a list here instead of just the string create a pass a list with only United States it will keep this second level of the index and now if we were to try to repeat our same operation.

253
00:41:01,300 --> 00:41:15,300
We would see that we just get a bunch of nands because the first data frame didn't have anything where the country was Germany and year was 2000 or anything 2000 or 2017.

254
00:41:16,300 --> 00:41:23,300
So anytime that it one of these rows occurred the first item was missing so it has to give us a nand output.

255
00:41:24,300 --> 00:41:38,300
And then on the other hand the second item didn't have anything where the outer layer of the index was equal to United States so for every item in this data frame there was not a corresponding item in the second one again resulting in nand.

256
00:41:39,300 --> 00:41:54,300
So this automatic dropping of the index level when the secondary levels of the index are sufficient is actually quite useful in some circumstances but you just need to be aware of what's going on.

257
00:41:55,300 --> 00:42:01,300
Okay moving on to the next example here we have.

258
00:42:02,300 --> 00:42:19,300
A two pull here and a list here this will give us the single row for United States in 2010 and it will give us both the GDP and net exports columns so one row for us in 2010 and.

259
00:42:19,300 --> 00:42:23,300
Two columns for GDP and exports.

260
00:42:24,300 --> 00:42:30,300
We get a series back because we only have one row and we have two items in this series.

261
00:42:32,300 --> 00:42:38,300
Here this will just be a number or a series for all variables.

262
00:42:39,300 --> 00:42:41,300
For U.S. into other 10.

263
00:42:44,300 --> 00:42:48,300
Fine it starts with the list so now we're going to say.

264
00:42:49,300 --> 00:42:56,300
Two rows one for U.S. in 2010 and second for the type of.

265
00:42:57,300 --> 00:43:00,300
For Canada in 2015.

266
00:43:01,300 --> 00:43:04,300
Great this will be.

267
00:43:05,300 --> 00:43:08,300
All rows for.

268
00:43:09,300 --> 00:43:16,300
All rows with U.S. or Canada as country show all 17 years for both.

269
00:43:17,300 --> 00:43:20,300
Only GDP column.

270
00:43:23,300 --> 00:43:26,300
Great and finally this will give us.

271
00:43:27,300 --> 00:43:29,300
series with.

272
00:43:30,300 --> 00:43:33,300
Only year on the index.

273
00:43:36,300 --> 00:43:40,300
And values of US GDP.

274
00:43:41,300 --> 00:43:46,300
Now, reason we knew that we would get back a single index data frame.

275
00:43:47,300 --> 00:43:52,300
It's because if we select everything for the United States in the first level.

276
00:43:53,300 --> 00:44:00,300
The year is now sufficient to be unambiguous so it dropped the country level for us whereas above we needed the country level.

277
00:44:01,300 --> 00:44:06,300
Because we need to know whether or not whether these rows correspond to Canada or to the United States.

278
00:44:07,300 --> 00:44:08,300
Okay.

279
00:44:09,300 --> 00:44:12,300
You might want to take a break again now.

280
00:44:13,300 --> 00:44:18,300
Both to let your mind relax and have time to study and review the things that we just talked about.

281
00:44:19,300 --> 00:44:29,300
Being able to dissect and extract exactly the right data is almost a pandas superpower that we hope that you can develop and internalize.

282
00:44:30,300 --> 00:44:32,300
And that will become part of your everyday tool belt.

283
00:44:32,300 --> 00:44:38,300
But it takes practice so please put the time into practice in the study it will be well worthwhile.

284
00:44:43,300 --> 00:44:50,300
Okay, let's just focus now on the notion of data alignment but also when we have.

285
00:44:51,300 --> 00:44:55,300
Of multi index and we're mostly going to leave this to you.

286
00:44:55,300 --> 00:45:10,300
So we will have an exercise right here at this point where we like you to create a new data frame using some subset of our rows and then do some operations on it see what happens and.

287
00:45:11,300 --> 00:45:16,300
We'll regroup here in a few minutes so please pause at this point and attempt the exercise.

288
00:45:16,300 --> 00:45:33,300
Okay, welcome back. Let's go ahead and work through this together so first we'll create a very well my idea and for me let's just do.

289
00:45:34,300 --> 00:45:36,300
The rows.

290
00:45:37,300 --> 00:45:43,300
Let's say we would like the United States and Canada.

291
00:45:43,300 --> 00:45:50,300
For years 2015 and 2016.

292
00:45:54,300 --> 00:45:57,300
Take a look at what this looks like.

293
00:45:58,300 --> 00:46:00,300
Excuse me.

294
00:46:01,300 --> 00:46:09,300
Okay, so here we have four rows it's Canada and the US for the year 2015 and 16.

295
00:46:09,300 --> 00:46:18,300
So now let's take a look at what would happen if we were to use this data to do some operations so first.

296
00:46:19,300 --> 00:46:27,300
I'm going to move this up here so we can see it on the same slide and now let's try the WDI over my idea.

297
00:46:28,300 --> 00:46:30,300
So what happens here.

298
00:46:31,300 --> 00:46:32,300
I can't quite see it.

299
00:46:33,300 --> 00:46:37,300
I'm going to change this unless you can do thousand two and 2003.

300
00:46:40,300 --> 00:46:49,300
Now what happens is we get man's everywhere where oh, let's add I'm sorry I'm changing this example as we go.

301
00:46:51,300 --> 00:46:54,300
This is a useful thing to see though so I won't let it out.

302
00:46:54,300 --> 00:47:08,300
Okay, so now we have the year 2003, just in 2016 and 17 for Canada and the US if we take the full WDI data frame and divide it by.

303
00:47:09,300 --> 00:47:12,300
Our new data frame will get as we have nands.

304
00:47:13,300 --> 00:47:23,300
In all rows that don't appear in my the F but for Canada in 2002 we have all ones what happened here.

305
00:47:24,300 --> 00:47:38,300
Was it looked at the WDI value for for Canada in 2002 and it found the government expenditure number and it looked up that same sell or that same entry for my idea.

306
00:47:39,300 --> 00:47:45,300
It looked up Canada 2002 government expenditure because these are the same we see a one everywhere.

307
00:47:46,300 --> 00:47:49,300
If it was anything but a one pandas would be misaligning the data.

308
00:47:49,300 --> 00:48:00,300
But the whole point of being able to set the index and trust pandas to align things is that if we were to do this division will either see man or one those are the only options.

309
00:48:01,300 --> 00:48:07,300
We'll see same behavior down here for the latter years of the United States.

310
00:48:08,300 --> 00:48:30,300
I think that one example was sufficient for our purposes here feel free to do more if you like to experiment more but understanding that it's either missing or equal to one makes very clear that it's pulling out the exact same row column combinations from the two data frames.

311
00:48:30,300 --> 00:48:33,300
Okay.

312
00:48:34,300 --> 00:48:48,300
So we've seen here that when we want to extract all rows for multiple values of an outer index and then everything for later levels we use this convenience and tax.

313
00:48:49,300 --> 00:49:01,300
In our example we had the WDI dot lock and then we could pass a list of only Canada and the United States to get back all years for both of those two countries.

314
00:49:02,300 --> 00:49:05,300
However, oh yeah, here's the example.

315
00:49:06,300 --> 00:49:10,300
And we're getting back all of Canada and all of the US for each of those years.

316
00:49:11,300 --> 00:49:21,300
However, suppose you wanted to get data for all the countries for only years 2005 to 2007 and 2009 for example.

317
00:49:22,300 --> 00:49:39,300
We don't yet have the tools to do this using just dot lock because the years on the second level instead of the first and we don't have a way that we've learned so far to specify hey I would like all countries because that sort of peers on the first level.

318
00:49:39,300 --> 00:49:43,300
And then a list with these three numbers because I want any of these three.

319
00:49:44,300 --> 00:49:49,300
There is a way to do it, but we need a new tool here we use what's called index slice.

320
00:49:50,300 --> 00:50:03,300
So here the index slice we we open up the dot lock and where we're selecting rows instead of a list or a tuple here we're going to start by constructing an index slice.

321
00:50:04,300 --> 00:50:16,300
And we can tell this index slice that we'd like a colon for the first layer of the index if you remember colon means all or everything when we're slicing in Python.

322
00:50:17,300 --> 00:50:32,300
So this tells this index slice says I want all values are all rows regardless of their value of the first level of the index, but then I would like to restrict the rows where the second layer of the index is either 2005.

323
00:50:33,300 --> 00:50:35,800
Or 2007 or 2009.

324
00:50:37,000 --> 00:50:48,300
So now we get all four countries, but we only have these years and then we get back all columns because we have this comma all for the column specifier.

325
00:50:48,800 --> 00:51:00,600
So notice here that dot lock can accept up to two arguments the first one before the comma specifies the rows the second one after the comma specifies the columns.

326
00:51:01,600 --> 00:51:20,600
We see the colon here in two places first it's seen all values on the first layer or the country layer of the index are acceptable and the second usage is to say we would like all values or all columns are also acceptable.

327
00:51:24,600 --> 00:51:26,600
Here's that in words.

328
00:51:26,600 --> 00:51:34,600
So now we have another exercise that we'd like for you to do.

329
00:51:35,600 --> 00:51:45,600
I'll go ahead and pause here I'll let you read through the exercise you can work through it and then we'll come back and we're together okay let's pause now.

330
00:51:45,600 --> 00:52:03,600
Okay welcome back here in this exercise we'll begin by creating another version of our WDI data frame, but this time we're going to set year as the first layer of the index and country as the second.

331
00:52:04,600 --> 00:52:26,600
We're then given three different data extraction operations for the WDI data frame and what you're asked to do is to use index slice to get the same data out of WDI to so let's start with the first one here we're getting all data from the United States.

332
00:52:27,600 --> 00:52:38,600
Can do this WDI to dot lock we need to use index slice here because we want all the years but we only want the United States as the second one.

333
00:52:41,600 --> 00:52:49,600
And then we'll get all the columns and if we run this we'll get back very similar data frame here we're going to have.

334
00:52:50,600 --> 00:52:53,600
2017 and all the columns.

335
00:52:54,600 --> 00:53:01,600
Next we would like to get back these six rows for either the US or Canada for these three years.

336
00:53:02,600 --> 00:53:08,600
So now here what we can do is we can actually get this one without using.

337
00:53:09,600 --> 00:53:12,600
Next slice so we can do WDI to dot lock.

338
00:53:13,600 --> 00:53:16,600
We can pass the years first.

339
00:53:16,600 --> 00:53:23,600
And then we can pass a list of countries.

340
00:53:28,600 --> 00:53:41,600
That's that we want all columns we'll get back again a data frame with the same observations we'll still see that these index levels are swapped so the printing looks slightly different but the data is the same.

341
00:53:42,600 --> 00:53:45,600
Finally this third example we would like.

342
00:53:46,600 --> 00:53:50,600
For each of the 17 years for both Canada and the United States.

343
00:53:51,600 --> 00:53:56,600
Get that using our second one we would do we have to use index slice here.

344
00:53:57,600 --> 00:54:08,600
We want all the years we want a colon for the year level of the index and we want just the United States and Canada for giving me I didn't mean to press enter there.

345
00:54:08,600 --> 00:54:12,600
Canada and then we would like just the GDP column.

346
00:54:13,600 --> 00:54:17,600
Here again we're going to get back the same values the printing's different.

347
00:54:18,600 --> 00:54:24,600
Because the order of these index levels is different but we got back the same 34 numbers.

348
00:54:24,600 --> 00:54:35,600
I hope you had a chance to experiment and play with the index slice and that you understand how that helps us.

349
00:54:36,600 --> 00:54:51,600
Okay so we've been working with these hierarchical or multi indices on the row labels or in the index but we can also have it on the column index so what we're going to do here.

350
00:54:51,600 --> 00:54:56,600
This will take our WDI data frame and we will swap the columns in the rows.

351
00:54:57,600 --> 00:55:06,600
This operation comes from linear algebra and is known as the transpose and the way we write it is by doing a dot capital T after the data frame.

352
00:55:07,600 --> 00:55:11,600
So when we do this now the index has just these five.

353
00:55:12,600 --> 00:55:23,600
Variable indicators this used to be the columns and now our columns have two levels on the outer most level we still have the country.

354
00:55:24,600 --> 00:55:29,600
This used to be on the far left of WDI and on the second level of our.

355
00:55:32,600 --> 00:55:34,600
Column names we have the year.

356
00:55:35,600 --> 00:55:58,600
What we can do is we can tell we can start extracting data we can tell pandas we would like all the variables that's this first colon just for the United States this was doable because country was on the outer layer of our column indices here country was the first level of column indices.

357
00:55:58,600 --> 00:56:14,600
We are not as also just like we saw with the United States on the rows because we want only data for the United States and we want all of it the year is now the only level of index for our columns.

358
00:56:15,600 --> 00:56:21,600
We didn't need that second layer to identify the country because we know that this is only data for the United States.

359
00:56:21,600 --> 00:56:30,600
If we wanted to get both the US and Canada we could pass a list here and notice that we get countries both the US and Canada.

360
00:56:33,600 --> 00:56:44,600
And the same types of rules that we learned for extracting rows will work here so in this example we're going to get all the variables and then we will have a tuple.

361
00:56:44,600 --> 00:56:55,600
Which tells pandas to expect the first item to apply to the first layer of the index and the second item to the second layer here we want all columns.

362
00:56:56,600 --> 00:57:05,600
Where the country is either United States or Canada and the year is 2010 so we should get back something that is five by two.

363
00:57:06,600 --> 00:57:12,600
All five variables for these two different countries in 2010.

364
00:57:14,600 --> 00:57:17,600
Here's another exercise for you to try.

365
00:57:18,600 --> 00:57:22,600
I will go ahead and pause here while you attempt that and then we'll regroup in a minute.

366
00:57:27,600 --> 00:57:28,600
Okay welcome back.

367
00:57:29,600 --> 00:57:41,600
Here what we're asked to do is to use this transposed WDI data frame to get all data for all countries in years 2010, 2012 and 2014.

368
00:57:41,600 --> 00:57:47,600
So here we would do WDI transpose dot lock we're going to get all the variables.

369
00:57:48,600 --> 00:57:56,600
We'll do index slice and we'll put a colon in the first position this represents that we want all countries.

370
00:57:56,600 --> 00:58:06,600
And then we'll do a list in the second position note of telling pandas that we would like only rows or sorry the columns.

371
00:58:07,600 --> 00:58:12,600
But the year is equal to 2010, 2012 or 2014.

372
00:58:14,600 --> 00:58:23,600
Forgot a comma right here and here we go we get all five variables and we only have these three years but we have them for all four countries.

373
00:58:26,600 --> 00:58:36,600
And there's a nice symmetry between how we can use these indexing rules for a multi-level column or multi-level row data frame.

374
00:58:39,600 --> 00:58:46,600
So we've talked about how to set the index but one of the other key operations when we're dealing with the index is to reset it.

375
00:58:47,600 --> 00:59:05,600
And when we call the reset index method when we and we don't pass any arguments the following happens we will see that the columns that were previously used for the index are returned back to be columns alongside the existing ones.

376
00:59:06,600 --> 00:59:16,600
And the index is going to be reset to go from zero one to all the way through the total number of rows and the data frame minus one.

377
00:59:17,600 --> 00:59:30,600
This is the default index also called a range index in pandas and when we call reset index again whatever we had there is move back as a column and then we get back the default range index.

378
00:59:30,600 --> 00:59:47,600
So there are a few variations of behavior with the reset index method and we'd like for you to do this exercise now to learn what these variations are from the documentation of the method.

379
00:59:48,600 --> 00:59:55,600
So we'll pause at this time for you to work through this exercise and then we'll regroup in a minute for us to work through it together.

380
01:00:00,600 --> 01:00:16,600
Okay welcome back we'll go ahead and start this exercise together. So the first hint is that we should use the.

381
01:00:17,600 --> 01:00:32,600
Accummentation string for reset index to understand how it works so when I do the WDI dot reset index and a question mark the Jupiter notebook opened up this help window.

382
01:00:32,600 --> 01:00:38,600
If you're in Jupiter lab or different environment you might have seen something slightly different but this same content should be everywhere.

383
01:00:38,600 --> 01:00:46,600
We'll see here that there are a few arguments one is called level and drop and these are the ones that will focus on at this point.

384
01:00:47,600 --> 01:01:03,600
So first the level argument says that we should only remove given levels from the index and this could be specified by an integer a string or some tupler list of integers and strings.

385
01:01:03,600 --> 01:01:15,600
By default if we don't pass anything or remove all levels of the index so let's use that to see how we can remove just the year so if you do WDI dot reset index.

386
01:01:16,600 --> 01:01:33,600
We pass as the first argument or level as year what we see is if the country stayed on the index but the year was moved up and was made a column alongside the existing ones so this satisfies the first.

387
01:01:34,600 --> 01:01:36,600
Part of the question.

388
01:01:37,600 --> 01:01:43,600
So now the second part of the question says that we'd like to throw away all levels of the index.

389
01:01:43,600 --> 01:01:52,600
Turn the looking at the documentation and we'll look at this drop method or show you this drop argument here it says do not try to insert the index.

390
01:01:52,600 --> 01:02:09,600
As columns this reset it to the default so if we were to run this they would not be inserted as columns that sounds like just what we want because we'd like to throw away the levels let's try this WDI dot reset index drop.

391
01:02:10,600 --> 01:02:25,600
Here we'll see that we do get this default zero through n minus one on the index but now country and year are nowhere to be seen they have been removed from the index and dropped from the data frame entirely.

392
01:02:26,600 --> 01:02:37,600
The third part here asks us to combine these two we would like to remove country from the index but keep year and then we don't want to keep country as a column.

393
01:02:37,600 --> 01:02:43,600
So here we can combine these two things that we've learned WDI dot reset index.

394
01:02:44,600 --> 01:02:48,600
The level that we would like to reset entry.

395
01:02:49,600 --> 01:02:52,600
And we like to drop it we don't need to keep it around.

396
01:02:53,600 --> 01:03:05,600
When we do this we still get the year on the index but now instead of moving country up to be another column it's just completely thrown out of the data frame we no longer have country information.

397
01:03:05,600 --> 01:03:14,600
We wouldn't necessarily want to do any of these operations but it's useful to know how just like you can set the index you can also reset the index.

398
01:03:18,600 --> 01:03:26,600
So as we close our discussion on the index we will kind of leave you with a few parting words of.

399
01:03:27,600 --> 01:03:36,600
Best practice and suggestion for how to do that and the question that should come to your mind is we've seen the index being important.

400
01:03:36,600 --> 01:03:44,600
And now the question becomes how do we pick the index how do we feel or know that we have the right columns on the index.

401
01:03:44,600 --> 01:03:53,600
And there is some belief on on what is a deep a good default value or a good default answer to this question and.

402
01:03:53,600 --> 01:03:55,600
To explain that we're going to look at.

403
01:03:57,600 --> 01:04:03,600
Description of what had the weak am a very popular data scientists in the our community.

404
01:04:04,600 --> 01:04:17,600
We're first to as tidy data and the first two components of his definition of tidy are that each column should have only one variable in it and that each row should have one observation.

405
01:04:18,600 --> 01:04:23,600
Sounds fairly simple but you'll see how this helps us with the index here pretty soon.

406
01:04:25,600 --> 01:04:32,600
If we're striving to have a tidy data which makes a lot of forms of analysis easier so it's a great default.

407
01:04:33,600 --> 01:04:41,600
Then when we choose the index we should make sure that the row labels are sufficient to uniquely identify an observation.

408
01:04:41,600 --> 01:04:47,600
For our column or sorry for our WDI data frame.

409
01:04:49,600 --> 01:04:55,600
This unique way to identify an observation would have been the country and the year.

410
01:04:56,600 --> 01:05:03,600
And then the column names should be specific enough to identify one single variable.

411
01:05:03,600 --> 01:05:13,600
Again in our WDI example this was any of the components of GDP consumption government expenditure imports exports or GDP.

412
01:05:14,600 --> 01:05:18,600
Let's think about another example suppose we have date on interest rates.

413
01:05:19,600 --> 01:05:22,600
Each column might represent one.

414
01:05:23,600 --> 01:05:29,600
Asset one different bond one different term structure for debt.

415
01:05:29,600 --> 01:05:39,600
And then on the rows we might have the date or the time and we would keep track of in this data frame how the interest rate evolves over time.

416
01:05:40,600 --> 01:05:43,600
The reason we chose the rows.

417
01:05:44,600 --> 01:05:53,600
To be time was that it allowed us to think through and identify an observation as what was the interest rate on a particular date.

418
01:05:53,600 --> 01:06:03,600
And then putting the different assets or debt as columns allowed us to identify them as separate variables.

419
01:06:04,600 --> 01:06:08,600
So the notion of.

420
01:06:09,600 --> 01:06:19,600
Keeping everything in a two dimensional form where we have a row label and a column label might seem a bit limiting at first because there are many forms of data.

421
01:06:19,600 --> 01:06:25,600
That typically require more than two dimensions for example if you had an image or a picture.

422
01:06:26,600 --> 01:06:33,600
You would have a two dimensional grid of pixels and then at each of these two dimensional points.

423
01:06:34,600 --> 01:06:40,600
You would have a third dimension that represents the color saturation in red, green and blue.

424
01:06:41,600 --> 01:06:45,600
So inherently one natural way to represent this would be.

425
01:06:46,600 --> 01:06:57,600
As a three dimensional object one for the pixels going up and down the picture the second dimension going left and right and the third dimension going into the color space.

426
01:06:58,600 --> 01:07:05,600
Well, we could represent this in pandas in a data frame by using a hierarchical index.

427
01:07:05,600 --> 01:07:10,600
One thing you might choose is to put both the.

428
01:07:11,600 --> 01:07:20,600
horizontal and vertical pixel coordinate on the index and then have the columns be the red, green and blue pigment values.

429
01:07:21,600 --> 01:07:25,600
In this way we're still able to keep it in a tabular.

430
01:07:26,600 --> 01:07:35,600
Explicitly two dimensional form but because we have this notion of the hierarchical index we're able to represent a three dimensional data set.

431
01:07:36,600 --> 01:07:45,600
This example could be extended to more and more dimensions if we just add extra layers to either the row index or the column of index.

432
01:07:45,600 --> 01:07:50,600
One of the main.

433
01:07:51,600 --> 01:08:00,600
Points we'd like to emphasize when you're trying to organize your data is that you really need to understand the problem you're trying to solve.

434
01:08:01,600 --> 01:08:03,600
The quote correct.

435
01:08:04,600 --> 01:08:10,600
Labels for your data will often depend on the problem at hand.

436
01:08:11,600 --> 01:08:18,600
So for example suppose we wanted to study how the GDP and consumption evolved over time for different countries.

437
01:08:19,600 --> 01:08:24,600
Well, in this case we would want both time and the country to be on the index.

438
01:08:25,600 --> 01:08:28,600
This is what we saw earlier with the WDI data frame.

439
01:08:29,600 --> 01:08:36,600
However, if instead of looking over time I was more interested in looking at differences across countries.

440
01:08:36,600 --> 01:08:46,600
At a particular moment in time I might choose to put the country invariable on the index and have the year be the column labels.

441
01:08:49,600 --> 01:09:01,600
This allows me to think of all the observations for 2010 for example as a variable and I can quickly do comparisons row by row between different countries.

442
01:09:02,600 --> 01:09:16,600
The last party wisdom will leave with you is that following the tidy rules above and just thinking about what you would like to accomplish with the data or how you intend to use it.

443
01:09:17,600 --> 01:09:26,600
And a little practice with setting and resetting the index will help you to consistently get the correct index that makes your analysis as easy as possible.

