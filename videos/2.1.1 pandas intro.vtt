WEBVTT

00:00.000 --> 00:05.000
Hi, this is Chase Coleman. Today we're going to be talking about the Python library pandas.

00:05.000 --> 00:12.000
Prior today you should have completed the Python fundamentals training. This was something we offered over the summer.

00:12.000 --> 00:19.000
At the end of today you should understand some of the core pandas objects such as a series and a data frame.

00:19.000 --> 00:24.000
You should understand how to index into particular elements of series and data frames.

00:24.000 --> 00:30.000
And you should understand some of the basic types that can be stored inside of a series or a data frame.

00:30.000 --> 00:35.000
Additionally, as we go you'll learn how to make some basic visualizations.

00:35.000 --> 00:43.000
The outline for today is to talk a little bit about the pandas library to introduce what a series is and then introduce what a data frame is.

00:43.000 --> 00:51.000
To talk about some of the different data types available in pandas and then to talk about modifying some of the data frames.

00:54.000 --> 01:01.000
Great. So let's go ahead and get started.

01:01.000 --> 01:10.000
So the pandas package will be imported and typically you'll give it the alias PD. So we'll write import pandas as PD.

01:10.000 --> 01:19.000
Don't worry about what this line does for now, but basically what it does is it's going to allow us to put plots inside of our notebook.

01:19.000 --> 01:30.000
And then finally we're going to activate the want econ data science plotting theme.

01:30.000 --> 01:34.000
Now let's go ahead and figure out what version of pandas everyone has.

01:34.000 --> 01:38.000
So on my computer I have version 1.1.1.

01:38.000 --> 01:48.000
But anything that's higher than 0.25 should be okay.

01:48.000 --> 01:55.000
Great. So the first data type we're going to introduce is called a pandas series.

01:55.000 --> 02:04.000
And a series represents a single column of data and it will be associated with row labels for each observation.

02:04.000 --> 02:13.000
And pandas is going to refer to these row labels, which are right here in this case 0, 1 and 2 as the index.

02:13.000 --> 02:18.000
And we might have named, we might have a name associated with this series.

02:18.000 --> 02:26.000
In this case maybe we just call it s. And so the series named s has an index of 0, 1, 2.

02:26.000 --> 02:34.000
And the values that are stored inside of the series are called the values.

02:34.000 --> 02:44.000
So on the next slide we're going to create a series which includes the US unemployment for every other year starting in 1995.

02:44.000 --> 02:55.000
So here we have the values. And here we have each of the years notice we started 1995 and we go until 2017.

02:55.000 --> 03:02.000
And we take a step by two. So this will have 1995, 1997, etc.

03:02.000 --> 03:12.000
And then we're going to create a series by putting the values as the data argument, the years as the index argument,

03:12.000 --> 03:17.000
and then we're going to give this series the name unemployment.

03:17.000 --> 03:28.000
And let's see what we have. So we can see like we just talked in the previous slide that we have the index right here.

03:28.000 --> 03:39.000
And it was this list of years that we talked about. And then over here we have each of the values that are associated with that index.

03:39.000 --> 03:48.000
And we have the name of our series at the bottom.

03:48.000 --> 03:56.000
So we can look at the index or the values. Notice the values are stored inside of a Numpy array.

03:56.000 --> 04:03.000
And the index is stored inside of a pandas index object.

04:03.000 --> 04:09.000
So now that we have a series, what can we do with it?

04:09.000 --> 04:17.000
So typically our data will have kind of thousands or hundreds of thousands of rows or maybe even millions or billions of rows.

04:17.000 --> 04:22.000
So we obviously don't want to display all of it at once.

04:22.000 --> 04:31.000
And there's two methods for series that will just show us the first few observations or the last few observations.

04:31.000 --> 04:40.000
So notice an employment dot head will show us the first five and unemployment dot tail will show us the last five.

04:40.000 --> 04:54.000
We could also give an argument to either of these of just an integer and it will show us the last N observations from this series.

04:54.000 --> 05:04.000
So let's go ahead and do some basic plotting. And if we plot a series using the plot method, all it will do is plot the values.

05:04.000 --> 05:14.000
So if we go ahead and look at the values we had, notice 5.6 is associated with 1995.

05:14.000 --> 05:21.000
5.3 is associated with 1997, 4.3 in 1999, etc. etc.

05:21.000 --> 05:35.000
And it's created this nice little line plot for us. And as we mentioned earlier, we needed this percent map plot lib in line in order to get the plot to show up in the right place.

05:35.000 --> 05:46.000
So in this data set, it's not such an interesting observation. But in other data sets, you might be interested in knowing what unique values are in a series.

05:46.000 --> 06:02.000
So for example, if you had a series that had the ages of the individuals in your data set, that might take the values 18, 19, 20, 21, dot, dot, until the maximum age.

06:02.000 --> 06:10.000
So again, here it's not interesting because each value is different, but it's something you might do in the future.

06:10.000 --> 06:25.000
One of the things that you'll frequently want to do is to select particular elements from a series. And we can use this using the dot lock method or modifier, where index items is going to be some item from inside of the index.

06:25.000 --> 06:40.000
So if we look here, we can see we have our unemployment series. And if we wanted to get the value associated with 1995, all we would do is write dot lock 1995.

06:41.000 --> 06:55.000
And if we wanted to get multiple values, maybe we wanted the values from 1995, 2005, and 2015, we can just give it a list of values and notice extracted the correct values.

06:55.000 --> 07:05.000
So let's take a minute and pause. And we're going to have each of you do some experimentation with these series methods.

07:05.000 --> 07:11.000
So the first thing is we'd like you to display only the first two elements of the series using the head method.

07:11.000 --> 07:16.000
We'd like you to use the plot method to make a bar plot.

07:16.000 --> 07:23.000
We'll use the dot lock to select the lowest and highest unemployment rate shown in the series.

07:23.000 --> 07:30.000
And run the code unemployment dot d type below. What does it give you? What do you think it corresponds to?

07:30.000 --> 07:35.000
And we'll go ahead and take about five minutes to do this.

07:35.000 --> 07:48.000
Okay, welcome back. So as we saw a few minutes ago, the way to select the first two values from a series using the head method is to do unemployment dot head with the integer two.

07:48.000 --> 07:53.000
And notice it selected 1995 and 1997.

07:53.000 --> 08:08.000
To do the plotting, we wanted you to investigate the documentation and recall from our lectures this summer that you can do this by taking the unemployment dot plot method and putting a question mark after and running the cell.

08:08.000 --> 08:11.000
And so that brings up the documentation.

08:11.000 --> 08:21.000
And it tells you that the inputs are the series or data frame, the X and Y labels, and then what kind of plot you'd like to produce.

08:21.000 --> 08:31.000
And notice one of the options is bar. So to make the bar plot, all we have to do is unemployment dot plot kind equals bar.

08:31.000 --> 08:39.000
And by default, it will set the index as the X values and the values as the Y values.

08:39.000 --> 08:44.000
And here we've got a bar plot.

08:44.000 --> 08:56.000
To select the minimum and maximum values of unemployment, you might have just looked by hand and notice 2001 and was the lowest unemployment in 2011 was the highest.

08:56.000 --> 09:03.000
But you also could have used the IDX min and IDX max arguments.

09:03.000 --> 09:13.000
And what do these do is if you look at IDX min question mark, it returns the row label of the minimum value.

09:13.000 --> 09:18.000
If multiple values equal the minimum, the first row label with that value is returned.

09:18.000 --> 09:25.000
So this will find us the minimum one and the maximum one could be done just like it.

09:25.000 --> 09:31.000
And then unemployment dot d type tells us float 64.

09:31.000 --> 09:49.000
So if we look at our unemployment series, just notice that the values themselves are float 64. So unemployment dot d type is just telling us what kind of values are being stored inside of our series.

09:49.000 --> 09:56.000
Great. So now we've talked about what a series is and we'll now talk about what a data frame is.

09:56.000 --> 10:03.000
So a data frame is just going to be how pandas will store multiple columns of data.

10:03.000 --> 10:10.000
You could think about data frames is simply just multiple series stacked side by side.

10:10.000 --> 10:14.000
You'll notice that we still have an index.

10:15.000 --> 10:26.000
And now the index is zero. We'll just call this column zero one and two.

10:26.000 --> 10:42.000
So index zero is associated with the a in column zero, the a in column one and the a in column two index one is associated with the b in column zero, the b in column one.

10:42.000 --> 10:53.000
And the b in column two and the index two is associated with the c in column zero, et cetera, et cetera.

10:53.000 --> 11:07.000
So on the next slide, we're going to create a data frame that contains the unemployment rate every other year for each region in the United States starting in 1995.

11:08.000 --> 11:36.000
And so what you'll notice is now rather than giving us giving the data frame function a single list, we're going to give it a dictionary and we're going to say north east is the key and that maps to the list 5.9 5.6 dot dot dot south is the key, which maps to the value 5.3 5.2 dot dot dot.

11:36.000 --> 11:41.000
And then national is the key that maps to et cetera.

11:41.000 --> 11:48.000
And we're going to turn that into a data frame and we'll use the same index as we did before, which was years.

11:48.000 --> 11:50.000
And then let's just see what that looks like.

11:50.000 --> 12:01.000
So notice what it's done is it's taken the list that was associated with each key in the dictionary and it's turned that into a column of data.

12:02.000 --> 12:10.000
So the first value in northeast was 5.9 in 5.6 4.4, et cetera.

12:10.000 --> 12:14.000
And notice now these are associated with the index 1995.

12:14.000 --> 12:22.000
So in 1995, the northeast region had an unemployment rate of 5.9 while the Midwest had an unemployment rate of 4.5.

12:22.000 --> 12:33.000
The south had an unemployment rate of 5.3 and the west had an unemployment rate of 6.6 and the national unemployment was 5.6.

12:33.000 --> 12:42.000
So again, we can extract the index from our unemployment and this is the same index that we saw earlier.

12:42.000 --> 12:48.000
And we can extract the values from the unemployment region data frame.

12:48.000 --> 12:53.000
And notice all this is, is it's a two-dimensional array, it's a matrix.

12:53.000 --> 13:08.000
And these values 5.9 5.6 4.4 are associated with the values that correspond to northeast because it was the first column 5.9 5.6 4.4.

13:08.000 --> 13:11.000
So what can we do with the data frame?

13:11.000 --> 13:16.000
The answer is pretty much everything we can do with a series and a little more.

13:16.000 --> 13:25.000
So just like with the series, we can take the head and the tail of the data frame to get an idea of what our data looks like.

13:25.000 --> 13:37.000
Additionally, we can create a plot and notice this plot now has one line for each column in the data frame.

13:37.000 --> 13:39.000
And we can index.

13:39.000 --> 13:49.000
Now this is going to look a lot like the indexing for a series but it's going to be a little bit more complicated because we have to choose from both an index and a column.

13:49.000 --> 13:51.000
So let's see how we would do that.

13:51.000 --> 14:07.000
So if we wanted to get the value that was associated with the unemployment rate in the northeast in 1995, we would specify 1995 as the index and northeast as the column.

14:07.000 --> 14:10.000
And that gives us the 5.9.

14:10.000 --> 14:24.000
If we wanted to get the 1995 in 2005 unemployment for the south, we could give it a list of 1995 in 2005 and then the south.

14:24.000 --> 14:36.000
And notice in this case, we were returned just a single number but because we're now asking for multiple things, it's returned a series to us.

14:36.000 --> 14:44.000
And like we can select multiple values from the index, we can also select multiple values from the columns.

14:44.000 --> 14:49.000
But notice it's also turned it into a series.

14:49.000 --> 14:57.000
We can also select an entire column by using the colon.

14:57.000 --> 15:07.000
And we also could select an entire row by doing it the other way and notice both of those return a series.

15:07.000 --> 15:22.000
You can also select multiple values from both in which case you'll be returned a new data frame.

15:22.000 --> 15:32.000
And if you don't use the dot lock, it will just extract the column associated with the string you pass it.

15:32.000 --> 15:36.000
Great. So now we know how to select data inside of a data frame.

15:36.000 --> 15:39.000
What types of things can we do?

15:39.000 --> 15:49.000
So we can divide by 100, which moves it from percent units to a rate.

15:49.000 --> 15:54.000
And notice it's divided every element of our column by 100.

15:54.000 --> 15:58.000
We can find the maximum value.

15:58.000 --> 16:01.000
We can subtract one column from another.

16:01.000 --> 16:11.000
So we've taken the unemployment in the west and subtracted the unemployment in the Midwest, which just tells us the difference.

16:11.000 --> 16:15.000
And we can also compute the correlation between two columns.

16:15.000 --> 16:21.000
So the unemployment in the west and the unemployment in the Midwest had a 0.9 correlation.

16:21.000 --> 16:27.000
And if we wanted all of the correlations at once, we can simply compute the correlation matrix.

16:27.000 --> 16:33.000
So notice it says, a northeast is correlated perfectly with the northeast unsurprising.

16:33.000 --> 16:45.000
It's got a 0.87 correlation with the Midwest, a 0.96 with the south in the west, and a 0.97 with the national unemployment rate.

16:45.000 --> 16:48.000
So let's stop for a minute and do another exercise.

16:48.000 --> 16:58.000
In this case, we'll continue to encourage using introspection, the tab completion, and Google through to fulfill the following exercises.

16:58.000 --> 17:05.000
Let's find a way to obtain a list that contains all of the column names in the DataFrame unemployment region.

17:05.000 --> 17:09.000
Let's use the plotting method, the plot method, to make a bar plot.

17:09.000 --> 17:15.000
What does this look like now and how does it compare to the plot we created with the series?

17:15.000 --> 17:25.000
Let's use .loc to select the unemployment data for the northeast and west in the years 1995, 2005, 2011, and 2015.

17:25.000 --> 17:30.000
And let's run the code unemploymentregion.d types below.

17:30.000 --> 17:38.000
What does this give you? How does this compare to the same thing on the series operation?

17:38.000 --> 17:41.000
Welcome back. So let's go over the answers.

17:41.000 --> 17:45.000
So there's a property of the DataFrame called .colums.

17:45.000 --> 17:51.000
And notice this just corresponds to the equivalent of .index but for the column data.

17:51.000 --> 17:58.000
And notice it gives us northeast, Midwest, Southwest, and National.

17:58.000 --> 18:05.000
We can make the bar plot and notice what it's done is it's plotted each of the columns for each year.

18:05.000 --> 18:12.000
So the x-axis is still the indexes but now we have five different bars for each year.

18:12.000 --> 18:19.000
And the colors correspond to the Northeast, Midwest, Southwest, and National.

18:19.000 --> 18:27.000
To select the subset of data we talked about, we can do as we discussed and pass two lists.

18:27.000 --> 18:33.000
And with d types, notice we were told float64 but it now gives us a series.

18:33.000 --> 18:44.000
So it says the Northeast column has all float data, the Midwest column has all float data, et cetera.

18:45.000 --> 18:54.000
So in the previous exercise we asked you to run the commands, unemployment.dtype and unemploymentregions.dtypes and to think about the outputs.

18:54.000 --> 18:59.000
As we've already discussed, they return the types of the values inside of each column.

18:59.000 --> 19:03.000
If we do this with a series, it will just give us a single type.

19:03.000 --> 19:13.000
And if we do this with a DataFrame, it gives us a series that maps the column name into what type of data is stored inside of that column.

19:13.000 --> 19:18.000
So it's important that you often check what type of data you're reading into.

19:18.000 --> 19:27.000
Pandas? Because you can get some things where if data is not of the type you think it is, that it will misbehave.

19:27.000 --> 19:32.000
So let's see for example, so DataFrames will only distinguish between a few types.

19:32.000 --> 19:40.000
They can recognize Booleans, floating point numbers, integers, dates, which we'll talk more about soon, categorical data,

19:40.000 --> 19:45.000
and then everything else, including strings, is stored as an object.

19:45.000 --> 19:51.000
In the future, we will continue to refer to the data type of data stored in a column as its dtype.

19:51.000 --> 19:56.000
So let's look more closely at an example of when having an incorrect dtype can cause problems.

19:56.000 --> 20:07.000
So suppose that we imported this unemployment data from somewhere else, but instead the data for the South column came as a string.

20:07.000 --> 20:14.000
So notice what we've done here is we've created, we've taken the column of the South,

20:14.000 --> 20:20.000
and we've turned it into a string data type, and then we've saved it back into that column.

20:20.000 --> 20:28.000
And now when we look at string unemployment d types, we see float64, float64, and object.

20:29.000 --> 20:34.000
So if we just look at the data frame, notice everything looks okay.

20:34.000 --> 20:45.000
You don't notice that South is of type string, but if we try to do something like compute the sum, you'll get something weird.

20:45.000 --> 20:54.000
So notice for the Northeast, Midwest, West, and National, it's performed the sum as we might expect, but when we summed the South,

20:54.000 --> 20:59.000
it's just taken all of the unemployment rates, and it's tied the strings together.

20:59.000 --> 21:09.000
And this happens because dot sum is just calling plus between each of the rows in a column, and when we add two strings, the result is the two strings being concatenated.

21:09.000 --> 21:13.000
And so right here, all we've done is concatenate all of the strings.

21:13.000 --> 21:21.000
So these types of errors will pop up unexpectedly, and it's useful to check what type your data is.

21:22.000 --> 21:27.000
Now let's go ahead and talk about how we can change the data inside of a data frame in various ways.

21:27.000 --> 21:36.000
In particular, we'll talk about adding new columns, renaming the index labels or column names, and altering the data inside of the data frame.

21:36.000 --> 21:42.000
Some of these will be discussed at length later in the class, but we'll just give a brief introduction.

21:42.000 --> 21:55.000
So to create a new column, you can take the data frame, we'll often abbreviate our data frames as DF, and we can give it a new name and strings, and assign it to the values.

21:55.000 --> 21:57.000
So let's see how we could do that.

21:57.000 --> 22:11.000
So we could create unemployment region, a new column called unweighted mean, and we could do that by adding the Northeast, Midwest, South, and West unemployment regions, and then dividing by four.

22:12.000 --> 22:23.000
And notice, if we do that, we now have the national mean, which is going to be population weighted, and the unweighted mean, which is what we just performed right here.

22:23.000 --> 22:26.000
You can also change the values inside of a data frame.

22:26.000 --> 22:33.000
Again, you should do this very sparingly because you don't want to change the data that you're using.

22:34.000 --> 22:43.000
So in this case, we're going to take the 1995 unweighted mean value, and we're going to assign it to zero.

22:43.000 --> 22:51.000
And so now, in the year 1995, the unweighted mean has been reset to the value zero.

22:51.000 --> 22:54.000
And we can also rename columns.

22:54.000 --> 23:06.000
One of my favorite examples that's entirely frustrating is the Bureau of Labor Statistics here in the United States, names their regional unemployment rate according to the following protocol.

23:06.000 --> 23:15.000
LASRD 9100000003.dot.dot.

23:15.000 --> 23:19.000
And you're supposed to know that that's the unemployment rate for the Northeast.

23:19.000 --> 23:28.000
So they have reasons internally for doing this because they have so many variables, but it makes our job really difficult because we'll need to type it repeatedly.

23:28.000 --> 23:35.000
And so what we'll do is we'll often rename these columns by passing a dictionary to the rename method.

23:35.000 --> 23:46.000
And what you do is you take a dictionary and you take the value that it currently is, in this case, Northeast, Midwest, South, and West, and that will be the key of your dictionary.

23:46.000 --> 23:49.000
And the value of your dictionary will be the new name.

23:49.000 --> 23:55.000
So in this case, we have NEMWS and W.

23:55.000 --> 24:00.000
And so if we look at our data frame, it looks like things have been renamed.

24:00.000 --> 24:05.000
Well, maybe not. So what happened here?

24:05.000 --> 24:10.000
Why doesn't the data frame show that why does the data frame still show the old column names?

24:10.000 --> 24:15.000
The reason is most panda operations are going to create a copy of your data.

24:15.000 --> 24:24.000
And to specify that you meant to overwrite your data frame, you have to use the in place option.

24:24.000 --> 24:33.000
We recommend that you avoid using this too much until you understand exactly what you're changing because you don't want to overwrite your data.

24:33.000 --> 24:40.000
And we'll often just create the new data frame and assign it back to something of the same name.

24:40.000 --> 24:46.000
So in this case, we've renamed our columns and this creates a new data frame.

24:46.000 --> 24:56.000
And then we've assigned it to unemployment short name and in the short name data frame, we now have the renamed columns.

24:56.000 --> 24:59.000
And that's all we have for this lecture.

24:59.000 --> 25:03.000
So we'll see you soon to talk about panda's basics.

