00:00:00 --> 00:01:21
Hello, this is Spencer Lyon and today we will be doing a review of pandas by way of example. What we will be looking at today is an example dataset called the movie lens dataset. We will be using this to learn a few things. First, we will be learning how to use the request library in pandas, which is a very popular library for handling interactions with web services. Second part of this will be downloading a file that is contained in a zip archive. So we are going to learn how to allow pandas to operate on these zip files, but we will do so entirely in memory without having to write the file out to a hard drive. And finally, we are going to practice merging datasets so that we can do a more complete analysis on a variety of datasets. Just to note that you will need to enter an access if you are following along in running this notebook because we will be downloading a file from the internet. And also this was originally created a few years ago by a team led by Dave Bacchus, Dr. Coleman and myself, as well as one of our teaching assistants Brian the block for a course that we taught at NYU Stern in their data boot camp course.

00:01:05 --> 00:02:16
And also this was originally created a few years ago by a team led by Dave Bacchus, Dr. Coleman and myself, as well as one of our teaching assistants Brian the block for a course that we taught at NYU Stern in their data boot camp course. And we have taken this notebook and it has been modified for today's purposes, but this was when the content was originally developed. Okay, so we are going to start by importing some packages. So first we are going to make sure that our plots are going to show up, then we are going to do our standard imports of pandas and map plotlib. We also have a new import of date time as dt and then a handful of new imports down at the bottom where we are going to import the OS package requests, IOs, zip file and SSU2. Don't worry too much about these now, we will go over what they are, but we will run these now and we will be ready to go when we get later on. Okay, so a little background on the data set that we are going to be using. So there is a group out of the University of Minnesota called the group lens team.

00:02:05 --> 00:03:14
Okay, so a little background on the data set that we are going to be using. So there is a group out of the University of Minnesota called the group lens team. And this team has gone and put together and collected a number of data sets that are now publicly available for academic use. And one of which is called the movie lens data set. So this contains millions of movie ratings by users of the movie lens website. That's where the data set gets its name and we are going to be using a small subset of this data set that contains a 100,000 ratings. This is down from about 27 million that are contained within the full data set. So the data itself comes in a zip file that we could download from the group lens data set. And inside the zip file there will be a few different CSV files containing different parts of the data as well as a handy read me file. We've gone ahead and we've downloaded the zip file and looked inside of it and we've read the read me and here are some details about the different data files that are in this zip archive.

00:03:03 --> 00:04:23
We've gone ahead and we've downloaded the zip file and looked inside of it and we've read the read me and here are some details about the different data files that are in this zip archive. So first there is a ratings.csv file and here each line in the file is going to have the rating user gave for a particular film at a particular time. Next we have the tags.csv and this would include a number of tags for specific film that a user applied. And maybe it would be a tag to say I watched this with a particular individual or a tag to put it in some sort of list. These are kind of defined by the users. We won't be using these but it does exist in case you're interested. Third is the movies.csv file. Here each line in the file is a movie name. And then we also have each line represents a movie. And the columns are going to be the movie ID, the title and the genres. And these genres are going to be most together in a single stream each separated by a pipe or a vertical bar. And then finally there's a link.csv and this would provide links to external websites if you wanted to get more information about the movies.

00:04:15 --> 00:05:27
And then finally there's a link.csv and this would provide links to external websites if you wanted to get more information about the movies. Our analysis today will focus on the ratings and the movies files. So we would like to be able to download the file from the internet and read the ratings.csv and movies.csv and to appendis data frame. And there are at least two ways of doing this. One is kind of what we'll call the more manual approach where we could use our internet browser navigate to the movie landscape. And then we'll click the link to download the file, put it on our hard drive. And then we could extract the zip archive, put the file somewhere and finally go back to our Jupiter session and use PD.reads.csv. That option is comfortable and something that we may have done a lot in the past. But there's also a second option. So the second option is to have Python automate the whole process. Python will go it will request a zip file, download it, it'll start opening it up. And it will prepare these two files for pandas to read.

00:05:22 --> 00:06:35
And it will prepare these two files for pandas to read. Of these two options, the first is likely easier at first glance because it's something we're familiar with. However, the second is going to be a lot more powerful. And so we're going to choose that option for our work today. So why do we do it the hard way? Well, first of all, it builds character. And if you haven't done things that build character, you're welcome. We're going to do this today. Secondly and more seriously, one major benefit of doing it through the second option is that the entire analysis can be self-contained in the notebook. And what this means is that there's no need for the user of the notebook to do anything quote by hand. They don't have to open up a particular website, make sure that the zip archive gets extracted into a particular place. So we can hand somebody our notebook and they can run the whole process. And finally, once we learn how to use these tools, we can apply them to other data sets. As it's almost inevitable that we'll come across an archive or compressed version of data at some point.

00:06:28 --> 00:07:49
As it's almost inevitable that we'll come across an archive or compressed version of data at some point. Be it through a zip file or a tar file and being able to handle these directly in our Python code will give us an extra tool in our belt that will likely need going forward. So how do we actually get about go about this? First, we're going to start by defining very clearly what we want to accomplish. So in words what we want is to create pandas data frames from the ratings.csv and movies.csv files that are contained in the zip archive that we could download from the group lens website. So let's take it one step at a time and try to map out what needs to happen to fulfill our want. So first we need to download the file and our strategy for doing this will be to lean on and use the request package. Second, once we've downloaded the file, we need to be able to unpack this contents that were downloaded and treat them as a file. And there's going to be some special handling. We'll talk more about that. But to do this step, we're going to use a built in Python module called the IOM module.

00:07:40 --> 00:08:52
And there's going to be some special handling. We'll talk more about that. But to do this step, we're going to use a built in Python module called the IOM module. Next, once we are able to get our hands on the file, we need to then recognize and treat this file as a zip archive. The itself contains multiple files. Again, we're going to use this with a built in tool in Python called the zip file module. And then finally, once we've been able to identify the CSVs within the zip file, we need to use the pandas.readcsv function to construct our data frames. That's the outline. We're going to go through these things one step at a time and we'll make sure that we provide a bit more detail on how they work when we get to each of them. Before we get there, there's a couple of digressions first. And we felt that this was important. The request documentation states the following. Recreation a use of other HTTP libraries may result in dangerous side effects, including security vulnerabilities verbose code reinventing the wheel constantly reading documentation to press it headaches or even death.

00:08:37 --> 00:09:51
Recreation a use of other HTTP libraries may result in dangerous side effects, including security vulnerabilities verbose code reinventing the wheel constantly reading documentation to press it headaches or even death. This is a bit like hard to but we totally agree. The request package of library is by far the easiest way to interact with websites that we found in Python. So we're going to be learning a bit more about it today. And I'm sure certain that as you continue in your programming careers, you'll be continuing to use it. Second digression is when we are constructing this solution. We knew what we wanted and we did our homework and Google the round for a solution that could work. And we ended up finding a particular the helpful stack overflow thread that let us piece together our solution. Okay, so let's get started. So remember our first step is to use the request library to download the file. So here's how we do this. In code first we have a variable called url that is just contains a string that points to the url where we can download our file.

00:09:41 --> 00:11:05
In code first we have a variable called url that is just contains a string that points to the url where we can download our file. Once we've defined this we can use the request.get function and pass it our url as an argument. We'll store the output as a variable called res which is short for response. And I may use the term res or response interchangeably as we go forward. And once we've done that we'll just print out a few things contained within this response object to see what it looks like. So we'll go ahead and run that. And so we see here that we got a response status code. So the HTTP or web language has a set of principles or standards defined in it. And one of these is called the status code. So when you, your browser, Python attempts to make a request over HTTP to a different web service. That service will do its operations and then return something. If everything was successful the convention is to return the code 200. And this just means you asked me for something. I was able to find it and I gave it to you.

00:10:59 --> 00:12:16
And this just means you asked me for something. I was able to find it and I gave it to you. So that's great. Second we want to look at the type of this response object and sure enough it's a class implemented in the request module called response. And that's where we get its name. Each of these request responses has what's called a content field. And this is where the actual data that is sent back from the external web server is contained. And when we look at this we can see that this is a bytes object. So in Python we've typically work with textual data as a string, but there's also a way to have Python interpret characters or text as bytes. And this is kind of the native way to represent or encode files. So in this case the content of our response has class bytes. And then finally we can look at the headers. Another part of the HTTP standard for we have communicating extra information about the request. Here we are able to see things like content length. This header tells us how long in bytes the response.content field is.

00:12:09 --> 00:13:34
This header tells us how long in bytes the response.content field is. There are other things like when the file was that modified what the content type is. And notice here that we have content type is application slash zip, which is again another convention for demonstrating to us the consumer of this web URL. That the content the bytes contained within it represent a zip file. So this all looks good. It's what we are expecting. And it's nice to see that returned in the response object. So step two is to read the file as a bytes object that Python can work with. So we've talked about a few different file formats in the past. CSV would be a plain text file. You can open it up in any text editor and you can actually read the characters that are there and it's human readable. We talked about other file formats like feather or parquet or excel that are not human readable. They are binary file formats. Well the zip archives and other binary file format. So in order to work with this, we're going to actually take the content that we just obtained.

00:13:26 --> 00:14:49
So in order to work with this, we're going to actually take the content that we just obtained. And we're going to wrap it inside of an instance of the IO.bites IO class. So to do this it's one line of code. We imported the IO module that was built into Python up at the top of our notebook. And now we're just going to create a new variable called bytes. That is the IO.bites IO instance formed by the content of our response. So we execute that. Everything worked okay for us. Now we need to move on to step three. So where we are now is we've downloaded the file and we've interpreted it as a binary source. But we actually have more information. This isn't just any arbitrary binary blob of data. It's actually a file with a very particular format called the zip file format. Python knows how to handle zip files intrinsically. And there's a built in the zip file module for doing this. So the next step will be to have Python understand we'll be able to tell Python or communicate to it that our bytes IO object has data that represents a zip file.

00:14:35 --> 00:16:04
So the next step will be to have Python understand we'll be able to tell Python or communicate to it that our bytes IO object has data that represents a zip file. And once we do that we'll be able to do common zip archive operations on our our data. So here we're going to pass our bytes object into the ZF, which is short for zip file zip file class. And we're going to return back something called zip and the zip file is an object that has class zip file. So that's great. Again, what we were expecting. So now that we have a zip file, we need to take a look with inside. So the zip file class and all move out of the way here. The zip file class has a handy method called name list. Now this method, it will list all the different files and folders that are contained within the zip archive. So let's go ahead and take a look at what these contents are for our file. So we have our zip object and we're going to call the name list method. And we see here that there must be one folder called ml-ladest-small.

00:15:56 --> 00:17:27
And we see here that there must be one folder called ml-ladest-small. And then inside that folder there are a number of files. There's a read me and then there's those four CSV files we talked about earlier. Now we notice that the ratings.csv and the movie CSV.files or sorry.csv files are in there. And in order to actually have pandas read this data, we need to give it that full path. We need to give it ml-ladest-small slash ratings.csv and the same for movies. Now we could just write that text out but we're actually going to just search through that list for any of the file names that includes the string movies. And since there's only one, that will be our movies, the path to our movies file and we'll repeat the same for our ratings. So that's what we're doing just down here. And we'll see here that it did correctly find the path to our movies file. Okay. Finally, we're ready to let pandas read in our CSV file. I'll move back over here to be more centered. So we're going to use our friend, pd.reads CSV and the only extra step here is that we need to call on our zip file object.

00:17:15 --> 00:18:40
So we're going to use our friend, pd.reads CSV and the only extra step here is that we need to call on our zip file object. We need to call the open method and pass the path to the file we'd like to open. So here we want to open the movie file, open the ratings file, and that will allow us to read these two CSV files into a data frame. So we'll run that. Again, everything executed without error. And let's take a look at the data and see what we got. So first we'll print out the info, which will tell us what the columns are, and then we'll look at the first few rows. So here it looks like the movies dataset has three columns, one being movie ID, which is an integer, and then it has two string columns, one for the title of the movie, and then one for the genre. So it looks also like there are 9,742 rows, and each of the three columns has a non-null value for all those rows. So we don't have any missing data, which is very helpful. We'll do the same for the ratings dataset. And here we have a user ID, a movie ID, a rating, and the timestamp.

00:18:32 --> 00:19:51
And here we have a user ID, a movie ID, a rating, and the timestamp. The two ID columns as well as the timestamp are all integers right now, and then the rating is a floating, a float 64. Okay, so we've just seen how the ratings dataset has a movie ID column, but not the title of the movie. Let's think about why this is. So the reason for this is a concept called normalization. Let's think this through. The movie names directly in the rating data frame would potentially cause each movie name to repeat it many times, because for every movie there may be many different users who are reviewed the movie. So one of the movie names we've seen so far is called Grumpy or Old Men parentheses 1995. Now thinking about this, this takes up a whole lot more room than the integer three if we were to save this as a CSV file. We have many characters just as it is one. So for this reason and others, the group plans team decided to store the movie names and genres in the movies.czv file, alongside an integer movie ID.

00:19:40 --> 00:20:53
So for this reason and others, the group plans team decided to store the movie names and genres in the movies.czv file, alongside an integer movie ID. Now this is unique for every row of that CSV file, and this movie ID is then used throughout all the other files as a way to refer to a specific movie. This is an example of a relational database technique called normalization, and pardon the typo in the word example there. So you might be thinking, well, why would we normalize? If we're just trying to save space and this is only a couple megabytes, it's probably not that big a deal. Well, there are other examples where instead of having 100,000 rows, as we do in our ratings dataset, there may be millions or billions of rows. And at that point, it really does matter trying to optimize storage space. But there's a second reason for why we would normalize that may even work compelling. So for the second point, let's consider a scenario where the group plans team wanted to add an additional column of information about each movie.

00:20:42 --> 00:21:55
So for the second point, let's consider a scenario where the group plans team wanted to add an additional column of information about each movie. They wanted to add the director or perhaps the producer of the movie. So in their current structure, in order to do this, they would go through that 9,000 line movies CSV file. They would add a director column, and then for each movie, they would add a director. There would be no duplication of movie director pairs, because each movie only shows up one time and in one row. Now, contrast this with a different version of the dataset that has the movie title and genre in the same CSV file as the ratings. If we wanted to add a director column to this file, what we would have to do is we would go through the 100,000 different ratings. We would look at what the movie title is and add the director. Now, if there were 50 users, for example, who rated a single movie, would repeat that director's name 50 times, just as we're repeating the title of the movie 50 times.

00:21:51 --> 00:23:11
just as we're repeating the title of the movie 50 times. This process of finding every single row that goes to a particular movie, could be more cumbersome and time consuming than adding a single row, or adding the director column to just a single row of the movie's data frame. In this sense, adding new features or richness to the movie's dataset was much easier when it was self-contained and isolated, instead of having it be already combined and mixed in with the ratings. So, for our analysis, however, we want to be able to analyze the ratings for specific movies, the ID, the movie ID, that integer doesn't really mean much to us, and we would like to see the title of the movie because it has a bit more context. So, we need a way to bring in the movie title into the ratings data frame. And as you're probably thinking to yourself, given what we learned a few weeks ago, this is the perfect use case for the merge functionality that pandas offers. To understand how this is going to work, we're going to do just a small example looking at the first three rows of ratings dataset.

00:23:04 --> 00:24:18
To understand how this is going to work, we're going to do just a small example looking at the first three rows of ratings dataset. So here's what it looks like. In the first three rows, we have a... The user ID column is filled entirely with the integer one. This means that the same user rated three different movies. The movie that was rated was movie with ID one, ID three and ID six. Each of these movies was given a rating of four by user with ID one, and then we have the timestamp. So let's see taking just these three rows, let's see what happens when we merge in the movies dataset on the movie ID column. We see here that the first four columns are exactly the same as what we had. However, we have an additional two columns. We have the title and the list of genres for this particular movie. Here's a breakdown of what happened. For each of the three rows in ratings.head three, pandas went and it found the value in the movie ID column. Now we can think of pandas storing that in memory or keeping a record of what the current movie ID is.

00:24:11 --> 00:25:30
Now we can think of pandas storing that in memory or keeping a record of what the current movie ID is. Once it has this, it goes to the movie's data frame, and it searches the movie ID column for all of the rows that have a matching movie ID. Once it finds one, it brings over any columns from movies that aren't found in ratings, in this case title and genres, and it brings them into the output alongside the existing columns for this particular movie ID. It would then go to the next row, find the movie ID from ratings, look up the corresponding rows inside movies, and bring over the data, and we'll do this one row at a time. The output then has all of the columns found in either ratings or movies. Now that we've kind of understood how that works with just the first few rows, let's look at what happens when we do this on the entire data set. So I'll move to the site here so we can see all of the rows that are being displayed. So what we've done is we've called the PD.merge function, passed it the ratings data frame first, and then the movies, and then we set two arguments.

00:25:21 --> 00:26:39
So what we've done is we've called the PD.merge function, passed it the ratings data frame first, and then the movies, and then we set two arguments. One, we set how it equal to left, and then on equal movie ID. Now as you remember, the how equal left argument says that the output should contain all rows found in the left or first data frame passed to the merge function. In this case that would be ratings, so the output needs to have every movie ID that can contain in the ratings data frame. The on keyword argument here says that when we're trying to match up the rows of ratings with the rows of movies, we need to be looking at the value of the movie ID column from both the ratings data frame and then from the movies one. Once we've done this merge, we print out the shapes of our three data frames now, the combined one, the ratings and the movies, as well as show the first 20 rows of our movie of our combined data set. Looking at the dimensions, we see that the number of rows in the ratings data frame and the new combined data frame is equal.

00:26:31 --> 00:27:54
Looking at the dimensions, we see that the number of rows in the ratings data frame and the new combined data frame is equal. This is what happened for two reasons. One is that we called how equal left. We passed that argument. When how is left, all of the ratings that appear or movie ID is appeared in the ratings data set are going to show up in the output. Reason number two is that each of those movie ID should up in only one row of our movies data frame. The reason the rows are the same are one, which shows how equal left. So every row of ratings is represented in the output and then second. Each movie ID from ratings shows up only once and exactly once in the movie data frame. Had the movie ID number one appeared two times in the movie's data frame, we would have actually seen that the first rating would be repeated. We'd have user one movie one rating four. And then we'd have the title of genre from the first match in the movie's column. In this case it's toy story and then if it was actually a duplicate movie ID in the movie's data frame, we would repeat the first four columns that came from ratings.

00:27:45 --> 00:28:55
In this case it's toy story and then if it was actually a duplicate movie ID in the movie's data frame, we would repeat the first four columns that came from ratings. And then we'd have the new title in genre that appeared in movies. That's not the case here. We have a perfect one to one mapping between the movie ID in the ratings data frame and the movie ID in the movie's data frame. Finally the number of columns here is going to be the first four columns that come from the ratings data frame. Plus all of the non movie ID columns from movies in this case that's going to be two and so we end up with six columns. So at this point now that we have our combined data frame, we're ready to do a little bit of analysis. And this is going to be the last part of this section of the Pandas review and we want to do this exercise together. So some of the things we're going to ask you to do, you already have the tools for, but some of them you don't quite yet have the tools and the reason we're doing this is we're trying to motivate one of the concepts we're going to be talking about next week when we go into

00:28:40 --> 00:30:01
So some of the things we're going to ask you to do, you already have the tools for, but some of them you don't quite yet have the tools and the reason we're doing this is we're trying to motivate one of the concepts we're going to be talking about next week when we go into what are called group by operations. You'll see here soon. What we'd like to do now is pause the video, we want to work through and talk through these things together, be able to ask questions and answer them. Okay, welcome back. I've moved myself for physically and on the screen so that I can be a bit closer to my keyboard. So let's go ahead and we'll work through each of these examples one of the time. So in order to under to get the average rating across all movies and all users will be able to use the mean method on the rating column. When we do this we see that the answer is three and a half, which on a scale from one to five makes a lot of sense. It's fairly in the average of that range. So next we were asked to find and try to understand the distribution of ratings and the way we want to do this for our answer was to compute or to display a histogram of the data.

00:29:48 --> 00:31:09
So next we were asked to find and try to understand the distribution of ratings and the way we want to do this for our answer was to compute or to display a histogram of the data. Of how many ratings fell in each bin and what we're going to do here is at the top we have a map plot lib version of this and at the bottom we have a plot lib version. So using to be the same graph effectively, but they're going to be using two different libraries and we're just going to show you this for variety. So the first thing to notice here is that we have the bins that we're creating and this is going to be equally space starting at 0.25 going all the way to 5.25. So when we do this we're telling pandas and map plot lib to count the number of ratings that occurred in each of these intervals that are each half a rating wide. So this very first interval would be from 0.25 to 1 and then so on. Now we see here that there's kind of a peak that it seems like the mode or the most likely most common rating is a 4 and there are also kind of other peaks at 5 and then again just below 3 and the way I might think of this is.

00:30:52 --> 00:32:11
Now we see here that there's kind of a peak that it seems like the mode or the most likely most common rating is a 4 and there are also kind of other peaks at 5 and then again just below 3 and the way I might think of this is. If a user is going to go and write a review it seems more likely that they're going to write a review about movies that they like. There seem to be. A handful of movies that get rated as top ratings by a lot of people and then fewer ratings just beneath that bar so once you've crossed the threshold of going past four. It's more likely to get to five than you stop at four and a half and then the idea that the average rating would be a four. Again, reinforces the idea that there are more users willing to rate movies that they enjoy than ones that they didn't. So let's take another look at the same. Graph with this time using the plotly plotting library. So now it's going to be the same thing but here we'll see that it's interactive we consume we can scroll we can hover over things and it tells us that there were 26,000 people who rated between four and four and a half for example.

00:31:58 --> 00:33:14
So now it's going to be the same thing but here we'll see that it's interactive we consume we can scroll we can hover over things and it tells us that there were 26,000 people who rated between four and four and a half for example. Okay, so third is we were asked to find the average rating of each movie so now one way we might do this is we would first use our indexing knowledge to say okay if we wanted to look at the same movie thirty one. We would get all rows that are of course bonding to movie thirty one we could take the rating column and compute the mean. And we do this we see that for this movie the average rating is about three point one eight. However, instead of having to repeat this either in a loop or by hand for every different movie idea all nine thousand of them. We would actually wait to let pandas do this for us and this is utilizing something called group by. This is something we haven't learned yet and we'll cover in detail in the next two lectures on pandas. So don't worry just for now be a consumer of this and just be.

00:33:06 --> 00:34:25
So don't worry just for now be a consumer of this and just be. When I first saw it marvel at how great this is so what happens is we can look at just the rating column. And then we're going to group by the movie idea column and compute the mean and what pandas does is it will say for all it'll collect. In one by one through all the different movie ideas it will collect all rows with that particular movie idea. Then it will grab the rating column and compute the average of just those rows. Very similar to what we did up here from movie thirty one but pandas is doing this. Letting movie idea vary from one all the way to the very last movie idea which appears to be one hundred ninety three thousand six hundred nine. So in a matter of a couple seconds or less than a second let's see how long it took pandas on my machine. In a matter of four milliseconds pandas was able to compute to figure out which rows belong to each group of movie ideas. And then compute the average of rating for only those rows and it did that for all nine thousand seven hundred twenty four movie ideas.

00:34:15 --> 00:35:27
And then compute the average of rating for only those rows and it did that for all nine thousand seven hundred twenty four movie ideas. And so by functionality and pandas is almost a superpower and it's something that we're very excited to teach you but we couldn't resist showing it off a little bit here. The last question was similar to the one just before it so here we asked you to count the number of ratings for each movie. So did you this it's the same code except we're going to replace the movie or sorry the mean method with count. So here we're going to look for a single movie we're going to look at the rating column count how many ratings they were it's like there were thirty eight. And then we're going to use this magical group by and instead of calling the mean method we'll call the count method. And we see that we get back a data frame with all the rows one for each movie idea and then the number of times that movie was rated. Hopefully this is what your appetite a bit for the group by concept and we're going to be talking about it in much more detail in future lectures.

00:35:18 --> 00:35:45
Hopefully this is what your appetite a bit for the group by concept and we're going to be talking about it in much more detail in future lectures. The last note we'll offer here is there are more resources for learning how to do merging and cleaning data sets the pandas dox are fairly good. But there are better guides out there we recommend one by data carpentry if you follow this link you can see that there. Thank you.

