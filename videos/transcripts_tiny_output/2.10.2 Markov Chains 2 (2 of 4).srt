00:00:00 --> 00:01:48
Okay, so now we are ready for our lead example of a Markov chain. Something that we really want to talk about, the economics and statistics of. So this is going to be a version of a famous model called the Lake model of an instance unemployment, but it could be some Lake model of other things. So we are going to consider a worker who at any given time T is either unemployed and we will call that state zero if he is unemployed or is employed state one. So employed means he or she has a job. Unemployed means does not have a job, but it is looking for a job. And suppose that over one month, if you are an unemployment, if you are an unemployed worker, you find a job with probability alpha. So alpha equals the probability that an unemployed worker finds a job with his next draw. But an employed worker could become, so basically we have an unemployed worker could switch to become an employed worker with the probability alpha. And employed worker sometimes becomes unemployed with probability beta.

00:01:38 --> 00:03:55
And employed worker sometimes becomes unemployed with probability beta. So in terms of our Markov model, we are going to have the state space. Here we go. The H equals zero one. There we go. The transition probability, we go from zero to one with probability alpha. We go from one to zero with probability beta. And then because the row sums have to sum to one, we automatically can fill in the whole matrix. So this is our first to cast matrix. And if I supplement that with some probability of your employment state, let's call the employment state, if I supplement that with a probability distribution, which would look like this, let's say I will just just make this up. I'll call it pi zero just to make sure, let's say it's 20% chance you're unemployed. And 80% chance that you're employed at times zero, I'm just making this app. Then the pair, pi zero, that is a Markov chain. And that Markov chain generates a probability distribution over our entire sequence, an entire infinite sequence of the random variable employed versus unemployed.

00:03:35 --> 00:05:52
And that Markov chain generates a probability distribution over our entire sequence, an entire infinite sequence of the random variable employed versus unemployed. So our random variable would take like two values zero or one. And so a history of a person, a history of a person might look like starts out at times zero being unemployed. Find the job, find the job, find the job, stay in the job, stay in the job, stay in the job, get fired, still unemployed. So this sequence, going on forever, describes the life history of the worker. So if we know the values of alpha and beta, we can ask all sorts of questions. We could ask what's the average duration of unemployment? We could ask over long horizon, what's the fraction of time that a worker finds yourself unemployed? We could say conditional unemployment, what is the probability of becoming unemployed at least once over the next 12 months? That's a complicated event, but we could figure that out. That's going to be useful. I want to take a little detour now and show you some, and show you a little bit of properties of geometric distribution and important distribution.

00:05:31 --> 00:07:18
I want to take a little detour now and show you some, and show you a little bit of properties of geometric distribution and important distribution. Okay. So you're going to see why we do this in a minute. So geometric distribution is, this is going to be a random variable. And we're going to let PB, the probability of what we're going to call success. And one minus PB, the probability of failure. This is actually one Bernoulli, it's a Bernoulli trial. That's all this is. But now what we're going to do is we're just going to repeat. We're going to take a sequence of independent Bernoulli trials. And we're going to form a certain random variable, which I'm going to tell you about. And the random variable we're interested is, is this, it's the times in a sequence of Bernoulli trials. It's the time before we get one success. So I'm going to take a sequence of draws. And I want to know the probability of K failures. Before the first success. And K is going to be go from 0, 1, 2, on to infinity.

00:07:12 --> 00:09:12
And K is going to be go from 0, 1, 2, on to infinity. And I'm going to let Y, I be the value of the random variable success of failure in the Ith trial. So if I just take a sequence of Bernoulli trials, I'm just going to get a sequence of 0s or 1s. So I want to compute this probability. So here goes, let's compute it. Well, I want to compute, I just go, I do not skip steps. I write down what I want to compute. I want this, the probability that Y equals 0, Y1 equals 0, Y1 equals 0, YK1 minus 1 equals 0. And then finally, this is my first one. I want to compute the probability of this. This is what I want to compute. And I know that my draws are independent. They're independent. Why? Because I'm assuming it. OK, so now I just write, I use independence. This, the probability of this is of that, that's a joint distribution. No, that's a joint distribution. I want to compute, you know, that's a probability that comes from the joint distribution. I now use independence. So the joint distribution is just the product of the marginal distributions.

00:09:06 --> 00:11:12
So the joint distribution is just the product of the marginal distributions. That's independence. So I write that down. So that's just the probability of Y0 equals 0, probability of Y1 equals 0. That probability of YK minus 1 equals 0. Finally, times probability of YK equals 1. Now I just copy. Well, this is equal to 1 minus p. Where? I got that from here. This is equal to 1 minus p again. 1 minus p k times and then finally p. Get that from here. Isn't that beautiful? And then I just collect. So that's equal to this. 1 minus p k times times p. So when I set up the draws like that, how long do I have to wait? That's the probability. So this is a probability that's a probability distribution. And it's a waiting time. It's called a waiting time. To my first success. And it is called a geometric distribution. Well, why is it called a geometric distribution? Well, it's because of this factor. 1 minus p raised to the k. That's a geometric series. So this is called a geometric series. And then it's just normalized so the probabilities add up to 1.

00:11:08 --> 00:12:48
And then it's just normalized so the probabilities add up to 1. So we'll notice if you calculate summation 1 minus p to the k times p. Some that up use your high school knowledge of geometric series. We get 1. Okay. So now we could calculate the expected time to first success. And this is a name expected time to first success. This is called expected waiting time. We're going to use this in a minute in this lecture in a really fun way. So if you just calculate that now, this is a little tricky to calculate. Well, we calculate the expected time. I'm just going to calculate the mean. How do I calculate a mean? I take summation k. Go from 0 to infinity. Those are all the values. I multiply the values of the random variable times the probability, which I just read off from my probability distribution. If you sum those up, I'm not going to derive this here. But if you sum this up, you can check it on a computer. This is just equal to 1 over p. So 1 over p is the expected waiting time for a geometric distribution.

00:12:39 --> 00:14:37
So 1 over p is the expected waiting time for a geometric distribution. Okay. And we're going to see why I did that right now. So let's return to where we were before. And we have this quote unquote lake model. We were talking about. We have this mark off chain. And the probability, if we come back up here, the probability that an unemployed worker moves into employment is in any given period, the probability of success, the probability of a success is alpha. We'll call that a success. We'll call the failure is the person stays unemployed. So what we can read right from this is the expected waiting time. Here is just 1 over alpha. That's 1 over alpha. So that's the expected duration. That's the average duration of unemployment. That's the average duration of unemployment for an unemployed worker who fits this model. And now we can come up here. Success is just a definition. We have an employed worker going the other way. An employed worker here, a quote unquote success. It's a bad word now in this sense.

00:14:35 --> 00:15:46
It's a bad word now in this sense. Success is the employed worker becomes unemployed. But we have a waiting time distribution. So if we do a calculation, what's the average duration of employment? Well, this will turn out to be. It won't be this. We could figure that out. So the average duration of. Yeah, so let's I'm going to ask you to figure that out as an exercise. And maybe I'll stop this now and ask what's the average duration of employment. How long do you keep a job? That's an interesting number. It's going to depend on data. And we'll be able to calculate that. So why don't you work on that? And I'll work on it for a minute.

