Hello, this is Spencer Lyon and in this lecture we will be learning about how to handle temporal data with pandas.
By temporal data we mean data that has some notion of time or a period.Before viewing this lecture you should be familiar with and comfortable with defining Python functions.Specifically Python functions that can consume a pandas data frame or series and then operate on it.Additionally it would be helpful if you have viewed the group by content and are comfortable with how pandas represents the group by object and allows you to operate on it through built-in functionsbuilt-in functions as well as applying or aggregating based on custom functions.Our goals for this lecture will be to understand how pandas handles dates.One of the some of the things that we're going to understand after this lecture is how to parse a string into a date time object.Date time is both a built-in Python object and a pandas extension type for handling both dates and times.We will know how to write out our dates and custom formatted strings that may be a requirement for various applications we're working on.We'll also work through how we can access specific fields associated with a date time, something like the day, the month, year, minute, hour, or second.We're going to do this from a date time index where the date data is on the index itself, as well as when we have a column or a series with the date time data type.Finally we will do a bit of computation using dates and we're going to be doing both rolling computations like a moving average as well as resampling operations like moving from a weekly to a monthlyweekly to a monthly frequency.We'll work on a few examples of each and we'll try to understand the difference between the two and when we would apply each one.We'll be using some artificial data and we'll also be using some data from the real world.
The data we'll be using is the Bitcoin to US dollar exchange rate between March 2014 and the present.We'll obtain this data from Quandal but also provide a CSV file with at least a subset of this data in case there are connectivity issues.This is most of what we talked about and here's the outline of a bit more detail.
You're following along with this notebook and you do not have the Quandal library installed.You can uncomment this line right here as follows and then execute it and it will go ahead and install the Quandal library for you.If I execute this it tells me that the requirement was already satisfied and so I will
re-comment it and we can move on to the next slide.Which is the next code cell in this code cell we're just going to be doing some imports.
These three we should be familiar with. Here we're going to import.We're going to set up the Quandal library to use our API key.We've created one specifically for viewers of this lecture but we have a note at the end for how you could obtain your own if you are going to be accessing more data from Quandal.And perhaps hitting some data usage restrictions based on this shared API key.Then we're going to set up a plotting theme to make our charts look a little bit nicer than the standard map plot lib style.
This code executed well and we'll move on to the next slide.So Pandas has extensive support for handling dates and times.
And we as the instructors are very thankful for this working with times is a complicated issue.When trying to reason about times to with a computer you have to be aware of and instruct it how to handle things like leap years or different holidays or calendar events.You also need to think about things like time zones and daylight savings time.
All of these things are complications that are taken care of before us by the pandas library.We're going to loosely refer to data that has either a day or a time or both information has a time series data.This time term time series mostly comes from the subfield of statistics that aims at analyzing data over time.
And we will be using that same language as we refer to data with a temporal element.Let's dive into exploring pandas time series capabilities.
Some of the topics that pandas provides are some of the main features that it provides is the ability to parse a string into a date.In other words, if we're given a textual or string representation of a date or a date time, pandas can convert that into a proper date time object for further use.You can also start with a date time object and write it out into a string. This would kind of be the inverse of the first point.There may also be computations we'd like to do based on parts of the date time or the time stamp.And we'll learn how to extract those when the time stamps either living that data frame or series or the index.We'll talk about how we can shift or adjust data through time by taking a lead or a lag.
And then we'll also talk about resampling and rolling operations.And we want to point out here that like other topics, but probably even a bit more for this one, we're going to skip a lot of the functionality that pandas offers.And we're going to cover the basics and we should be comfortable with them, but we encourage you to look at the official documentation for even more information.The first thing we'll learn how to do is to parse strings as dates.
Because often when we read in data from a file, perhaps a CSV file, the dates will be written as strings.If we're lucky, these dates will follow some kind of structured pattern, a very common pattern that we've seen in our work is the following where we have four digits for the year separated by ayear separated by a hyphen, two digits for the month, another hyphen, and then two digits for the day.For example, we could write Christmas Day in 2020.
Let me fix that. That's follows. We would first start with the four digits for the year, which should be 2020.And then a hyphen, the two digits for the month, because December is the 20, there's the 12th month, we'd write a 12 here.
And then Christmas is on the 25th of that month, so we would write a 25.Let's go ahead and evaluate that cell. So we have this variable for us later on.Now, in order to do time series like computations on this, we need to move from the string form into a proper date time.
The panda's date, the panda's two date time function does this for us.So we'll call PD dot two underscore date time, and we'll pass in the single argument Christmas string.When we do that, we're going to save the variable as Christmas, and we're going to print out that it has a class pandas do do do do dot timestamp.Well, the timestamp represents the single moment in time.
Now, when we display this string or this value Christmas, instead of seeing only the string we started with, we see that it's a timestamp.Notice that in addition to the date, pandas also provides the hour, minute, and second corresponding to our timestamp.We didn't supply that our Christmas string that we passed in was only the part I've highlighted here.And pandas set the minute or the hour, minute, and second to its default value of zero, meaning midnight on Christmas.Now, the pandas to date time function is actually pretty smart at guessing the format of the date.So if what we're going to do in this experiment is we have here a list of different ways that we could write the date for Christmas in the year 2020.The first one we're going to write out the full month.Then the day comma year, we could do an abbreviated version of that we could start with the day of the week before we can even flip the order around where now it's going to be the two digits for thetwo digits for the day and abbreviation for the month in 2020.And we can even append the suffix th as if we were talking about the 25th of December.When we execute this cell, we'll see that in each case pandas is able to produce the exact same date or exact same timestamp object.Which gives us the assurance that it was able to correctly identify the pattern contained in each of these strings.It's quite impressive as there are an infinite number of ways you may write this type of information and pandas seems to be able to handle the most common formats without any extra help from us.However, there are some cases where pandas won't be able to guess things.So for example, if I was a seller on the website Amazon and I were to get back a report from them on each order that was placed for one of my products, there would be a column in the data set thatthe data set that had timestamps formatted as follows.So looking at this, we can kind of tell that the date here is going to be the 25th of December 2020.However, if we were to try to ask pandas to be this for us, it would fail. So when I execute this cell when I try to say two date time, it's going to tell me that it doesn't really understand how tounderstand how to go from the string we gave it into a string.Mayor, sorry, into a date time object says that there was an unknown string format.
So what do we do? Well, one option would be to manually manipulate this string and only keep the first part of it.So let's see if we were to keep just the first say 11 characters, we would be able to cut off right here after the 25th.And it produces a timestamp for us. If we do anything else, it's going to start to fail.And now the 11 must have included the T. So now if we go only the first nine characters, we only get up to this point and now pandas gets it wrong.So we were talking about December 2nd instead of December 25th, because when it saw the single digit two after the last hyphen, it must assume we wanted the number two.And this is more canonically written zero to you.
Anyway, one option would be to manipulate the string. However, there's actually a more powerful method that will learn next.But in order to have pandas parsed that without us changing the input, what we can do is we can utilize the format argument of the two date time function.So when we execute this, we pass in the same string that was causing us problems before, but now with the additional format argument, we see that pandas is correctly extracting the timestamp.Now, if we stare at this Amazon and what this funky suffix, I gave it string f time.
We'll see that it relates very closely to the string m is Christmas Amazon.We encourage you to take a moment to compare this string to the one below and then we'll talk through it.So let's show both of these strings. And now notice that the overall structure or format is very similar.But where everywhere we had a number in the Christmas Amazon variable, we have some kind of placeholder, some strange percent letter placeholder.But the idea is there's something and then a hyphen something else a hyphen something else the letter T and then a colon a colon plus space zero zero space colon zero zero.So now the way pandas was able to interpret this is it used the string format time the string f time variable.
As a template or a format for how to extract different parts of the date.In this example, the percent capital Y was an instruction to pandas to look for a four digit number representing the year.The percent lowercase m constructed pandas to look for a two digit number in this location representing the month of the date.
We can see you could probably guess here what the D H M and S represent.But instead of guessing what will encourage you to do is look at the Python documentation for a list of all the possible percent something patterns that would be accepted by the format argument.We're going to give you an opportunity to practice this by performing the following exercise.
First we'd like for you to open up the link to the Python documentation in the previous cell.And then with that open look at the following three strings. So what we would like for you to do is using the documentation page.We would like to construct a argument for the format variable of the two date time function in order to be able to parse each of these strings.Essentially, when we in our example, a minute ago, we're able to construct this format string in order to parse the Christmas Amazon variable.We'd like for you to construct similar format strings for the three dates that appear in the exercise.And we will not be working through this exercise together in class as we will leave it for an assignment.
Now let's think let's talk through how we could work with more than one date at a time.So the pandas to date time function is also pretty intelligent about figuring out how to handle this tuples series or other collections of date looking things.And just as it was able to guess how to interpret the following the date of Christmas, it's also able to interpret a list of things that look like dates.We'll just do this one example just to demonstrate that it's possible and that we can pass in a list of dates and get back what's called a date time index.So let's talk about this further in the lecture, but all of the things we've learned about the date time argument, including what format of string is automatically identified by pandas, as well aspandas, as well as the different ways we can instruct pandas to interpret the strings using the format argument.These things all apply equally to a collection of dates in addition to just the one that we saw previously.Often when working with multiple dates in a time aware data set, the dates will have a regular frequency or spacing in between observations.We could use the PD dot to date time function, we just learned about by passing a string representing evenly spaced dates in order to construct this type of value.However, this is more work than we need to do.
Pandas provides the very convenient date range function to help us construct ranges of regularly spaced dates.There are two basic forms for calling the date range function.
In the first approach, we pass to PD dot date range, a start variable, an end variable, and a frequency variable.The frequency variable is passed to the freak or F R E Q argument.The second approach would be to pass start, not pass ends, but instead set the keyword argument periods equal to some number N and then again set a frequency.Now, in these examples, start an end, represent a timestamp or anything that PD dot to date time can recognize as a timestamp.Frequency would be some kind of frequency string like D for daily or A for annual.We'll talk more about these shortly and then N is some integer representing the number of periods we'd like for pandas to generate.
Let's test it out.Let's test it out.
So we'll start with passing, we'll start with the first form where we pass something for start something here for end.And then a value for the freak keyword argument and here we're going to pass a and what happens is pandas starts in the year 2020 goes one year forward because we picked an annual frequency to 2021,frequency to 2021, 22 and 23.If we were to omit the third argument omit the frequency argument pandas uses the default frequency of daily.So here we're passing start and end and implicitly the frequency argument has its default value of daily and we're getting all the days between April 1st 2020 and April 25th 2020.Now we'll try the second version of the function where we pass the start and a number of periods and we'll see here that this example returns the same thing as previous one we start at April 1st 2020at April 1st 2020 and we continue forward for 25 periods.Now because the freak argument has a default value of d for daily we get the same answer here we could change this to something different like hourly and now we're going to see that we get back morewe get back more data and we're seeing we get back slightly different data.So instead of seeing every day between April 1st and April 25th represented we're actually going to be seeing the first all 24 hours belonging to April 24th for the first 24 of our 25 observationsour 25 observations and then the 25th one would be the very first hour of April 2nd.So if we were to change this to something different like M for months we see here that we have 25 data points still but now we change one point to the next changes months.The frequency strings we've been using are known as an offset alias in the pandas documentation and there are a lot of them.So here we've actually included a table taken from their documentation that describes all of them.Not going to walk through all of them but you see here that we have the calendar day that we were using we have a or why for yearly h for hourly M for monthly and then a whole lot of other ones thatof other ones that we haven't used yet.Chances are the types of frequencies you may be interested in for your analysis are probably represented here in one of these offset aliases.If that wasn't enough pandas goes a step further they also offer something called an anchored offset these are going to be represented as a suffix on the offset alias and what that does is it tiesdoes is it ties the date that's generated to a particular point in the range.It's a little confusing so let's do an example if we had a for annual pandas would generate timestamps for the last day of the year.If we instead use the frequency a dash ma r for March pandas would instead return the last day of the month of March for each year.It was generating the time stamp now the list of anchored offsets is even longer so here we'll just provide a link to the documentation and we'll encourage you to take a look on your own time.At what the different anchored offsets are.The next topic we'll talk about is called the time delta and this arises in the case that we need to do arithmetic on our dates or on our timestamps so for example suppose we had two timestamps wetwo timestamps we have the original Christmas timestamp we defined before which represented December 25th 2020 as well as a new timestamp we're defining here called new year representing January 1st.We'll now subtract Christmas from New Year's.
Culturally I'm not sure what you get if you take away Christmas from New Year's however in pandas world this actually returns something useful to us.We stored it as a variable that was named diff and we see here that if we ask for the type of diff we see that it is a pandas stuff stuff time delta object.Now a time delta represents the difference in timestamps when we have pandas when we have Python or Jupiter print this for us.We see here that the time delta argument has 359 days 0 hours minutes and seconds so there are 359 days in between Christmas and New Year's.As mentioned before a time delta object will represent the difference between two timestamps these objects have various properties like days.Notice here that the days was equal to 359 consistent with the string we saw before and the seconds is zero also consistent with the string representation what we didn't see was that we had diff dotwe had diff dot days.Time 24 hours in a day time 60 hours minutes in an hour time 60 seconds in a minute we didn't see that diff dot seconds was equal to this number 31 million 17 600 seconds.The reason for this is that the time delta stores how many of each unit is needed to make up the total difference so in this case we had 359 days was precisely the difference between our twobetween our two timestamps because they both had hour, minute and second all set to zero so we didn't need any seconds in order to compute the difference between the two dates.If we have a time delta object like the diff that we have as well as a timestamp and we add them together we go back another timestamp so in this case New Year plus diff is actually equal toactually equal to Christmas.This makes sense because remember we computed diff equals Christmas minus New Year.
And if you just do some algebra here you'll see here that Christmas must be equal to New Year plus diff.Thankfully the time delta and timestamp arithmetic implementation in pandas does satisfy this basic algebraic concept.Time delta objects can also be used as part of arithmetic expressions here we're going to compute 10 times diff and what we see is that we have 3590 days instead of the original 359 days found in359 days found in diff.The interpretation here is that any integer n times a time delta object is going to be the the full duration of that time delta repeated n times.In addition to getting a time delta by subtracting one date from another we can also construct a time delta by hand using the PD dot time delta constructor.So here we're going to set the days hours and minutes keyword arguments and we'll construct another time delta.So here the string form lets us know that our time delta represents one day four hours and three minutes.
If we add this to Christmas what we should see is December 26th 2020 at 403 a.m.And indeed when we do that we do see that we are December 26th 403 a.m.
So our time delta that we constructed by hand and added to Christmas led to our expected result.Common technique that we've employed many times in our code is to create a variable representing a quote standard or often used time delta.Then we will leverage this scalar multiplication plus addition operations in order to adjust the timestamps found in our data.So let's see an example. We might construct a variable named one day that is equal to a time delta object representing one day.Similarly one hour would represent one hour. Now we can do arithmetic directly on these two times delta's and they will combine their total time delta.So here we have one day and one hour. But we can also do things like compute a variable for Christmas day in 2021 by doing 365 days times our one day and then adding that to Christmas.And you'll see here that we still have December 25th but this time the years 2021 instead of 2020.We can continue to do more time delta arithmetic by subtracting off one hour and the expected result should be December 24th at 11 p.m. or hour 23 in the year 2021.So this is the last hour of Christmas Eve in the year 2021.
We will use this very often if we ever need to do computations directly on one day to the next one hour to the next or anything like that.We previously learned how we can use the percent pattern format in order to have pandas read a specially formatted string as a date.We can also use this same format in order to have pandas go from a date object into a string formatted how we like.So for example, let's remind ourselves that the Christmas variable in the pandas timestamp with the date of Christmas to the near 2020.Now we're going to use some of the slightly less common formatting options for the string format time method.
Or from then these again come from the table in the Python documentation.What we'll do is when we evaluate this cell, we see here that we wrote we love percent a space percent b space percent d parentheses also written space percent c close parentheses.So pandas returned when we passed in when we passed that string to the string format time method spelled s pr f t i m e on our Christmas variable was we love Friday December 25 also written fri25 also written fri December 25, 002020.So notice here that these formatting placeholders that we used in order to create date times from strings can also be used to go the other direction.We haven't exercised where we give you a chance to practice this.What we like for you to do is use the PD dot to date time function to create a variable expressing the birthday of one of your friends or family members as a date time object.Then we like for you to call the string format time method on that new variable you just created to write out a message that looks in the same format as this.The date will be different for the birthday that you chose.
But the overall structure of the string should match what you see here.We will now turn to learning about how pandas can help us to extract data or subsets of data from a data frame or series with temporal information.Now most often when we have a date time column or date time information, it will be found on the index because often an index.
Often the date is used to help us identify an observation.Now if we do have the date values on the index.
And it's the only level of the index pandas will create for us a special index called of type date time index.And this is the case we have a lot of flexibility and power for accessing subsets of data with an ocean of time periods.We will do this using the already familiar dot lock access or property of the data frame in the series.But when there's a date time index against additional flexibility and opportunity for accessing data.And the fact is that while the examples we will show have a single level index with date time data.
The same features and opportunities would work with a multi index.And especially when that in the dates are on the left most part or the outermost part of the index.
It's easiest to understand how this works by looking at an actual data set.So what we'll do here is we'll load up a real data set.And we'll use the quantum library to load a data set containing the exchange rate between Bitcoin and the US dollar from March or sorry from May of 2015 to roughly November of 2020.And here is the code for asking for this data from a bundle.If for whatever reason there are network issues, we also prepare to CSV file that you should have received in conjunction with this notebook.That's called BTC underscore usd.csv that contains the data we extracted.
We'll go ahead and let quondle get the data for us.And then we'll ask to print out the info about the data frame as well as look at the first few rows by using the head method.
We see here that we have a date time index and that there are 2,381 rows.The values on the index go from May 1st, 2014 through November 5th, 2020.
In addition to this index, we have 7 other data columns.
The first four have to do with the price of Bitcoin.They are open high low close.
And this for each date or each row in our data frame, this would represent the first transaction price between Bitcoin and US dollars on that date.The highest price, the lowest price, and then the last or closing price.We then have two notions of volume, how many units of Bitcoin were transacted on each day, and then what is the total US dollar value in the currency or start in the United States dollar.And then finally, there's a weighted price.
Now notice that because we have the dates on the index, we are able to do some additional things.For example, if we wanted all the data for the year 2015, we would get our data frame, go to the dot lock accessor, and then pass the string 2015.Notice that while we get back, the index starts at January 1st of 2015 and ends December 31st, 2015.
And there are 365 rows in our data set.This corresponds to one row per day in the calendar year for 2015.
Notice also that we're getting all the columns back.Now compare this to what we would have previously gotten using our knowledge of the dot lock accessor, if we didn't have a daytime index.What would have happened was this string would have been interpreted as an actual item to be found somewhere on the index, and it would have returned all rows where the outer most layer of the indexlayer of the index was equal to the string 2015.This is very different from behavior when we have date time information on this left or outer most layer of the index.In addition to looking at a whole year, we can actually go and look at one month at a time.
We can pass again to the dot lock accessor.We've got the last August 2017, and we're going to get back a data frame with rows starting from August 1st down to August 31st, show total of 31 rows, and again all the columns.In addition to spelling out the word August, we could also use its two digit numerical abbreviation to get back the exact same data.Now we'll point out here that the same properties we already know and understand about how dot lock works apply here.The first argument past dot lock here, the only argument is used to extract a subset of rows or subset of rows, it's used to index, it's used to extract values using the index.If we were to pass another value here, this would allow us to specify certain keys or labels on the columns.For example, if we pass a list of the strings open and high, we'll get back just these two columns.
All of the knowledge and experience you've gained using dot lock will still carry over.We just get additional flexibility by being able to specify dates and periods and get back a whole subset of rows that pertain to in this example, August 2017.Now we don't need to stop it just a month, we can build down to a day.Here we ask for August one 2020 and what we get back is a series. This contains seven rows in our series, one for each of the columns in our data frame.And we can get back to the same data using the two digit month, two digit day, four digit year to reference the same date.So here's a question to think about and that we'll answer here is what type of things can we pass to the dot lock access or property when we have a date time index.And the general answer is that anything that can be immediately converted to a date time using the PD dot two date time without needing to specify the format argument.Is valid to be the first argument to dot lock.
In other words, anything that pandas automatically recognizes as a date can be used as the first argument to the dot lock accessor.And the behavior is that pandas will return all rows where the date in the index has some notion of belonging to the date or period that we passed in.We saw this before when we asked for the month of August 2017, we got all rows that if you were to ask somebody is this date in August 2017.The answer would be true for all 31 of those rows that we got back.So just how we've used the colon operator in other indexing operations to specify a range of values to extract we can do the same with dates.Here we're going to extract the pricing information starting at April 1st 2015 going through April 10th 2015 notice here that the endpoints April one and April 10 are both included.This is slightly different than what you would see with a Python list or a numpy array where the end point is not included here.
Everything is inclusive on both boundaries.But again, we only passed one argument. This was used to filter rows and all columns were returned.
We'll introduce this next exercise here.So for each item in this mark down list that appears below extract the data specified in the bullet point using or from the BTC USD data frame using the dot lock accessor.So we'd like for you to get the data starting at July 2017 and going through August 2017.
We'd like for you to go from April 25th 2015 through June 10th 2016 and then finally October 31st 2017.As with other exercises in this lecture, we will leave this one as an assignment to complete outside of the lecture.We'll now move to understanding how we can access different properties of the date information.
Once we've made pandas aware that it should be recognized as a timestamp or date time object.The things that we may want to access are what is the month, minute, second or hour corresponding to the date.When we have the information as the only level on the index, we can use the data frame dot index to access the index and then we can use dot blank where blank could be year month or whatever part ofor whatever part of the date we'd like to access.Let's see an example.
We can look at the BTC USD dot index dot year, which will start from 2014 because our earliest dates were in May of 2014 and then it will continue on through 2020.We can also ask for the day and here we get a one corresponding to the first day of a month and then at the very end, we're going to see here that this 31 corresponds to October 31 2020.And then we see here represented the first five days of November 2020.We can do the same thing if the date time information is actually a column of the data frame instead of the index, but we have one more step.So for we were able to do DF and then access the index and here we're replacing that with bracket and then pass a string for the column name.And then the extra step here is that we can't just go straight to dot year or dot day, we have to insert an extra dot DT.And what this does is the first step once we've access the column, pandas will give us a series, the D type of this series will be something like PD dot timestamp.Now whenever pandas has a series with a timestamp D type, there is a special property dot DT.And then allows us to go in and access different components of the date time, such as the year, month, or hour.
See how this works.For example, so we're going to start with the BTC USD data frame and then we'll call reset index, which will move the date values from being the index and now they're actually a column sittinga column sitting alongside the pricing and volume information.Let's see here as we show the first five rows that this transformation happened.Now we can access the column as follows once we've done that, we can use our dot DT to get at the date time properties of this column.And then we can ask for which property we can tell pandas which property we're looking for here. It's the year.If we do that, we get that the first five years are 2014, which is consistent with what we're seeing up there.We can do the same thing with month, the only thing changing between these two code cells is we've swapped out year for month.And we should see five reported because for these first five rows, the month is all May or the fifth month of the year.The next topic we'll cover is the notion of shifting the rows of the data around or constructing leads or lags of the data.Now the motivation here is that often when we're doing time series analysis, we may want to compare the data at one date against the data at a different date.If these dates are on the index, this can be somewhat difficult because as you recall pandas will align arithmetic operations and other operations based on the index values.So if for example, we wanted to compute the percent change in Bitcoin price from one day to the next.We can't do this directly using a series because the index values would need to be a little bit different.They need to be shifted so that when we say, for example, we wanted to compute the percent change between July 4th, 2020 and July 5th, 2020.So what we would really need to do is have one series representing the actual date on July 4th, the actual closing price.And then we'd need to have a different data set showing the actual closing price from July 5th, but have the index show July 4th.
So the only do the operation, everything is aligned for us.Now thankfully pandas makes this quite easy and convenient for us using a method called shift.Now if we just call shift on a date time indexed data frame, what it will do is it will roof all the data forward one period and fill the rows with missing data.
So let's see what this looks like.We'll look at the first five rows of RBTC USD data frame and notice that on the first row, the opening price was $449.Now if we shift the data and then look at the first five rows, what we'll see here is now that the first row is entirely missing data.And the date correspond or sorry, the value corresponding to the date may second 2014 now reads that $449.0.
So what happened was these four rows highlighted up top were all shifted down one date.So now the 449 instead of corresponding to the actual date of May 1st is now lined up with May 2nd.
Similarly, the data for May 4th at $4.39, $439 now applies to May 5th.So we see here that pandas has kept the index exactly what it was in the original data frame and moved every row down one.The reason we get empty data here on the first row, we get this man representing a missing data point is because in order to do this properly, pandas would have needed to know what the price was forthe price was for Bitcoin in terms of US dollars on March 31st, 2014.So that data doesn't appear in the data frame.
So pandas doesn't have access to it.
Therefore it's missing, which is represented here as man or NAN.Now that we have this, we can do the example we mentioned before we can compute the one day at a time percent change between Bitcoin and the United States dollar.So we'll see here that between the first and the second, there was a 2% increase in the price of Bitcoin and then the next days the price goes down.This is consistent here with between the first and the second we see an increase.
We go from 449 to 460 and then after that we continue to fall for 60, 452, 439, 435.So the ability to shift the data made it possible for us to leverage the fact that pandas aligns arithmetic using the index to compute this percent change correctly.Now if we set the argument, if we pass an argument to the shift function, this tells us how many periods we would like the data to be shifted.In this case, if we pass the number three here, we see that the data is shifted down three rows.
So now that 449 dollar opening price moved from back here on May 1st down to May 4th.Implicitly with no argument, the default value is 1 meaning everything shifts down one row.Now if we shift the data by a negative value, what we'll see here is that all the data moves up by however many, by the absolute value that we pass in here.So passing a negative two moved this 439 dollar price from May 4th up to May 2nd.It's easier to see the shifting up if we look at the last few rows of the data frame, because now we see that down at the end of our data frame, we have missing data for November 4th and 5th of 2020,and 5th of 2020, because we shifted all rows up by two.Now explain this next exercise. So what we would like for you to do is to use the shift function to determine the week in the past five years or in the five year horizon for which we have data thatwe have data that has the largest percent change in the volume of trades.So the total quantity of Bitcoin traded. This can be found in the volume parentheses BTC column.So that's the first ask we have second, we'd like you to repeat that, but do it at the biweekly and the monthly frequencies.So here's a hint. First we have data only at a daily frequency and you should use the fact that one week is equal to seven days when you're solving the first two asks the one week change in volumechange in volume and then the biweekly change it volume.Then our second hint is why you can't do the month exactly because not all months have the same number of days for this exercise you should approximate a month by 30 days.We will now talk about doing rolling computations or moving window computations on our time aware data frames.So pandas makes the computation of these type of statistics very simple and we find that it's easiest to understand how this works by using an example.What we'll do is we'll take the first six rows of our BTC USD data frame and we'll call that BTC small.
Now we've shown here the entirety of this data frame, just these six rows and seven columns.So now what we're going to do is we're going to compute the two day moving average for all the columns. So here, we'll have and the way we do this is we say starting with the BTC small data frame,small data frame, we're going to access the dot rolling method.We'll pass an argument of 2d meaning two days and then we will compute the mean and what happens here is the following pandas will look at each row and it will try it will then look backwards thelook backwards the number of days and apply the average.So here we see and I'm going to show you BTC small so that we can kind of try to understand what's going on.So you'll see here that on the first row, we get back exactly the same data we started with.
The reason for this is that the there was not a day to look back in order to form this two day window.So pandas used all of the two day window that it could and returned us exactly the data we started with.Now things are different on the second row. So when we when pandas got to the second row corresponding to me second, what it did was it looked at this day and then one back making a two day windowa two day window and it took the average of these two values.So we see here that the average of 449 and then 461 for 60.9 is 454.9.
So this is the value that pandas computed here and we could do similar things for each of the other columns in our data frame.If we look at the next row for May third, we're going to see that the average between 252 and a sharp 452 and 460 is roughly 456, which was what computed here on this row.And pandas will then continue on through the rest of the rows in the data frame starting at each row and looking backward the number of days we specified and then computing the average.So I did this for each column and each row in our data frame.
Let's kind of visualize what this looks like by constructing a plot.What we have here is we have the open column, the opening price, and we're plotting the raw data in this red dotted line down here.And then we're going to compute a 21 day rolling maximum of the open column and then we'll plot it here in the blue line.We'll then add a legend that helps us keep track of which line corresponds to which series. And we'll see here and I'm actually going to make this a little bit bigger.We see here that pandas is tracking for us over a three week horizon, the kind of the peak of the red line. So this blue line continues to be kind of almost a step function.In this example, the red line reached a local maximum right about here where my cursor is.
And then for the next 21 days, the blue line stayed flat right at that local maximum.And then it fell again to the next local maximum, which we find right here.
And you can see the same pattern appearing throughout the graph.Now in addition to applying a built in aggregator like mean, we can actually ask that pandas apply a custom aggregation function that we define.This is similar to what we saw when we did group by and then we used the apply method of a group by object.So here what we'll do is we'll define a function called is volatile as the following behavior. If the variance of the input is greater than one, we'll say that yes, the data was volatile, the data inthe data in X is volatile.If the variance is less than one, we'll return zero.
So now what we'll do is for our BTC small data frame, we will do a two day rolling window and apply the is volatile method.So we see here that the first row has a zero all across. Now the reason for this is because when we do the two day rolling window, the very first row has no previous day to be combined with.X is actually just going to be the one value corresponding to may first the variance of a sequence of length one is always going to be equal to zero exactly.So when we computed the variance and asked was zero greater than one, this always return false and we get back zero.So we see zero here for every row. Now we'll see that for each other row, the opening price was volatile according to our definition for the other five days in our sample.For the other five two day windows in our sample, I should say.So the option to this would be for the closing price between may fourth and may third, the volumes were also quite volatile according to this measure.Now we have a fairly fun exercise that we'd like for you to do and we'll explain how it works.So would like for you to imagine that you were given access to the TARDIS time machine from the TV series Doctor who.And you were told that you are allowed to use the TARDIS only once to go back in time and return to the present subject to the following conditions.First, you may travel back to any day in the past. It's totally your choosing on that day the only action you can take is to purchase one Bitcoin at market open.You then have to take the time machine 30 days into the future and sell your Bitcoin at market close.You can then return to the present and pocket the profits and your objective is to pick which day in the data we have represented you would choose to travel back to in order to maximize the totalmaximize the total profits you can gain by buying and selling one Bitcoin with 30 days in between.Now the question is how would you pick the day and this is the kind of bulk of the exercise and we would like for you to think carefully about what you would need to compute in order to make theorder to make the optimal choice.And to solidify the idea in your mind for what you need to compute we would like for you to write down your answer here in this mark down sell you can double click into it and then replace this boldreplace this bold text your answer here with your description of what you'd like to be able to compute in order to make your optimal decision in this scenario.If we do have a note of caution don't look too far down in the notebook because we actually write out the answer in a minute.
But do this thought exercise and see what you come up with.As with other exercises we'll leave this as an assignment for you to complete on your own.Now our solution our answer to this question was that in order to make the optimal decision we need to know the maximum difference in price at the close of a window of 30 days compared to the openingto the opening price of the start of the window.In other words for each date in our time series we would like to look at the closing price for that date look back 30 days and compute the opening price from 30 days prior and then compute thethen compute the difference.The date we will pick would be 30 days prior to the max of that of that answer.Here's the next exercise we would like for you to do the following we would like for you to write a pandas function that implements your strategy or the one we just described.We'd like for you to pass it to the ag method of rolling BTC which we've computed for you down here.We'd like for you to extract the open column from the result and then find the date corresponding to the maximum.Once you've done that you will have your answer to which day you should travel back to and you also be able to answer the question of how much money you would have made where you've given this timegiven this time traveling opportunity.We've just seen how we can leverage the pandas time series functionality to do rolling or moving window computations.
We can also have pandas do what's called resampling for us.Resampling is another way to say changing the frequency of the data.
So for example, instead of computing a monthly moving average or a 30 day window moving average.We may want to be able to answer questions like what was the average price of Bitcoin for each calendar month.In order to compute statistics like this we don't want a moving window where we just want to resample the frequency at which we represent the data.
Let's see some examples of how this works.So we can use our BTC USD data frame and now instead of the rolling method we're going to use the resample method.The argument here should be some notion of the frequency that we would like the data to be expressed in.So currently our BTC USD data is in a daily frequency and by passing BQ here we're saying that we would like for the data to be represented in a business quarterly frequency.So let's do this and then compute the mean or average for each business quarter.You notice here that we have far fewer rows we don't have the 2000 plus rows it looks like we have here a couple dozen.
And now we have data only for the end of the month.June September December and March and so we'll have four rows for 2015 for 16 17 18 19 and also 2020 we only have three rows for.So we've been here for the first year 2014 because the data started in May or month five so we have no observations in the first quarter of the year which would be months January February and April.Now we want to point out a key difference between the resample method we just saw and the rolling method we were using earlier.With resample a single number was returned per column for each window that we considered.
For in the example we just looked at it was a business quarter.The resample method it will actually alter the frequency of the data and the number of rows will be different from the data from we passed in.On the other hand with the rolling form of computation and aggregation the number of rows in the output will match the number of rows in the input as well the frequency of the index.So we can actually sample at different frequencies business quarterly is not the only one.And once we have it we can do multiple aggregations at the same time. So for example suppose we wanted to do semi annually or two business quarters.We could resample starting with 2bq and the s here says we would like the dates in the output to be the start of each to quarter window.If you recall from our previous example we saw that we had the end of months June September December and March now here we're going to be seen the beginning of months.Now we're going to ask for instead of the average we would like for the min and the max for each of these two quarter windows. So now here we can only see April and October for each year.And we have a hierarchical index on the columns where we have the original column names as the outer most layer.
And on the inner layer we have the two different aggregation methods we requested.So we'll see here that in the first half of 2014 the difference in the opening price of bitcoin US dollars was roughly just shy of $300.And we'll see that this gap is quite extreme later in the time series where in the first half of 2019 this was an $8,000 difference in the opening price from the start of the quarter start of thestart of the year to this end of the start of the second quarter.We now have another exercise so let's revisit the thought experiment where we have access to this amazing time machine.You're again given access to it to make one travel through time but this time your conditions are a bit different.So now what you're allowed to do is travel back to the first day of any month in the past.
On that day you can purchase one bitcoin at the market opening.You're then allowed to travel to any day in that calendar month and sell the bitcoin at market close.Once you've completed these two transactions you will then return home to the present and you can keep the profit you made in your pocket and your objective is to again maximize the profit from theseprofit from these two transactions.The question we would have for you is to which month would you travel and on which day of the month would you return to sell your bitcoin.Just as we did last time we would like for you to take a moment to write your thoughts determine exactly what you would need to be able to know or compute in order to make an optimal decision anddecision and take a moment to write it in the markdown so below.Our response to the thought question that was just posed is that in order to make an optimal decision we would need to compute the following for each month in our data set.We would like to compute the maximum difference between the close price on any day in that month and the opening price on the first day of the month.Once we've done this we simply look for the maximum value across all months for that statistic and that's the month that we would like to visit.Now here in this next exercise you may or may not be surprised we want you to do the experiment.
In particular we would like for you to do these four steps.First we would like for you to create the body of this pandas function we've called monthly value.
This should implement the strategy that was described previously.Then we would like for you to pass in the function to the ag method of the resample BTC object computed for you below.We then for like for you to extract the open column from the result find the date with the maximum value and then return the amount of money that you would have made.Now a couple of questions you might ask was is this strategy more or less profitable than the rolling window computation we did previously if so by how much.And then also tell us which day you needed to return to within your chosen month in order to sell at the optimal closing price.The final note that we'll leave with here is with regards to the API key we saw used at the very beginning of our lecture.So if you look above in the notebook you'll notice that we were able to set the API key to a value with this strange looking string.This is our API key or our credentials to authenticate us as users with the quondal service.When we did this when we executed this line of code we told the quondal library that any time it was interacting with the quondal rest API that it should use the API key we specified in that string.API keys are very much like passwords and some APIs like a quondal require you to specify the key or password when making a request for data.By using this key we were able to obtain the Bitcoin US date dollar exchange rate directly from quondal.And we'll just point out that the API key listed in this notebook was one that we requested specifically for use in this class.The request was free it didn't cost us anything but this is the only thing for which we use this particular API key.If you plan on using quondal more extensively you may run into some limits because this key is shared with other users.And quondal does limit the number of requests each key can make if you do end up using quondal for more data collection efforts.We recommend that you go to their website and request for yourself your own free API key and then replace the line of code in the notebook that sets the quondal dot API config dot API key variable.And on the right hand side instead of using our API key you would use the one that quondal gave you directly.That's it for our lecture today we hope you enjoyed learning about time series operations and pandas and stay tuned for more time series operations when we get to learn you about some of theabout some of the statistical methods that arise in the time series domain.