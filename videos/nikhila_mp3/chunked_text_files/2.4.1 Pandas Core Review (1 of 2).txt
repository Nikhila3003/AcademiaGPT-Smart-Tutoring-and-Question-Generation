Hello, this is Spencer Lyon and today we will be doing a review of pandas by
a way of example. What we'll be looking at today is an example data set calledthe MovieLens data set and we're going to be using this to learn a few things.
So first we're going to be learning how to use the request library in pandas,which is a very popular library for handling interactions with web services.
Second part of this will be downloading a file that's contained in a zip archiveand so we're going to learn how to allow pandas to operate on these zip files but
we'll do so entirely in memory without having to write the file out to a hard drive.And finally we're going to practice merging data sets so that we can do a more
complete analysis on a variety of data sets. Just a note that you will needInternet access if you'd follow along in running this notebook because we
will be downloading a file from the Internet. And also this was originallycreated a few years ago by a team led by Dave Backus, Dr. Coleman and myself as
well as one of our teaching assistants Brian the Blanc for a course that wetaught at NYU Stern in the data bootcamp course. And we've taken this notebook
and it's been modified for today's purposes but this was when the content wasoriginally developed. Okay so we're going to start by importing some packages.
So first we're going to make sure that our plots are going to show up then we'regoing to do our standard imports of pandas and matplotlib. We also have a new
import of date time as GT and then a handful of new imports down at the bottomwhere we're going to import the OS package requests IO zip file and SSU tool.
Don't worry too much about these now we will go over what they are but we'llrun these now and we'll be ready to go when we get later on. Okay so a little
background on the data set that we're going to be using. So there is a group outof the University of Minnesota called the group lens team and this team has
gone and put together and collected a number of data sets that are nowpublicly available for academic use and one of which is called the movie lens
data set. So this contains millions of movie ratings by users of the movielens website. That's where the data set gets its name and we're going to be
using a small subset of this data set that contains a 100,000 ratings. This isdown from about 27 million that are contained within the full data set. So the
data itself comes in a zip file that we could download from the group lensdata site and inside the zip file there will be a few different CSV files
containing different parts of the data as well as a handy readme file. We'vegone ahead and we've downloaded the zip file and looked inside of it and we've
read the readme and here are some details about the different data files that arein the zip archive. So first there's a ratings.csv file and here each line in the
file is going to have the rating a user gave for a particular film at aparticular time. Next we have the tags.csv and this would include a number of
tags for a specific film that a user applied. Maybe it would be a tag to say Iwatched this within a particular individual or a tag to put it in some sort of
list. These are kind of defined by the users. We won't be using these but itdoes exist in case you're interested. Third is the movies.csv file. Here each
line in the file is a movie name and then we also have is each linerepresents a movie and the columns are going to be the movie ID the title and
the genres and the genres are going to be mushed together in a single stringeach separated by a pipe or a vertical bar and then finally there's a link
.csv and this would provide links to external websites if you wanted to get moreinformation about the movies. Our analysis today will focus on the ratings and
the movies files. So we would like to be able to download the file from theinternet and read them ratings.csv and movies.csv into a pandas data frame and
there are at least two ways of doing this. One is kind of what we'll call themore manual approach where we could go we could use our internet browser
navigate to the movie length site click the link to download the file put it onour hard drive then we could extract the zip archive put the file somewhere
and finally go back to our Jupyter session and use pd.csv. That option iscomfortable and something that we may have done a lot in the past but there's
also a second option. So the second option is to have Python automate the wholeprocess. So Python will go it will request a zip file it'll download it it'll
start opening it up and it will prepare these two files for pandas to to read.Of these two options the first is likely easier at first glance because it's
something we're familiar with however the second is going to be a lot morepowerful and so we're going to choose that option for our work today. So why do
we do it the hard way? Well first of all it builds character and if you haven'tdone things that build character you're welcome we're going to do this today.
Secondly and more seriously one major benefit of doing it through the secondoption is that the entire analysis can be self-contained in the notebook and
what this means is that there's no need for the user of the notebook to doanything quote by hand. They don't have to open up a particular website make
sure that the zip archive gets extracted into a particular place so we canhand somebody our notebook and they can run the whole process. And finally once
we learn how to use these tools we can apply them to other data sets as it'salmost inevitable that will come across an archived or compressed version of
data at some point be it through a zip file or a tar file and being able tohandle these directly in our Python code will give us an extra tool in our
belt that will likely need going forward. So how do we actually get a bit goabout this? First we're going to start by defining very clearly what we want to
accomplish. So in words what we want is to create pandas data frames from theratings.csv and movies.csv files that are contained in the zip archive that
we could download from the group lens website. So let's take it one step at atime and try to map out what needs to happen to fulfill our want. So first we
need to download the file and our strategy for doing this will be to lean on anduse the request package. Second once we've downloaded the file we need to be
able to unpack this the contents that were downloaded and treat them as a fileand there's going to be some special handling we'll talk more about that but to
do this step we're going to use a built-in Python module called the IO module.Next once we are able to get our hands on the file we need to then recognize and
treat this file as a zip archive that itself contains multiple files. Again we'regoing to use this with a built-in tool and Python called the zip file module.
And then finally once we've been able to identify the csv's within the zip filewe need to use the pandas.readcsv function to construct our data frames. That's
the outline. We're going to go through these things one step at a time and we'llmake sure that we provide a bit more detail on how they work when we get to each
of them. Before we get there there's a couple digressions. First and we felt thatthis was important. The request documentation states the following. Recreation
or use of other HTTP libraries may result in dangerous side effects including securityvulnerability, verbose code, reinventing the wheel, constantly reading documentation,
depression, headaches or even death. This is a bit like hard but we totally agree.The request package of library is by far the easiest way to interact with
websites that we found in Python. So we're going to be learning a bit more aboutit today and I'm certain that as you continue in your programming careers you'll
be continued to use it. Second digression is when we are constructing the solution. Weknew what we wanted and we did our homework and Google around for a solution that
could work and we ended up finding a particularly helpful stack overflow thread that let us piecetogether our solution. Okay, so let's get started. So remember our first step is to use
the request library to download the file. So here's how we do this. In code first wehave a variable called URL that just contains a string that points to the URL where we can
download our file. Once we've defined this we can use the request.get function and passthat our URL is an argument. We'll store the output as a variable called res which is short
for response. And I may use the term res or response interchangeably as we go forward.And once we've done that we'll just print out a few things contained within this response
object to see what it looks like. So we'll go ahead and run that. And so we see here that wegot a response status code. So the HTTP or web language has a set of principles or standards
defined in it. And one of these is called the status code. So when you your browser Pythonattempts to make a request over HTTP to a different web service that service will do its
operations and then return something. If everything was successful the convention is to returnthe code 200. And this just means you asked me for something. I was able to find it and I gave
it to you. So that's great. Second we want to look at the type of this response object.And sure enough it's a class implemented in the request module called response. And that's
where we get its name. Each of these requests responses has what's called a content field.And this is where the actual data that is sent back from the external web server is contained.
And when we look at this we can see that this is a bytes object. So in Python we typically workwith textual data as a string. But there's also a way to have Python interpret characters or text
as bytes. And this is kind of the native way to represent or encode files. So in this case thecontent of our response has class bytes. And then finally we can look at the headers. Heathers are
another part of the HTTP standard for a way of communicating extra information about the request.Here we are able to see things like content length. This header tells us how long in bytes the
response.content field is. There are other things like when the file was last modified what thecontent type is. And notice here that we have content type is application slash zip. Which is
again another convention for demonstrating to us the consumer of this web URL that the content,the bytes contained within it represent a zip file. So this all looks good. It's what we are expecting.
And it's nice to see that returned in the response object.So step two is to read the file as a bytes object that Python can work with. So we've talked about
a few different file formats in the past. CSV would be a plain text file. You can open it up in anytext editor and you can actually read the characters that are there and it's human readable.
We talked about other file formats like feather or parquet or excel that are not human readable.They are binary file formats. Well the zip archive is another binary file format. So in order to
work with this we're going to actually take the content that we just obtained. And we're going towrap it inside of an instance of the IO.Bytes.io class. So to do this it's one line of code. We importedthe IO module that was built into Python up at the top of our notebook. And now we're just going
to create a new variable called bytes that is the IO.Bytes.io instance formed by the content of ourresponse. So we execute that. Everything worked okay for us. Now we need to move on to step three.
So where we are now is we've downloaded the file and we've interpreted it as a binary source.But we actually have more information. This isn't just any arbitrary binary blob of data.
It's actually a file with a very particular format called the zip file file format.Python knows how to handle zip files intrinsically. And there's a built-in zip file module for doing this.So the next step will be to have Python understand we'll be able to tell Python or communicate to itthat our bytes IO object has data that represents a zip file. And once we do that we'll be able to do
common zip archive operations on our data. So here we're going to pass our bytes object into thezf which is short for zip file. Zip file class. And we're going to return back something called zip.And this zip file is an object that has class zip file. So that's great. Again what we were expecting.
So now that we have a zip file we need to take a look at what's inside.So the zip file class and all move out of the way here.
The zip file class has a handy method called name list. Now this method it will list all thedifferent files and folders that are contained within the zip archive. So let's go ahead and take a lookat what these contents are for our file. So we have our zip object and we're going to call the name listmethod. And we see here that there must be one folder called ml-latest-small. And then inside that
folder there are a number of files. There's a readme and then there's those four CSV files wetalked about earlier. Now we notice that the ratings.csv and the movies csv.files are in there.
And in order to actually have pandas read this data we need to give it that full path. We need togive it ml-latest-small-radings.csv and the same for movies. Now we could just write that text out
but we're actually going to just search through that list for any of the file names that includesthe string movies and since there's only one that will be our movies the path to our movies file
and will repeat the same for our ratings. So that's what we're doing just down here.And we'll see here that it did correctly find the path to our movies file.
Okay finally we're ready to let pandas read in our CSV file. I'll move back over here to be morecentered. So we're going to use our friend pandpd.readcsv and the only extra step here is that we need tocall on our zip file object. We need to call the open method and passing it the path to the file
we'd like to open. So here we want to open the movie file, open the ratings file and that willallow us to read these two CSV files into a data frame. So we'll run that. Again everything
executed without error and let's take a look at the data and see what we got.So first we'll print out the info which will tell us what the columns are and then we'll look at
the first few rows. So here it looks like the movies dataset has three columns one being movieID which is an integer and then it has two string columns one for the title of the movie and then onefor the genre. It looks also like there are 9,742 rows and each of the three columns has a non-null valuefor all those rows. So we don't have any missing data which is very helpful. We'll do the same for
the ratings dataset and here we have a user ID, a movie ID, a rating and a timestamp. The two IDcolumns as well as the timestamp are all integers right now and then the rating is a floating,
a float 64. Okay so we've just seen how the ratings dataset has a movie ID column but nota the title of the movie. Let's think about why this is. So the reason for this is a concept called
normalization. Let's think this through. Storing the movie names directly in the rating data framewould potentially cause each movie name to be repeated many times because for every movie there
may be many different users who have reviewed the movie. So one of the movie names we've seen so faris called grumpy or old men parentheses 1995. Now thinking about this this takes up a whole lot more roomthan the integer three if we were to save this as a CSV file. We have many characters instead of
just one. So for this reason and others the group lens team decided to store the movie names andgenres in the movies.csv file alongside an integer movie ID. Now this is unique for every row of that
CSV file and this movie ID is then used throughout all the other files as a way to refer to aspecific movie. This is an example of a relational database technique called normalization and
pardon the typo in the word example there. So you might be thinking well why would we normalize?If we're just trying to save space and this is only a couple megabytes it's probably not that big
a deal. Well there are other examples where instead of having a hundred thousand rows as we doin our ratings data set there may be millions or billions of rows and at that point it really does
matter trying to optimize storage space. But there's a second reason for why we would normalize thatmay be even more compelling. So for the second point let's consider a scenario where the group lens
team wanted to add an additional column of information about each movie. They wanted to add thedirector or perhaps the producer of the movie. So in their current structure in order to do this
they would go through that 9000 line movies CSV file they would add a director column and then foreach movie they would add a director. There would be no duplication of movie director pairs because
each movie only shows up one time and in one row. Now contrast this with a different version of thedata set that has the movie title and genre in the same CSV file as the ratings. If we wanted to
add a director column to this file what we would have to do is we would go through the 100,000different ratings we would look at what the movie title is and add the director. Now if there were
50 users for example who rated a single movie we would repeat that director's name 50 timesjust as we're repeating the title of the movie 50 times. This process of finding every single row
that goes to a particular movie could be more cumbersome and time consuming than adding a singlerow or adding the director column to just a single row of the movie's data frame. In this sense adding
new features or richness to the movie's data set was much easier when it was self-contained andisolated instead of having it be already combined and mixed in with the ratings.
So for our analysis however we want to be able to analyze the ratings for specific movies theID the movie ID that integer doesn't really mean much to ask and we would like to see the title of
the movie because it has a bit more context. So we need a way to bring in the movie title into theratings data frame and as you're probably thinking to yourself given what we learned a few weeks ago
this is the perfect use case for the merge functionality that pandas offers.To understand how this is going to work we're going to do just a small example looking at the firstthree rows of ratings of the ratings data set. So here's what it looks like. In the first three rows wehave a the user ID column is filled entirely with integer one. This means that the same user rated
three different movies. The movie that was rated was movie with ID one ID three and ID six.Each of these movies was given a rating of four by user with ID one and then we have the timestamp.
So let's see taking just these three rows let's see what happens when we merge in themovies data set on the movie ID column. We see here that the first four columns are exactly the same
as what we had. However we have an additional two columns we have the title and the list of genresfor this particular movie. Here's a breakdown of what happened. For each of the three rows in
ratings.head three pandas went and it found the value in the movie ID column. Now we can think ofpandas storing that in memory or keeping a record of what the current movie ID is. Once it has this
it goes to the movies data frame and it searches the movie ID column for all of the rows that havea matching movie ID. Once it finds one it brings over any columns from movies that aren't found in
ratings in this case title and genres and it brings them into the output alongside the existingcolumns for this particular movie ID. It would then go to the next row find the movie ID for ratingslook up the corresponding rows inside movies and bring over the data and we'll do this one row at a
time. The output then has all of the columns found in either ratings or movies.Now that we've kind of understood how that works with just the first few rows let's look at what
happens when we do this on the entire data set. So I'll move to the site here so we can see all of therows that are being displayed. So what we've done is we've called the pd.merge function pasted the
ratings data frame first and then the movies and then we set two arguments. One we set howit equal to left and then on equal movie ID. Now as you remember the how equal left argument
says that the output should contain all rows found in the left or first data frame passed to themerge function. In this case that would be ratings so the output needs to have every movie ID that
can discontinue in the ratings data frame. The on keyword argument here says that when we're tryingto match up the rows of ratings with the rows of movies we need to be looking at the value of the
movie ID column from both the ratings data frame and then from the movies one. Once we've done thismerge we print out the shapes of our three data frames now the combined one the ratings and the
movies as well as show the first 20 rows of our movie of our combined data set. Looking at thedimensions we see that the number of rows in the ratings data frame and the new combined data frameis equal. This is what happened for two reasons. One is that we called how equal left we passed that
argument when how is left all of the ratings that appear or movie IDs that appeared in the ratingsdata set are going to show up in the output. Reason number two is that each of those movie IDs
showed up in only one row of our movies data frame. I'll repeat that the reason the rows are thesame are one which shows how equal left so every row of ratings is represented in the output and then
second each movie ID from ratings shows up only once and exactly once in the movies data frame.Had the movie ID number one appeared two times in the movies data frame we would have actually
seen that the first rating would be repeated we'd have user one movie one rating fourand then we'd have the title of genre from the first match in the movies column in this case it's
toy story and then if it was actually a duplicate movie ID in the movies data frame we would repeatthe first four columns that came from ratings and then we'd have the new title in genre that
appeared in movies. That's not the case here we have a perfect one-to-one mapping between the movieID in the ratings data frame and the movie ID in the movies data frame.
Finally the number of columns here is going to be the first four columns that come from theratings data frame plus all of the non-movie ID columns from movies in this case that's going to
be two and so we end up with six columns. So at this point now that we have our combined data framewe're ready to do a little bit of analysis and this is going to be the last part of this
section of the pandage review and we want to do this exercise together. So some of the thingswe're going to ask you to do you already have the tools for but some of them you don't quite yet
have the tools and the reason we're doing this is we're trying to motivate one of the concepts we'regoing to be talking about next week when we go into what are called group bi operations you'll see
here soon but we'd like to do now is pause the video we want to work through and talk throughthese things together be able to ask questions and answer them. Okay welcome back I've moved myself
both physically and on the screen so that I can be a bit closer to my keyboard. So let's goahead and we'll work through each of these examples one of the time. So in order to get the
average rating across all movies and all users we'll be able to use the mean method on the rating column.When we do this we see that the answer is three and a half which on a scale from one to five makes
a lot of sense it's fairly in the average of that range. So next we were asked to find and try tounderstand the distribution of ratings and the way we want to do this for our answer was to compute
or to display a histogram of the data of how many ratings fell in each bin and what we're goingto do here is at the top we have a map plot lib version of this and at the bottom we have a
plotly version. So these are going to be the same graph effectively but they're going to be usingtwo different libraries and we're just going to show you this for variety. So the first thing to
notice here is that we have the bins that we're creating and this is going to be equally spacestarting at 0.25 going all the way to 5.25. So when we do this we're telling pandas and map plot
lib to count the number of ratings that occurred in each of these intervals that are each half arating wide. So this very first interval would be from 0.25 to one and then so on.
Now we see here that there is kind of a peak that it seems like the mode or the most likelymost common rating is a four and there are also kind of other peaks at five and then again just
below three. And the way I might think of this is if a user is going to go and write a review itseems more likely that they're going to write a review about movies that they like.
There seem to be a handful of movies that get rated as top ratings by a lot of people and thenfewer ratings just beneath that bar. So once you've crossed the threshold of going past four
it's more likely to get to five than you stop at four and a half. And then the idea that theaverage rating would be a four again reinforces the idea that there are more users willing to
rate movies that they enjoy than ones that they didn't. So let's take another look at the samegraph but this time using the plotly plotting library. So now it's going to be the same thing but
here we'll see that it's interactive we consume we can scroll we can hover over things and ittells us that there were 26,000 people who rated between four and four and a half for example.
Okay so third is we were asked to find the average rating of each movie. So now one way we mightdo this is we would first use our indexing knowledge to say okay if we wanted to look at same
movie 31 we would get all rows that are corresponding to movie 31 we could take the rating columnand compute the mean and when we do this we see that for this movie the average rating is about
3.18 however instead of having to repeat this either in a loop or by hand for every differentmovie idea all 9,000 of them we would actually wait till that pandas do this for us and this is
utilizing something called group by. This is something we haven't learned yet and we'll cover indetail in the next two lectures on pandas so don't worry just for now be a consumer of this and justbe when I first saw it marvel at how great this is so what happens is we can look at just the ratingcolumn and then we're going to group by the movie ID column and compute the mean and what pandas doesis it will say for all it'll collect moving one by one through all the different movie IDs it will
collect all rows with that particular movie ID then it will grab the rating column and compute theaverage of just those rows very similar to what we did up here for movie 31 but pandas is doing this
letting movie ID vary from one all the way to the very last movie ID which appears to be193,609 so in a matter of a couple seconds or less than a second let's see how long it took pandas
on my machine in a matter of four milliseconds pandas was able to compute to figure out which rowsbelong to each group of movie IDs and then compute the average of rating for only those rows and
it did that for all 9,724 movie IDs the group by functionality in pandas is almost a superpowerand it's something that we're very excited to teach you but we couldn't resist showing it off a
little bit here the last question was similar to the one just before it so here we asked you to countthe number of ratings for each movie so to do this it's the same code except we're going to replace
the movie or sorry the mean method with count so here we're going to look for a single moviewe're going to look at the rating column and count how many ratings there were except there were 38
and then we're going to use this magical group by and instead of calling the mean method we'llcall the count method and we see that we get back a data frame with all the rows one for each movie
ID and then the number of times that movie was rated hopefully this wet your appetite a bit forthe group by concept and we're going to be talking about it in much more detail in future lectures
the last note we'll offer here is there are more resources for learning how to do merging andcleaning data sets the pandas docs are fairly good but there are better guides out there we recommend
one by data carpentry if you follow this link you can see that there thank you