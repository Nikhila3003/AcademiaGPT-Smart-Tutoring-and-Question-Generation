1
00:00:00.000 --> 00:00:40.000
So this video, we're going to keep reviewing pandas and we're going to use an example using UN population data. Originally a lot of this material came from some work that Spencer and I did with Dave Backez who was that NYU and Brian LeBlock. And let's get started. So the data that we're going to use in this notebook to review pandas is we're going to look at the UN's population data. And in particular we're going to be focusing on the age distribution of the population. So there's going to be two types of data

2
00:00:32.000 --> 00:01:07.000
focusing on the age distribution of the population. So there's going to be two types of data that are in input to what we do. There's going to be what the UN calls estimates, which are estimates of the population at a point in the past and there's going to be projections which are forecasts about what the population might be for given year. Furthermore, the UN's going to provide us with a few different forecasts using some different modeling assumptions. And so under projections there will be three potential population models.

3
00:01:02.000 --> 00:01:44.000
modeling assumptions. And so under projections there will be three potential population models. We'll have low variant which is going to assume a low fertility, medium variant which assumes medium fertility and high variant which assumes high fertility. So let's go ahead and load the data. So what we do in this first code cell is the data is going to be stored at this URL. And we're going to use the URL joint to make sure this is joined appropriately. We also probably could have just added these strings together but this is just to be safe.

4
00:01:40.000 --> 00:02:21.000
We also probably could have just added these strings together but this is just to be safe. And so what that gives us is it gives us this URL. And so if we were to click this URL, it should take us to this Excel file. And so now what we're going to do is we're going to read a subset of the columns in particular. We're interested in the column of variant. Regents sub-region country or area country code type reference date. And then there's going to be a bunch of columns that are things like 0 to 4, 5 to 9, etc. all the way up to 100 plus.

5
00:02:12.000 --> 00:02:50.000
a bunch of columns that are things like 0 to 4, 5 to 9, etc. all the way up to 100 plus. And so we're going to create these and just this little list comprehension. And then we're going to add these columns to the columns we've already written now. Once we've done that, we'll use pandas read Excel function and we're going to read a URL which is the URL we created above. And then we're going to read four sheets from this Excel file. We're going to read the estimates, the low variant, the median variant and the high variant.

6
00:02:46.000 --> 00:03:25.000
We're going to read the estimates, the low variant, the median variant and the high variant. At the top of the top of the Excel file, there's 16 rows of kind of garbage, just citations or notations. So we're going to skip those rows. We're only going to select the subset of rows to work with. And then anything that is a dot dot dot is going to get read in as a missing value. And what this will do is if you read in one sheet, it gives you back a data frame. But if you read in multiple sheets by passing in a list, it gives you back a dictionary. So it's

7
00:03:20.000 --> 00:03:57.000
But if you read in multiple sheets by passing in a list, it gives you back a dictionary. So it's going to give us a dictionary with the keys, estimates, low variant, median variant and high variant. And so all we're going to do is go ahead and unpack these. And then we're going to stack these data frames, one on top of another. So remember, can cat take the data frames and just puts them together. There's kind of no clever merging back and forth. It's just literally going to stack them. And we're going to do this axis equals zero, which is going to be one on top of another.

8
00:03:51.000 --> 00:04:32.000
stack them. And we're going to do this axis equals zero, which is going to be one on top of another. And we're going to ignore the index. So this will take a minute. The data sets about 10 megabytes. So, which isn't that big. It just sometimes takes a minute for the server. Okay, perfect. So now we've read in our data. So what does it look like? So because we specified which columns we were going to read in, you should already have an idea of what the columns are going to be. So variant, we can now see is going to specify estimates. Or if we look at the tail,

9
00:04:24.000 --> 00:05:03.000
So variant, we can now see is going to specify estimates. Or if we look at the tail, we can notice it's going to have high variant. So the variant is going to tell us whether the data in this row is an estimate that's coming from kind of previous data or whether it's a forecast of what could happen in the future. The region sub-region country or area is going to tell us what region we're working with. So at the top it says world. So these are world population estimates. And at the bottom we have United States of America. And so we could also kind of infer that somewhere

10
00:04:57.000 --> 00:05:34.000
And at the bottom we have United States of America. And so we could also kind of infer that somewhere in between some of these countries will, the countries will be named. Country code is going to use the, what they call the alpha three standard, which is just, there's a three digit country, there's a three digit code for each country in the world. And this is just a standardized notation. Type is going to tell us what kind of data point it is. So again, if we look at the bottom, anytime it has a country's name, it's going to call it a country slash area.

11
00:05:29.000 --> 00:06:25.000
anytime it has a country's name, it's going to call it a country slash area. Reference date is going to give us a year and we've specified that this, the population is an estimate as of July 1. So here this row would read the population for the entire world, which is country code 900, on 1st of July 1950 was X. And then there's all of these columns that denote the age brackets of the different individuals. So we have, and these are in thousands of people. So the world in 1950, July 1st had 338,496,000 of people. So that's really 338,5 million, 0 to 4

12
00:06:11.000 --> 00:07:06.000
world in 1950, July 1st had 338,496,000 of people. So that's really 338,5 million, 0 to 4 year olds. Okay, so let's check the shape of the data and what types are in it to make sure everything is what we expect. So there's the 26 columns and we've kind of visually inspected these, they're approximate, they're what we expect. And the details are going to be, this is an object, so strings, also strings, this is an integer, that's good. The type is a string again, and then the year comes in as an integer, that's good and all of these numbers are floating point.

13
00:07:00.000 --> 00:07:40.000
and then the year comes in as an integer, that's good and all of these numbers are floating point. So that looks good. So our data is clean enough and now we kind of know what's in it. So the next step is kind of let's start cleaning the data. Let's put the data in a format in which we would be able to use it to answer some questions. So remember, this is what our data starts like. And so the first thing we're going to do is kind of any of the questions that we're asking today, I'm going to focus on just country data. So they have things like, so if we came in here,

14
00:07:35.000 --> 00:08:29.000
I'm going to focus on just country data. So they have things like, so if we came in here, we could do DF type.unique. And what this will tell us is each of the different values that type could have taken. So we could ask for anywhere where type was equal to region. Oh, there we go. And so if this is going to say, is this going to say things like this region is Africa, and so what's the population of Africa as a whole or OSEAN as a whole? Um, etc. And so I think we've seen this in the past, but if not, just a quick reminder,

15
00:08:22.000 --> 00:09:15.000
Um, etc. And so I think we've seen this in the past, but if not, just a quick reminder, query is a way that we can apply filters to the data. So this would be equivalent to writing DF.lock, DF type equal equals region and all columns. So you'll notice that we're getting truths everywhere. We could kind of up the ante and check for all.all. And this tells us every value is equivalent to one to another. So yeah, so the query is just a short hand notation and it does some things that make it a little faster like not creating copies of the data frame, but it's just a

16
00:09:09.000 --> 00:09:56.000
some things that make it a little faster like not creating copies of the data frame, but it's just a faster way to do Boolean selection. Okay, so like I said, we're going to focus on country data rather than looking at kind of regions or you know, high development, low development, any of the other classifications that the UN or any of the other world organizations uses. Okay, so here's our data. We notice now the heads starts at the index of 390 because it's eliminated the first 300 and 89 rows and it only has country data now. Okay, so if you look at this data frame and you're

17
00:09:45.000 --> 00:10:30.000
and 89 rows and it only has country data now. Okay, so if you look at this data frame and you're trying to kind of combine this data or reshape this data, you'll run into a bit of a headache that the column names aren't necessarily in the best format. They're not easily typeable or easily usable. So what we're going to do is we're going to kind of use common naming conventions for our pandas columns and we're going to rename the data that's been in, that's been ingested from the UN. So some kind of naming tips is typically you want to name your column something short and memorable

18
00:10:24.000 --> 00:11:04.000
So some kind of naming tips is typically you want to name your column something short and memorable and there's kind of standard conventions about how to do this. You want, so I typically like, I won't say that this is kind of a world standard, but I like my data frame columns to be named with lowercase letters and then when there's multiple words, I want to include in a single name. You use underscores. So if this was going to be something like variant type, I might have added an underscore to separate variant and type. But kind of beyond any

19
00:10:56.000 --> 00:11:39.000
variant type, I might have added an underscore to separate variant and type. But kind of beyond any other conventions, it's most important that you're internally consistent. So choose whatever conventions you want but make sure that you follow them. So what we're going to do is we're going to rename our columns and the input to rename is a dictionary and it's going to take a dictionary with keys that are the current column names and values that are the column names that you'd like to replace it with. And once we've renamed all of our columns, we're going to go ahead and drop the column

20
00:11:33.000 --> 00:12:14.000
it with. And once we've renamed all of our columns, we're going to go ahead and drop the column type from the data frame because we've already limited it to only having one type. So it only has country slash area information and none of the sub regions. Okay, and so you can see that we've now renamed our columns. So we left the age brackets the same. Those are kind of easy enough to work with. Variant and country. So variant was made lower case. All of this information about this was condensed into the word country because we're only working with country data. We've converted

21
00:12:09.000 --> 00:13:00.000
condensed into the word country because we're only working with country data. We've converted the word country code into alpha 3 because they're the alpha 3 country codes. And then reference date as of July has been converted into year. So now the data has one column for each age group. Kind of if you remember what we talked about in terms of tidy is you want to kind of want the data to be tall. You want each column to be a variable. And in this in some ways I guess the interpretation of our data is that a variable that the variable we're working with is population. And these things

22
00:12:50.000 --> 00:13:41.000
of our data is that a variable that the variable we're working with is population. And these things zero to four are more identifiers for the variable rather than their own variables. And so what we're going to do is we're going to move our data from a wide form to long form to make it more tidy than what we have right now. And if you remember we could do this with dataframe.milth. So melt is going to move data from is going to change this into a dataframe that has the columns variant country alpha 3 year. It will have a new column that has these values in it.

23
00:13:33.000 --> 00:14:21.000
the columns variant country alpha 3 year. It will have a new column that has these values in it. And then it will have a final column called values that will have the actual values. So a row of this dataframe will be estimates for Burundi which is country code 108 in the year 1950 for the age group 04 has the value 377,000. Okay, so let's go ahead and run that code. And just like we said one row is now an identifier which contains the information about the variant, the country, the alpha 3 code which is equivalent to two countries. So we could have potentially

24
00:14:15.000 --> 00:15:01.000
the country, the alpha 3 code which is equivalent to two countries. So we could have potentially dropped one or the other the year and then what age group are focusing on and what value that age group had. So this melt function I'm a big fan you'll you'll often use it when you're trying to tidy up your data. Okay, and so then towards the end of what we're going to do in class we're going to focus on countries that had more than 50 million people in the years 2010, 2015 and 2020. So if a country kind of 50 million people in 2020 they will not be included in our data set.

25
00:14:54.000 --> 00:15:38.000
So if a country kind of 50 million people in 2020 they will not be included in our data set. And so the way we're going to do this is we're going to use a pivot table to determine how many people were in each country during each year and then we're going to do some Boolean selection. So you'll notice we're only going to look at the estimates data because 2010, 2015 and 2020, our years that we already have data for. Then we're going to put country names on the index. So we're going to have countries running down the index. There's going to be the years

26
00:15:29.000 --> 00:16:08.000
So we're going to have countries running down the index. There's going to be the years across the columns and then in each value we want to put the total population of that country in that particular year. And so what we're going to do is remember the default aggregator function is taking the mean, but what are going to be the values that go in each of these? It's going to be each of the age groups. And so what we want to do is we want to sum up over all of the age groups, which has the data stored in

27
00:16:00.000 --> 00:17:00.000
And so what we want to do is we want to sum up over all of the age groups, which has the data stored in value. Okay, so that's going to give us our population sizes. And let's go ahead and look what look at what that looks like. Okay, perfect. So we can see we have years running along the columns and we have countries running along the index. And we have this number right here. How could we check that number? As we could go back and we could say DF.Query country is equal to Albania, for example, and we want to look at just, um, and let's say and year is equal to 1950. And so this should only give

28
00:16:43.000 --> 00:17:50.000
and we want to look at just, um, and let's say and year is equal to 1950. And so this should only give us, you know, 15 or 20 rows. Okay, so we have all of these values to notice there for these age columns. And now if we took this sum, it should give us the same value. We only want to sum the values column because everything else is meaningless. And let's make sure we're displaying this. Okay, so the population in 1950 of Algeria was 1,263,000, according to our pivot table. And if we do the only get the data from Albania in 1950 and take that sum, we confirm that it's

29
00:17:41.000 --> 00:18:28.000
And if we do the only get the data from Albania in 1950 and take that sum, we confirm that it's 1,263,000. Okay, so it looks like our pivot table is doing what we would expect. And so now we need to find a way to only use countries that have more than 50 million people. And the way we can do that is just create some kind of a Boolean selector. So we're going to do population sizes, which is this data frame here. We're going to look at all of the countries and we're going to look at the years 2010 to 2020. It only, they only have population data every five years, so this is going to

30
00:18:20.000 --> 00:19:03.000
years 2010 to 2020. It only, they only have population data every five years, so this is going to work, but if we wanted to be explicit about what years we also could have passed in a list. And we're going to check whether those values are greater than 50,000, which is 50 million because the population data is reported in thousands. And then we're going to ask whether all of those values were true. And that's going to give us some Boolean's. And then we're going to look at the index and we're only going to take the true values. And we're going to put that into a list.

31
00:18:55.000 --> 00:19:38.000
index and we're only going to take the true values. And we're going to put that into a list. And if that's going to give us countries population greater than 50 million, which is just this list of countries. So Bangladesh, Brazil, China, Democratic Republic of Congo, dot dot dot. So if you kind of look through this list of countries, you're not surprised that these countries have 50 million people. Okay, great. So now if we wanted to just have a data frame with the countries that have greater than 50 million people, we could just do DF dot query. So we're going to

32
00:19:32.000 --> 00:20:12.000
countries that have greater than 50 million people, we could just do DF dot query. So we're going to query again. And we're going to ask whether country is in this list. And so this app is kind of magic, is that it allows you to pass a variable. So we've created this variable right here. And the at sign tells it that we're not expecting this to be a column name or anything else. But rather this is a variable that's defined in the scope of what this query call should be able to see. So because we've already defined this, it will know how to hunt that down. So if we delete it,

33
00:20:07.000 --> 00:20:51.000
So because we've already defined this, it will know how to hunt that down. So if we delete it, it'll give us an error. But once we put at it knows to go get this. And if you looked at the country dot unique, you'd kind of line up that these are the same countries that we just saw in that other list. Great. So later on, we'll use this data set of using just the countries with greater than 50 million people. Excellent. So let's start exploring our data. This is kind of the fun part. So we've done some cleaning

34
00:20:43.000 --> 00:21:21.000
people. Excellent. So let's start exploring our data. This is kind of the fun part. So we've done some cleaning and so I have a confession. You know, the cleaning always looks better when you're presenting it to someone else. Really kind of these last 15 minutes that I've been talking, probably took me, you know, four or five times as long to do on my own just because there's a lot of trial and error. And so this is the same way as when you read kind of an academic paper, it looks beautiful, it looks polished. But that's because someone has taken the effort to clean it up

35
00:21:14.000 --> 00:21:57.000
it looks beautiful, it looks polished. But that's because someone has taken the effort to clean it up and to make it nice and it will automatically make sense. And so it takes practice to develop this skill. So it really is if you find chances to work with data, we highly encourage you to do it because cleaning the data is going to be a skill that's acquired through practice, not just by watching kind of data science and statistics and economics are all very much hands on learning. Okay. So you know, slash end rant, we'll go on and start looking at some visualizations.

36
00:21:50.000 --> 00:22:35.000
Okay. So you know, slash end rant, we'll go on and start looking at some visualizations. Okay. So one of the things that I kind of hinted at is that what we're going to be interested in is looking at the age distribution. And so let's go ahead and look at the age distribution in China. We're going to use the variant estimates so that we have the old data and then for any data that's in the future, namely for 2050 and 2080, we're going to get the medium variant. So this is going to be kind of the the medium version of the population forecasts.

37
00:22:29.000 --> 00:23:28.000
So this is going to be kind of the the medium version of the population forecasts. So we're going to find all of the rows that satisfy these criteria. We're going to do a pivot table and we're going to put the ages down the index and then on the columns we're going to put the different years and values and to value. And then we're going to take all of those rows but only the columns 1960 1990 2020, 2050 and 2008. Okay. So let's see whether that worked. I guess let's uh, so DF China and it has 1960, 90, 2020, 2050 and 2080 and then the ages down the, down the index.

38
00:23:15.000 --> 00:24:14.000
so DF China and it has 1960, 90, 2020, 2050 and 2080 and then the ages down the, down the index. So, oh. So that's what we wanted. Okay. So let's go ahead and plot this. So if you take a minute and stare at this graph, there's actually something that's not quite right. And I'll give you a second, just stare for a minute and there should be a couple of things that that look funny to you and you're you're not sure why. But once you do notice it, it will become obvious. So what's happened is that if you look at the x-axis of our bar chart, the ages have gotten out of order.

39
00:24:02.000 --> 00:24:49.000
So what's happened is that if you look at the x-axis of our bar chart, the ages have gotten out of order. So because we have a number dash, another number, this hat to be stored in a string. So we ended up with the ages 0 to 4, then 10 to 14. So something's missing there. So 5 to 9. Oh, and got put over here. And then 100 plus which should be at the end. And then I actually think everything else is in order. So there's just a few that are out of order. So how can we get these back in order? Well,

40
00:24:41.000 --> 00:25:23.000
So there's just a few that are out of order. So how can we get these back in order? Well, we can just kind of directly pass an order. So if you remember when we constructed the eight columns, we constructed the them in order using a list comprehension. And so let's just remake this chart and look at this. So this should look much better. So what do we have now on the y-axis, which should be the same for each chart. We have the thousands of people running up and down the y-axis. So what this says is that

41
00:25:11.000 --> 00:26:08.000
for each chart. We have the thousands of people running up and down the y-axis. So what this says is that in 1960, there were almost 100 million, 100 million people in China aged 0 to 4. And there were approximately 50 million. We'll call this one the 50 million bar of age 30 to 34. And so what we can see is that over time, and this is probably not a surprising or new fact to you, the population in China has aged. So in the kind of the 60s and 90s, there was a very young population. You see this population kind of in 2020 and 2050,

42
00:26:03.000 --> 00:26:48.000
there was a very young population. You see this population kind of in 2020 and 2050, advance into their middle aged. And then in 2050 and especially in 2080, you see this population retire and then potentially die off. And so the other thing you notice is that as these people have died off, there have been less births. And we'll talk about why something like that might be important next. So but rather than kind of seeing total population, we might just be interested in seeing the fraction of the population in each age group. So we've done kind of a lot here.

43
00:26:42.000 --> 00:27:23.000
seeing the fraction of the population in each age group. So we've done kind of a lot here. So let's go ahead and walk through it. So we've taken our data frame and we've divided by the entire sum of the population. So first we sum this gives us the total population in each year. And then we're going to take that and we're going to divide along the rows to tell you kind of what fraction of the population in 1950 was aged 0 to 4, etc. Okay, so then we're going to look at the age call. So we need to put them in order.

44
00:27:18.000 --> 00:28:02.000
Okay, so then we're going to look at the age call. So we need to put them in order. And then we're going to do this same plot command. We've added a few more arguments. So in particular, we're only going to look at kind of 0 to 0.2 on the y-axis. And we've added a title, which is population share by age bracket. And then so when you do a plot command in pandas, it returns either in matte plot lib access or an array of them. So because we chose to do subplots equals true, it created one plot per year. And so what we're going to do is figure out what was the

45
00:27:53.000 --> 00:28:44.000
equals true, it created one plot per year. And so what we're going to do is figure out what was the population in that year in millions. For each age group. Yes, sorry total. What was the total population? Then we're going to add another title. And that title is going to have the year, which is what we get from dfchina.collumslmthi. And then we're going to also put in the population. And this colon period 2f is kind of a string formatting syntax that adds two decimal places. So you'll notice this is 660.41. If we changed this to 4, these decimal places would have

46
00:28:37.000 --> 00:29:20.000
you'll notice this is 660.41. If we changed this to 4, these decimal places would have 4 numbers instead. So 0.4081. There's a few different things that you can do with string with kind of number formatting and strings. If you type up Python string number formatting, you can read all about it. For some reason, when I was setting the title, it was getting confused. So first, I set the title to nothing. And then I set the title to this string, which has the year and what the population was in that year. And I want it to be lined up on the right. And then I'm going to get rid of the spines

47
00:29:13.000 --> 00:29:54.000
that year. And I want it to be lined up on the right. And then I'm going to get rid of the spines on the right and top axis just because I think it looks better. And then this title layout when you have a lot of data like this, sometimes the graphs overlap. And so title layout makes sure that they don't overlap. But now we have kind of the same graph as we had before, except things are expressed in population shares. And we can see what the total population was in each year. And so in 2020, there were one and a half billion people living in China. And in 2050, they expected that to

48
00:29:46.000 --> 00:30:31.000
there were one and a half billion people living in China. And in 2050, they expected that to be slightly lower. And then they expected to be even lower in 2080. So what if we wanted to make this graph for other countries? Or for other variants? We could potentially copy and paste this code from right here. But when you do that, there's a really good chance that you start making errors. One of the stories I like to tell is when I was replicating a paper during the second year of my PhD. I found a paper where the authors had written a utility function and had clearly copied

49
00:30:24.000 --> 00:31:04.000
year of my PhD. I found a paper where the authors had written a utility function and had clearly copied and pasted it to a bunch of other places. But because of this, they had missed copy and pastes in the future as they changed it. And so there were at least three variations of their utility function. And so because of this, they're again, they weren't big deviations. I doubt it had any effect on their results. But it could have been a bug that was more malicious than just a small typo. And so whenever you get a chance to never you're doing something repeatedly, we highly encourage you to

50
00:30:58.000 --> 00:31:41.000
And so whenever you get a chance to never you're doing something repeatedly, we highly encourage you to write a function to do it. So let's go ahead and write a function. It's going to take data which is going to be a data frame, which country we want to write for the years that we want to plot and then which forecast variant we want to use. And then all of this code is just the same as before. So we're going to skip it. We're going to look at the 80 90 2000 2020 and 2050 and just run through some graphs real quick. So here's the age distribution of China. If the model assumes

51
00:31:33.000 --> 00:32:26.000
run through some graphs real quick. So here's the age distribution of China. If the model assumes low fertility. So with low fertility, the age distribution in China gets really old in by the year 2,100 and only has 684 million people rather than more than a billion in 2020. Here's the graph that we've already seen. So things don't look quite so bad here. You see a larger population, especially in kind of this 35 to 55, I think. And then if you take the high variant, which is going to assume a higher fertility, you actually have much less aging in the population.

52
00:32:18.000 --> 00:33:16.000
which is going to assume a higher fertility, you actually have much less aging in the population. So you get a relatively stable distribution across the ages with it tapering off at higher ages. We could do the same thing for India. So the low variant is going to look bad in terms of the age distribution by 2100 for pretty much any country we do. The medium variant is going to be less bad and the high variant is going to look. It's actually in some ways looks similar to the China graph. And then we can also do the United States. What you see is kind of

53
00:33:04.000 --> 00:33:52.000
China graph. And then we can also do the United States. What you see is kind of in both the low variant and the medium variant, we're going to have a relatively aged population. One of the things that's interesting is that the US sees a much smaller, even percentage-wise, decrease in the population. And that could be, I don't know exactly why that is. I'd have to see what their model looks like. So I'm not going to, I'm not going to try and make a guess this. Okay, so we've made these graphs about the age distribution and kind of played around. So why do we

54
00:33:47.000 --> 00:34:27.000
Okay, so we've made these graphs about the age distribution and kind of played around. So why do we care about it? I think there's lots of reasons we might care about it, but one reason we should be particularly concerned is social security programs. So in the US, the way the social security program is run is when you start working, you pay approximately 15% of your income to a government savings program they call social security. And when you retire at the age of, right now the retirement age is 65, you potentially start receiving payments from the government that are kind of

55
00:34:19.000 --> 00:34:56.000
age is 65, you potentially start receiving payments from the government that are kind of hypothetically this money that you saved with the government. And so kind of, I like to think of myself as young working age and you certainly, everyone in this class is a young working age. So you should be really interested in this because there's a lot of countries across the world, which it's not clear that their social security programs are going to be solvent in 40 years. I'm particularly concerned about this. I think it's very unlikely that the US social

56
00:34:51.000 --> 00:35:27.000
40 years. I'm particularly concerned about this. I think it's very unlikely that the US social security system stays solvent. And one number that economists and other people use to kind of think about whether a social security program will be able to sustain itself in the case that the money that kind of the working people contributed through their lifetimes is gone, as is the case in the United States, is something they call the dependency ratio. And so the dependency ratio relates to a number of persons aged 65 or over per 100 persons aged 15 to 64.

57
00:35:20.000 --> 00:35:57.000
ratio relates to a number of persons aged 65 or over per 100 persons aged 15 to 64. So why is this a helpful number? Is this this number tells us roughly how many working age people there are to support each person who has stopped working? So as the population distribution shifts to the right, which we kind of saw in a lot of the previous graphs, then there's going to be fewer individuals that are currently paying into social security programs that these social security programs are supposed to be making payments to the old who made payments to

58
00:35:51.000 --> 00:36:33.000
these social security programs are supposed to be making payments to the old who made payments to these programs while they were working age. So we're going to compute this age dependency ratio and we're going to do this by figuring out with two list comprehension. So this first one is going to give us all of the five times I to five times I plus four. So these are the age brackets. If the age is greater than 15 and less than 65 and then we're going to do the same thing if the age is greater than 65 and we're going to add the 100 plus category to the old age list.

59
00:36:26.000 --> 00:37:13.000
age is greater than 65 and we're going to add the 100 plus category to the old age list. And so what we're going to do now is first we're going to create a column called age classification and we're going to assign the value young to every value in this age classification column. Next we're going to figure out whether the age bracket is in this list working age and that's going to give us a Boolean and everywhere that that Boolean is true we're going to give it work. And so if the age is 0 to 4 it will be false that person would still have a young.

60
00:37:05.000 --> 00:37:48.000
And so if the age is 0 to 4 it will be false that person would still have a young. If that is 20 to 24 now that falls into our working age category and so the person is put as work and we'll do the same thing for old age. And so then we're going to so we're working with the medium variant of the four casts. We're going to pivot table and put the country in a year on the index and across the columns we're going to put the age classifications and in values we'll put value again and we're going to call this data frame dr for dependency ratio and then we're going to compute

61
00:37:42.000 --> 00:38:26.000
again and we're going to call this data frame dr for dependency ratio and then we're going to compute the dependency ratio which the way the UN defines it is 100 times the number of old divided by the number of working age and once we've done that we're going to save this back into the data frame dependency ratio we're only going to select that column and then we're going to unstack the level country so now we'll have year on the index and country across the columns and so let's see whether that works. If you get errors like this there is a reason that they give them to you

62
00:38:18.000 --> 00:39:10.000
that works. If you get errors like this there is a reason that they give them to you but sometimes you get false warnings and so in this case we're getting a false warning. Okay so like I said we have the year on the index and we have the country names on the columns and then these values are actually the dependency ratios that we just talked about and so just this kind of a matter of benchmark a zero dependency ratio would mean that you have no old people to support and age dependency ratio of 50 means that you have two working people for every

63
00:39:03.000 --> 00:39:49.000
old people to support and age dependency ratio of 50 means that you have two working people for every old person and then an age dependency ratio of 100 would mean that you have one working person for every old person and it can be over 100 but that just means you have more old people than working people. Okay so this next computation is obviously going to be wrong and the reason it's going to be wrong is because as the country ran into a crisis such as the one they might that we've kind of discussed is they would obviously increase their retirement age or there's other things that they could

64
00:39:43.000 --> 00:40:25.000
discussed is they would obviously increase their retirement age or there's other things that they could do but just as a thought experiment let's suppose that the dependency ratio that sustainable long term is 50 and so what this means is that there's going to be two workers for each person over 65 so of our countries with 50 million citizens how many of these countries are going to be sustainable in 2080 or 2100 and I think kind of this plot tells us a lot so this dotted line is our 50 and you see kind of a lot of countries that kind of so you've seen this happening between

65
00:40:19.000 --> 00:40:59.000
and you see kind of a lot of countries that kind of so you've seen this happening between 2000 and 2020 we've got kind of four or five countries that had a very quick run from the 20 to 30 range to 80 90 and you see a bunch of countries that have just done it in kind of who are starting down that same path and could potentially cross over 50 from 2020 to 2040 and then there's some other countries that are well below and so what are these countries? So let's go ahead and look at the number of years or in the index so we're going to look at

66
00:40:55.000 --> 00:41:39.000
So let's go ahead and look at the number of years or in the index so we're going to look at 2080 and all of the countries and let's see which of the countries have less than 50. So the Democratic Republic of Congo Egypt Ethiopia India South Africa Russia Indonesia the Philippines so these are all countries that have low age dependency ratios and 2100 it's an even smaller list and Ethiopia the Democratic Republic of Congo and South Africa are still on it but kind of some of these other countries in India and Russia in particular and Indonesia have fallen off of this list

67
00:41:33.000 --> 00:42:04.000
but kind of some of these other countries in India and Russia in particular and Indonesia have fallen off of this list so I don't know what to say about this other than if you believe this is kind of a good benchmark of a Solvitz social security program then you may want to go to one of these countries on these lists obviously there are other considerations that you would want to take into account that you know maybe these countries don't make your list but it's at least kind of hypothetical exercise

68
00:41:58.000 --> 00:42:34.000
you know maybe these countries don't make your list but it's at least kind of hypothetical exercise this was actually something our friend Dave Baccus was really interested in five six years ago and he's been there and I had started working on a paper on this at one point but it never got finished but hopefully this has been a chance to we think this is a fun example hopefully this was a chance to refresh you on some of the pandas topics that we've covered especially the reshaping because we can't emphasize this enough reshaping and cleaning

69
00:42:28.000 --> 00:42:46.000
especially the reshaping because we can't emphasize this enough reshaping and cleaning are things that you'll only learn to do by doing them yourself so hopefully this gives you a playground and some data where you can start trying to do the same so that's everything I have bye bye

