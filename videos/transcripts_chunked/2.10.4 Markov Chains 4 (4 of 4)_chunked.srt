1
00:00:00.000 --> 00:01:14.000
Okay, let's continue with the lecture on finite mark off chains. Okay, we'll come back to some of these claims on eigenvectors and eigenvalues of T later, but just store those. Just turn your own, you could read this part and this section teaches you some useful things. So with this, that's best going over on your own. So let's see some of the things about mark off chains and concepts about distributions that we already have seen, and mark on distributions. So we have a mark off chain pi, an initial distribution will call pi zero.

2
00:01:05.000 --> 00:02:16.000
So we have a mark off chain pi, an initial distribution will call pi zero. So then pi zero, a psi zero, that's the distribution of the state at times zero. If we want to know the marginal distribution of the state at times t, that's going to be psi sub t. We're going to know that psi sub t and we're going to use this notation. So there's a way to find psi t plus 1 given psi t. And we just use the standard laws of probability to do this. So psi t plus 1, that's going to be a list of probabilities that x t plus 1 is equal to y for every possible value of y.

3
00:02:01.000 --> 00:02:55.000
So psi t plus 1, that's going to be a list of probabilities that x t plus 1 is equal to y for every possible value of y. And if we just compute that, that's the summation probability x t plus 1 equals y condition on x t equals x times the probability x t equals x. This is all the information that we need to get this is in psi t. All the information we need to get this is in psi. So the formula that we get is this formula, if we just substitute that in. So this is an equation. We're going to see it has a very simple form.

4
00:02:51.000 --> 00:04:08.000
We're going to see it has a very simple form. It's going to be a matrix equation that maps psi t into psi t plus 1. And these are both marginal distributions. So if we write that out, if we write that out, that's just this equation. And if we repeat this many times, we can get this equation. psi t plus m is equal to psi t, post multiplied by p to the m. That's just the m power of p. And now we're going to define this thing called the special case is an initial distribution that has the property. It has a property is suppose we had an initial distribution that had the property that psi 0 equals psi 0 p.

5
00:03:54.000 --> 00:05:08.000
It has a property is suppose we had an initial distribution that had the property that psi 0 equals psi 0 p. But just suppose that, and that's such a psi 0 is very special. And it's called a stationary distribution or a stationary marginal distribution. It's going to play an important role. And now if we just stare at this equation, just stare at this equation. I'm just going to rewrite that by transposing both sides. So I'm going to get psi 0 transpose is equal to p transpose psi 0. And if you look at this, and now you look up at the definition of an eigenvector, this is psi 0 transpose is an eigenvector for p transpose with eigenvalue.

6
00:04:47.000 --> 00:05:58.000
And if you look at this, and now you look up at the definition of an eigenvector, this is psi 0 transpose is an eigenvector for p transpose with eigenvalue. And if I can value one, check that out. So what that's telling you is we can compute psi 0 by just taking the eigenvector of p transpose and normalizing. That's associated with the unit eigenvalue and normalizing. So it's a probability vector. So that's what's repeated, that's what's summarized here. And it's a very important idea. Okay, so such a psi 0 is called a stationary marginal distribution.

7
00:05:49.000 --> 00:06:58.000
Okay, so such a psi 0 is called a stationary marginal distribution. Okay, this material which I ask you to read, that's about a multi-step transition probabilities. And we already kind of talked about that a little bit. And now here's something I'm going to skip this example, although you might want to read this conjunction with a Hamilton example. I want to jump to this section 5.3. Because these section lots of, lots of sentences are going to be worth reading several times. So the marginal distributions read the sentence 10 times.

8
00:06:53.000 --> 00:07:46.000
So the marginal distributions read the sentence 10 times. The marginal distributions can be viewed either as probabilities or as cross-sectional frequencies in large samples. Remember a theme, what does probability mean? It means anticipated frequencies of random draws in very large samples. So that's continuing that theme. So we're going to think of, revisit our employment, unemployment dynamics model. And we're going to see, we're going to consider as, this isn't just one worker, but there's a large number of workers.

9
00:07:37.000 --> 00:08:23.000
And we're going to see, we're going to consider as, this isn't just one worker, but there's a large number of workers. And they're identical from the point of view of an outsider, of course they're all individuals. But they all space the same probabilities, the alphabet of probabilities of moving from, of moving from unemployment to employment. And the probability, data of moving from employment to unemployment. And they each, we have their lives like that. So now what we're going to let, we're going to reinterpret the model as saying, well, there's very, very many of these people.

10
00:08:14.000 --> 00:09:14.000
So now what we're going to let, we're going to reinterpret the model as saying, well, there's very, very many of these people. You could think of an infinite number, invisible. And we're going to let's side be the current cross-sectional distribution over 0, 1, which are our unemployed and employed states. So the cross-sectional distribution records the fractions of workers who are employed and unemployed at any given moment. And this fraction, so size 0, that's the unemployment rate. And what we want to know now is, and we're going to spend more time talking about this, because this relates to things that people in all countries are interested in at all times,

11
00:08:58.000 --> 00:09:37.000
And what we want to know now is, and we're going to spend more time talking about this, because this relates to things that people in all countries are interested in at all times, but especially during periods of big recessions or big booms. So if you want to know, what do you think the cross-sectional distribution will be 10 periods from now? The whole cross-sectional distribution. Well, that means, you know, what do you think the unemployment rate and the employment rate is going to be 10 periods from now?

12
00:09:31.000 --> 00:10:21.000
Well, that means, you know, what do you think the unemployment rate and the employment rate is going to be 10 periods from now? Well, that answers just sigh, Peter the 10th, where peas are stochastic matrix. So this section, I want you to simple, but also an adeep. Okay. So when the sample is really large, just where I said, outcomes frequencies, outcomes, this is frequencies, relative frequencies, relative frequencies, and probabilities are roughly equal. And this is our law of large numbers that we talked about before.

13
00:10:16.000 --> 00:11:26.000
And this is our law of large numbers that we talked about before. So for a very large population, this is going to represent the fraction of workers in each state. Okay. I promised you that I would talk a little bit about these two key concepts, irreducibility and apioreadicity. And the way to think about these, these are sufficient conditions that we'd like to have. Why? Because they, they make, they deliver, they imply very nice properties of a Markov chain. And these things both modify their properties of P.

14
00:11:20.000 --> 00:12:17.000
And these things both modify their properties of P. So I'll ask you to read this, but I'll tell you what irreducibility means. It would be a piece going to be a fixed, stochastic matrix. It's just fixed over time. And we say that two states communicate with each other. So if there's some positive integer such that P.J. There's some positive integers J and K such that in J steps you go from X to Y. And in K steps you can go, there's it's possible for you to go from Y to X. So somehow if there's a state here over here in the state, why?

15
00:12:12.000 --> 00:12:55.000
So somehow if there's a state here over here in the state, why? Somehow with enough steps there's a positive probability getting here and there's a positive probability getting there. So they quote unquote, communicate. That's what this means. And that's what communicate means. This stochastic matrix is irreducible if all states communicate. In other words, you can get from any state to any other state if you wait long enough. That's what we mean about irreducible. And we often assume irreducibility.

16
00:12:49.000 --> 00:13:49.000
That's what we mean about irreducible. And we often assume irreducibility. We often assume it because it gives very nice properties. And it's often true. So here's one that labor economists might talk about. So if you stare at this, you could see if it's irreducible. Check that. Is this irreducible? In other words, could you if you're rich, could you ever be poor? And if you're poor, could you ever be rich? You could talk about that. So here's an example. And of this. And you could check. This is irreducible.

17
00:13:40.000 --> 00:14:49.000
And of this. And you could check. This is irreducible. You could check whether that's true. Actually, how could you check? I have quarantine con. And I have the Markov chain. I say, I check. Right there. You have a chain. A really big chain. And you want to check whether it's irreducible. There's your secret weapon. Just by, by creating the chain. These are your two Python commands. And here's another chain. Another concept is called apiriodicity. So a chain is apiriotic if it's not periodic. So this is something that we also want.

18
00:14:45.000 --> 00:15:51.000
So this is something that we also want. So here's a periodic chain. This is periodic. And this chain, you notice if you're at C, you go to A, you go to B. You just keep going. You just cycle across these three for sure. So here's this chain. That chain has period three. And how could you figure out the chain of a periodic? You do these Python commands. Okay. So here's a definition of apiriotic. So that's a notion. So there's two things people who deal with Markov chain's often check. You reduce the ability. This is what they want. And apiriotic.

19
00:15:44.000 --> 00:16:36.000
You reduce the ability. This is what they want. And apiriotic. And if both those are true, some very interesting things and nice things are going to happen. If they're true, if there's true, I'm going to let you read about it. Something is nice about the stationary distributions, about the existence. And something is nice about convergence to stationary distributions. So here's our definition of a stationary distribution. I'm repeating that again. I see the read this. Lots of this is repeating over and over again because what I think you've learned by repeating.

20
00:16:26.000 --> 00:17:14.000
I see the read this. Lots of this is repeating over and over again because what I think you've learned by repeating. So stationary distributions, sweet this, have a natural interpretation as the castic steady states. Because you just stay there. You don't stay in a particular state. But you stay in the same distributions over states. So here's kind of a theorem. It is a theorem. Every state, every stochastic matrix has at least one stationary distribution. I'm not going to ask you to prove that. Now here's the key thing that we are after this one.

21
00:17:10.000 --> 00:18:03.000
Now here's the key thing that we are after this one. This is our reward. If apiriotic and irreducible, then ap has only one stationary distribution. There's only one. That's a uniqueness. And for any stationary distribution, you'll eventually converge to the stationary distribution. You'll matter where you start, you'll eventually converge to the stationary distribution. Okay? And so, again, we have apirioticity and irreducibility. You know what goes are. Then we know there's a unique stationary distribution.

22
00:17:58.000 --> 00:18:59.000
You know what goes are. Then we know there's a unique stationary distribution. And you'll converge this there no matter where you start. And this thing is often called, such a distribution is called, such a, such a chain is called uniformly ergodic. And now here's a check, easy check. If every element of p is strictly positive, then you're done. It's irreducible and apiriotic. This is good. So now, let's go back to our example, which is going to be the unemployment, the unemployment, unemployment model.

23
00:18:53.000 --> 00:19:45.000
unemployment model. Looks for a given worker, and that we had above. And we have two parameters. We have unemployment to employment. That was characterized by a probability, a transition probability alpha. Employment to unemployment, that was our beta. So we have these two parameters. And we actually have our meat, it's beautiful. We have our meat waiting time. So that's our average length of unemployment. And that's our average length of employment. So let's take a, let's make a guess that, okay. So, so we know our chain, our chain is,

24
00:19:32.000 --> 00:20:49.000
So let's take a, let's make a guess that, okay. So, so we know our chain, our chain is, let's get this right. Hopefully I did that right. Our chain is, is irreducible and apirotic. We could just check that every element's that. So if we check, we check this out. We take this and this. We could actually solve for the, we can solve for the, stationary distribution. This is the stationary distribution. We spend a fraction of our time p being unemployed, fraction of time 1 minus p being employed. And there's the, there's the, there's a form of a for p. And you could see, you could see,

25
00:20:37.000 --> 00:21:45.000
And there's the, there's the, there's a form of a for p. And you could see, you could see, how beta and alpha both influence this. And this makes sense. Okay, and then you could also check is, you could also check is, you could use eigenvalues and eigenvectors to compute the same thing. So, you know, if you, if you want to, you could use simpy and calculate eigenvectors and you, and eigenvalues and you would, you would get this. You can verify that in various ways. I'll actually read this on your own. How to calculate a stationary distribution.

26
00:21:40.000 --> 00:22:25.000
I'll actually read this on your own. How to calculate a stationary distribution. And some of you may be interested in, in parts of econometrics, basically Bayesian econometrics later. This calculating stationary distributions is a big part of that, because it's, it's used in Bayesian statistics a lot. So, I'm going to skip over this section. And, because we're going to come back and visit both this section and this section in, in a later, in later lectures.

