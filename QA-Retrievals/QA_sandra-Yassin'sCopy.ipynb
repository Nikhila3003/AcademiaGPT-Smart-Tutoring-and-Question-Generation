{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e884d382-ba9f-4c96-ae43-bdb8e491bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import dotenv\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "from langchain.schema.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "810fb808-7e88-4af8-86aa-bc98561f96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4449c505-18b5-461e-aa62-53843a7e2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "becd28f1-3090-4d88-bc8c-3f86636347d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_CONNECTION = \"postgresql://postgres:supa-jupyteach@192.168.0.77:54328/postgres\"\n",
    "COLLECTION_NAME = \"documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c285f09-ce19-432c-8c8f-591a8fff0c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorstore():\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    db = PGVector(embedding_function=embeddings,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        connection_string=DB_CONNECTION,\n",
    "    )\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86bdd675-e79d-4457-b2c9-7cccbad8f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore= get_vectorstore()\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "036a549a-0da6-47dc-b2c3-447b00366bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def create_chain(system_message_text):\n",
    "        ## Step 1: Create LLM\n",
    "        from langchain.chat_models import ChatOpenAI\n",
    "        llm = ChatOpenAI(temperature=0, max_tokens=4000)\n",
    "        ## Step 2: Create Retriever Tool\n",
    "        tool = create_retriever_tool(\n",
    "            retriever,\n",
    "            \"search_course_content\",\n",
    "            \"Searches and returns documents regarding the contents of the course and notes from the instructor.\",\n",
    "        )\n",
    "        tools = [tool]\n",
    "        ## Step 3: Create System Message from the Text Passed in as an Argument\n",
    "        system_message = SystemMessage(content=system_message_text)\n",
    "        ## Return the Chain\n",
    "        return create_conversational_retrieval_agent(\n",
    "        llm = llm, \n",
    "        tools=tools, \n",
    "        verbose = True, \n",
    "        system_message = system_message,\n",
    "        handle_parsing_errors=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9e79781-01da-4ebb-b3f0-eddbfa741d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "\n",
    "#import dotenv\n",
    "#dotenv.load_dotenv(\"/home/jupyteach-msda/jupyteach-ai/.env\")\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "#from langchain.schema import LLMResult\n",
    "#from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "#class JupyteachQuestionChain(LLMChain):\n",
    "  #  \"\"\"\n",
    "   # necessary for memory and PydanticOutputParser to work at the same time. \n",
    "    \n",
    "   # Notice that we set `ConversationBufferMemory.output_key` to `\"original_text_response\"`\n",
    "  #  and we use `\"original_text_response\"` as a key in `create_outputs` below.\n",
    "  #  \"\"\"\n",
    "\n",
    " #   def create_outputs(self, llm_result: LLMResult) -> List[Dict[str, Any]]:\n",
    "#        out = super().create_outputs(llm_result)\n",
    " #       return [\n",
    "  #          {**d, \"original_text_response\": g[0].text}\n",
    "   #          for (d, g) in zip(out, llm_result.generations)\n",
    "    #    ]\n",
    "\n",
    "\n",
    "def build_llm_for_pydantic_model(model_class):\n",
    "    parser = PydanticOutputParser(pydantic_object=model_class)\n",
    "    system = SystemMessagePromptTemplate.from_template(common_system_prompt)\n",
    "    human = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate(\n",
    "        messages = [system, MessagesPlaceholder(variable_name=\"history\"), human],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        # output_parser=parser,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    model = ChatOpenAI(temperature=0, max_tokens=4000)\n",
    "    \n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"history\", \n",
    "        return_messages=True,\n",
    "        output_key=\"output\",\n",
    "    )\n",
    "    return create_chain(prompt)\n",
    "    \n",
    "    \n",
    "    #JupyteachQuestionChain(\n",
    "     #   memory=memory,\n",
    "      #  llm=model,\n",
    "       # prompt=prompt,\n",
    "        #output_parser=parser,\n",
    "       # output_key=\"question\",\n",
    "       # return_final_only=False,\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08576cb1-90aa-4355-a242-4a813f9cbb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from abc import ABC\n",
    "from typing import List, Optional\n",
    "\n",
    "DifficultyType = int\n",
    "\n",
    "def execute_and_trace(code: str) -> bool:\n",
    "    try:\n",
    "        # Compile the code with a custom filename\n",
    "        compiled_code = compile(code, 'code_to_evaluate', 'exec')\n",
    "        exec(compiled_code)\n",
    "        return True\n",
    "    except Exception:\n",
    "        # Display the traceback which will correctly reference the original lines\n",
    "        formatted_traceback = traceback.format_exc().replace('<string>', 'code_to_evaluate')\n",
    "        sys.stderr.write(formatted_traceback)\n",
    "        return False\n",
    "\n",
    "\n",
    "class QuestionBase(BaseModel, ABC):\n",
    "    \"\"\"\n",
    "    Base class for all question types. \n",
    "    \"\"\"\n",
    "    question_text: str = Field(description=(\n",
    "        \"The main text of the question. Markdown formatted\"\n",
    "    ))\n",
    "    difficulty: DifficultyType = Field(description=(\n",
    "        \"An integer from 1 to 3 representing how difficult \"\n",
    "        \"the question should be. 1 is easiest. 3 is hardest\"\n",
    "    ))\n",
    "    topics: List[str] = Field(description=(\n",
    "        \"A list of one or more topics that the question is testing\"\n",
    "    ))\n",
    "\n",
    "    def _repr_markdown_(self):\n",
    "        return repr(self)\n",
    "\n",
    "\n",
    "class SingleSelection(QuestionBase):\n",
    "    \"\"\"\n",
    "    Question where user is presented a prompt in `question_text` and \n",
    "    a list of `choices`. They are supposed to provide the single best\n",
    "    answer (`solution`) as an integer, which is the index into `choices.\n",
    "\n",
    "    All questions must have a minimum of 3 options\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    {\n",
    "      \"question_text\": \"What does `.loc` do?\\n\\nBelow is an example of how it might be used\\n\\n```python\\ndf.loc[1995, \\\"NorthEast\\\"]\\n```\",\n",
    "      \"difficulty\": 2,\n",
    "      \"topics\": [\"pandas\", \"loc\", \"indexing\"],\n",
    "      \"choices\": [\n",
    "        \"The `.loc` method allows a user to select rows/columns by name\",\n",
    "        \"The `.loc` method allows a  user to select rows/columns by their position\",\n",
    "        \"The `.loc` method is for aggregating data\"\n",
    "      ],\n",
    "      \"solution\": 0\n",
    "    }\n",
    "    \"\"\"\n",
    "    choices: List[str] = Field(description=(\n",
    "        \"A list of markdown formatted strings representing \"\n",
    "        \"the options for the student. Minimum of length 3\"\n",
    "    ))\n",
    "    solution: int = Field(description=(\n",
    "        \"Index into choices representing correct answer. Zero based\"\n",
    "    ))\n",
    "\n",
    "    def check(self, response):\n",
    "        return self.solution == response\n",
    "\n",
    "    def __repr__(self):\n",
    "        out = f\"{self.question_text}\\n\\n\"\n",
    "        for i, c in enumerate(self.choices):\n",
    "            if i == self.solution:\n",
    "                out += f\"- [x] {c}\\n\"\n",
    "            else:\n",
    "                out += f\"- [ ] {c}\\n\"\n",
    "        return out\n",
    "            \n",
    "\n",
    "class MultipleSelection(QuestionBase):\n",
    "    \"\"\"\n",
    "    Question where user is presented a prompt in `question_text` and \n",
    "    a list of `choices`. They are supposed to provide all answers that\n",
    "    apply (`solution`)\n",
    "\n",
    "    All questions must have a minimum of 3 options\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    {\n",
    "      \"question_text\": \"What are some possible consequences of a learning rate that is too large?\",\n",
    "      \"difficulty\": 2,\n",
    "      \"topics\": [\"optimization\", \"gradient descent\"],\n",
    "      \"choices\": [\n",
    "        \"The algorithm never converges\",\n",
    "        \"The algorithm becomes unstable\",\n",
    "        \"Learning is stable, but very slow\"\n",
    "      ],\n",
    "      \"solution\": [0, 1]\n",
    "    }\n",
    "    \"\"\"\n",
    "    choices: List[str] = Field(description=(\n",
    "        \"A list of markdown formatted strings representing \"\n",
    "        \"the options for the student. Minimum length of 3.\"\n",
    "    ))\n",
    "    solution: List[int] = Field(description=(\n",
    "        \"List of indices into choices representing correct answers. Zero based\"\n",
    "    ))\n",
    "\n",
    "    def check(self, response):\n",
    "        return set(self.solution) == set(response) and len(response) == len(\n",
    "            self.solution\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        out = f\"{self.question_text}\\n\\n\"\n",
    "        for i, c in enumerate(self.choices):\n",
    "            if i in self.solution:\n",
    "                out += f\"- [x] {c}\\n\"\n",
    "            else:\n",
    "                out += f\"- [ ] {c}\\n\"\n",
    "        return out\n",
    "\n",
    "class Code(QuestionBase):\n",
    "    \"\"\"\n",
    "    Question where user is presented a prompt in `question_text` and \n",
    "    given `starting_code`. They are then supposed to modify the `starting_code`\n",
    "    to complete the question. After doing so the code will be verified by running\n",
    "    the following template as if it were python code:\n",
    "\n",
    "    ```python\n",
    "    {setup_code}\n",
    "\n",
    "    {student_response}\n",
    "\n",
    "    {test_code}\n",
    "    ```\n",
    "\n",
    "    The test code should have `assert` statements that verify the correctness of\n",
    "    the `student_response`\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    {\n",
    "      \"question_text\": \"How would you create a `DatetimeIndex` starting on January 1, 2022 and ending on June 1, 2022 with the values taking every hour in between?\\n\\nSave this to a variable called `dates`\",\n",
    "      \"difficulty\": 2,\n",
    "      \"topics\": [\"pandas\", \"dates\"],\n",
    "      \"starting_code\": \"dates = ...\",\n",
    "      \"solution\": \"dates = pd.date_range(\\\"2022-01-01\\\", \\\"2022-06-01\\\", freq=\\\"h\\\")\",\n",
    "      \"setup_code\": \"import pandas as pd\",\n",
    "      \"test_code\": \"assert dates.sort_values()[0].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-01-01\\\"\\nassert dates.sort_values()[-1].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-06-01\\\"\\nassert dates.shape[0] == 3625\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    starting_code: str = Field(description=(\n",
    "        \"Starting code that will be the initial contents of the \"\n",
    "        \"student's text editor. Used to provide scaffold/skeleton code\"\n",
    "    ))\n",
    "    solution: str = Field(description=\"The correct code\")\n",
    "    setup_code: str = Field(description=(\n",
    "        \"Any code that needs to execute prior to the student code to \"\n",
    "        \"ensure any libraries are imported and any variables are set up\"\n",
    "    ))\n",
    "    test_code: str = Field(description=(\n",
    "        \"Code containing `assert` statements that verifies the correctness\"\n",
    "        \"of the student's response\"\n",
    "    ))\n",
    "\n",
    "    def check(self, response):\n",
    "        to_evaluate = f\"{self.setup_code}\\n\\n{response}\\n\\n{self.test_code}\\n\\nTrue\"\n",
    "        return execute_and_trace(to_eval)\n",
    "\n",
    "    def __repr__(self):\n",
    "        out = f\"{self.question_text}\\n\\n```python\\n{self.starting_code}\\n```\"\n",
    "        out += f\"\\n\\n**Solution**\\n\\n```python\\n{self.solution}\\n```\"\n",
    "        out += f\"\\n\\n**Test Suite**\\n\\n```python\\n{self.setup_code}\\n\\n{self.solution}\\n\\n{self.test_code}\\n```\"\n",
    "        return out\n",
    "        \n",
    "\n",
    "class FillInBlank(QuestionBase):\n",
    "    \"\"\"\n",
    "    Question type where the student is given a main question and then\n",
    "    a code block with \"blanks\" (represented by `___X` in the source).\n",
    "    The student must provide one string per blank. Correctness is evaluated\n",
    "    based on a Python test suite based on the following template:\n",
    "\n",
    "    \n",
    "    ```python\n",
    "    {setup_code}\n",
    "\n",
    "    {code_block_with_blanks_filled_in}\n",
    "\n",
    "    {test_code}\n",
    "    ```\n",
    "\n",
    "    There must be at least one `___X` (one blank) in `starting_code`\n",
    "\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    {\n",
    "      \"question_text\": \"Suppose you have already executed the following code:\\n\\n```python\\nimport numpy as np\\n\\nA = np.array([[1, 2], [3, 4]])\\nb = np.array([10, 42])\\n```\\n\\nFill in the blanks below to solve the matrix equation $Ax = b$ for $x$\\n\",\n",
    "      \"difficulty\": 2,\n",
    "      \"topics\": [\"linear algebra\", \"regression\", \"numpy\"],\n",
    "      \"starting_code\": \"from scipy.linalg import ___X\\n\\nx = ___X(A, ___X)\",\n",
    "      \"solution\": [\"solve\", \"solve\", \"b\"],\n",
    "      \"setup_code\": \"import numpy as np\\n\\nA = np.array([[1, 2], [3, 4]])\\nb = np.array([10, 42])\\n\",\n",
    "      \"test_code\": \"assert np.allclose(x, [22, -6])\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    starting_code: str = Field(description=(\n",
    "        \" The starting code for the student. Must contain at least one \"\n",
    "        \"`___X` (three underscores and capital `X`), which represents \"\n",
    "        \"a blank that will be filled in by the student.\"\n",
    "    ))\n",
    "    solution: List[str] = Field(description=(\n",
    "        \"A list of strings representing the correct code to place in \"\n",
    "        \"the blanks. Length must match number of `___X` that appear in \"\n",
    "        \"`starting_code`.\"\n",
    "    ))\n",
    "    setup_code: str = Field(description=(\n",
    "        \"Any code that needs to execute prior to the student code to \"\n",
    "        \"ensure any libraries are imported and any variables are set up\"\n",
    "    ))\n",
    "    test_code: str = Field(description=(\n",
    "        \"Code containing `assert` statements that verifies the correctness \"\n",
    "        \"of the student's response\"\n",
    "    ))\n",
    "\n",
    "    def merge_answer(self, response: List[str]):\n",
    "        parts = self.starting_code.split(\"___X\")\n",
    "        n_blanks = len(parts) - 1\n",
    "        assert len(response) == n_blanks\n",
    "        pieces = []\n",
    "        for x, y in zip(parts, response + [\"\"]):\n",
    "            pieces.extend([x, y])\n",
    "        return \"\".join(pieces)\n",
    "\n",
    "    def check(self, response):\n",
    "        code = self.merge_answer(response)\n",
    "        to_eval = f\"{self.setup_code}\\n\\n{code}\\n\\n{self.test_code}\\n\\nTrue\"\n",
    "        return execute_and_trace(to_eval)\n",
    "\n",
    "    def __repr__(self):\n",
    "        merged = self.merge_answer(self.solution)\n",
    "        out = f\"{self.question_text}\\n\\n```python\\n{self.starting_code}\\n```\"\n",
    "        out += f\"\\n\\n**Solution**\\n\\n[{', '.join(self.solution)}]\\n```\"\n",
    "        out += f\"\\n\\n**Rendered Solution**\\n\\n```python\\n{merged}\\n```\"\n",
    "        out += f\"\\n\\n**Test Suite**\\n\\n```python\\n{self.setup_code}\\n\\n{merged}\\n\\n{self.test_code}\\n```\"\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42dc845a-aafd-4d6e-b463-90c1064a97dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_system_prompt = \"\"\"You are a smart, helpful teaching assistant chatbot named Callisto.\n",
    "\n",
    "You assist professors that teach courses about Python, data science, and machine learning\n",
    "to graduate students.\n",
    "\n",
    "You have 5+ years of experience writing Python code to do a variety of tasks. \n",
    "\n",
    "Your responses typically include examples of datasets or code snippets.\n",
    "\n",
    "For each message you will be given two inputs\n",
    "\n",
    "topic: string\n",
    "difficulty: integer\n",
    "\n",
    "Your task is to produce practice questions to help students solidify their understanding of the provided topic\n",
    "\n",
    "The difficulty will be a number between 1 and 3, with 1 corresponding to a request for an easy question, and 3 for the most difficult question.\n",
    "\n",
    "If the user asks you for another question and does not specify either a new topic or a new difficulty, you must use the previous topic or difficulty\n",
    "\n",
    "Your responses must always exactly match the specified format with no extra words or content.\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dbbfa09-90cd-4383-a793-007d1da0f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.schema.messages import SystemMessage \n",
    "\n",
    "ms_parser = PydanticOutputParser(pydantic_object=MultipleSelection)\n",
    "code_parser = PydanticOutputParser(pydantic_object=Code)\n",
    "ss_parser = PydanticOutputParser(pydantic_object=SingleSelection)\n",
    "fib_parser = PydanticOutputParser(pydantic_object=FillInBlank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdb9e153-f739-40cd-b693-41a534be6ed8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for SystemMessage\ncontent\n  str type expected (type=type_error.str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ss_chain \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_llm_for_pydantic_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSingleSelection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m q_ss \u001b[38;5;241m=\u001b[39m ss_chain\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifficulty: 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtopic: scikit-learn LinearRegression\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m q_ss\n",
      "Cell \u001b[0;32mIn[8], line 54\u001b[0m, in \u001b[0;36mbuild_llm_for_pydantic_model\u001b[0;34m(model_class)\u001b[0m\n\u001b[1;32m     47\u001b[0m model \u001b[38;5;241m=\u001b[39m ChatOpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4000\u001b[39m)\n\u001b[1;32m     49\u001b[0m memory \u001b[38;5;241m=\u001b[39m ConversationBufferMemory(\n\u001b[1;32m     50\u001b[0m     memory_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     51\u001b[0m     return_messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m     output_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m )\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m, in \u001b[0;36mcreate_chain\u001b[0;34m(system_message_text)\u001b[0m\n\u001b[1;32m     11\u001b[0m tools \u001b[38;5;241m=\u001b[39m [tool]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m## Step 3: Create System Message from the Text Passed in as an Argument\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m system_message \u001b[38;5;241m=\u001b[39m \u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_message_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m## Return the Chain\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m create_conversational_retrieval_agent(\n\u001b[1;32m     16\u001b[0m llm \u001b[38;5;241m=\u001b[39m llm, \n\u001b[1;32m     17\u001b[0m tools\u001b[38;5;241m=\u001b[39mtools, \n\u001b[1;32m     18\u001b[0m verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     19\u001b[0m system_message \u001b[38;5;241m=\u001b[39m system_message,\n\u001b[1;32m     20\u001b[0m handle_parsing_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/load/serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for SystemMessage\ncontent\n  str type expected (type=type_error.str)"
     ]
    }
   ],
   "source": [
    "ss_chain = build_llm_for_pydantic_model(SingleSelection)\n",
    "q_ss = ss_chain.invoke(input=\"difficulty: 1\\ntopic: scikit-learn LinearRegression\")\n",
    "q_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b9cdf2-349f-456f-b9e2-89125456270b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyteach)",
   "language": "python",
   "name": "jupyteach"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
