{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9968ecd3-1eda-4e72-a77b-d3bffc8e0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.messages import SystemMessage\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "import textwrap\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from question_generator_model import SingleSelection, Code, AnyQuestion, FillInBlank, MultipleSelection\n",
    "\n",
    "load_dotenv(\"/home/jupyteach-msda/jupyteach-ai/.env\")\n",
    "\n",
    "COLLECTION_NAME = \"documents\"\n",
    "DB_CONNECTION = \"postgresql://postgres:supa-jupyteach@192.168.0.77:54328/postgres\"\n",
    "\n",
    "\n",
    "def get_vectorstore():\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    db = PGVector(embedding_function=embeddings,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        connection_string=DB_CONNECTION,\n",
    "    )\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e410d458-7f99-4368-a69e-a34f423791eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that takes the input and returns the output from the retreival agent\n",
    "def create_chain(\n",
    "        system_message_text, \n",
    "        temperature=0, \n",
    "        model_name=\"gpt-3.5-turbo-1106\", \n",
    "        model_kwargs={\"response_format\": {\"type\": \"json_object\"}},\n",
    "        verbose=False,\n",
    "    ):\n",
    "    # step 1: create llm\n",
    "    retriever = get_vectorstore().as_retriever()\n",
    "    llm = ChatOpenAI(temperature=temperature, model_name=model_name, model_kwargs=model_kwargs, verbose=verbose)\n",
    "    \n",
    "    # step 2: create retriever tool\n",
    "    tool = create_retriever_tool(\n",
    "        retriever,\n",
    "        \"search_course_content\",\n",
    "        \"Searches and returns documents regarding the contents of the course and notes from the instructor.\",\n",
    "    )\n",
    "    tools = [tool]\n",
    "\n",
    "    # step 3: create system message from the text passed in as an argument\n",
    "    system_message = SystemMessage(content=system_message_text)\n",
    "\n",
    "    # return the chain\n",
    "    return create_conversational_retrieval_agent(\n",
    "        llm=llm, \n",
    "        tools=tools, \n",
    "        verbose=False, \n",
    "        system_message=system_message\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d30f26d-5f64-488b-aa4c-c0150387dfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to check if the retrieval is happening\n",
    "def report_on_message(msg):\n",
    "    print(\"any intermediate_steps?: \", len(msg[\"intermediate_steps\"]) > 0)\n",
    "    print(\"output:\\n\", msg[\"output\"])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67f269c-5ff9-4bd0-a256-1edd5bc0a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fucntion that returns the system prompt with the format of the question requested \n",
    "def create_system_prompt(pydantic_object):\n",
    "    common_system_prompt = textwrap.dedent(\"\"\"\n",
    "    You are a smart, helpful teaching assistant chatbot named AcademiaGPT.\n",
    "\n",
    "    You are an expert Python programmer and have used all the most popular\n",
    "    libraries for data analysis, machine learning, and artificial intelligence.\n",
    "\n",
    "    You assist professors that teach courses about Python, data science, and machine learning\n",
    "    to college students.\n",
    "\n",
    "    Your task is to help professors produce practice questions to help students solidify \n",
    "    their understanding of specific topics\n",
    "\n",
    "    In your conversations with a professor you  will be given a topic (string) and an\n",
    "    expected difficulty level (integer)\n",
    "\n",
    "    Occasionaly the professor may ask you to do something like produce a similar question,\n",
    "    or  make the question more difficult or easy. You need to assist the professor with the same. You can use the previous topic to do this.\n",
    "    \n",
    "    If the professor asks you for another question and does not specify either a new topic \n",
    "    or a new difficulty, you must use the previous topic or difficulty.\n",
    "    \n",
    "    If the professor ask for more than one question in a single message, you need to apologize and \n",
    "    inform that you can only generate one question at a time. You need to also ask the professor to \n",
    "    put in a new message with the topic and difficulty to generate a new question.\n",
    "\n",
    "    You are encouraged to use any tools available to look up relevant information, only\n",
    "    if necessary.\n",
    "\n",
    "    You will apologize if you're unable to generate an output that meets professor's requirement.\n",
    "\n",
    "    Your responses must always exactly match the specified JSON format with no extra words or content.\n",
    "\n",
    "    You must always produce exactly one JSON object.\n",
    "    \n",
    "    {format_instructions}\n",
    "    \"\"\")\n",
    "\n",
    "    parser = PydanticOutputParser(pydantic_object=pydantic_object)\n",
    "    return common_system_prompt.format(format_instructions=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06d39e29-dadd-4644-8c36-6418829a6f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Example usage\\ntry:\\n    result = generate_and_parse_question(YourPydanticModel, \"Your Query\")\\n    # Continue processing the result as needed\\nexcept Exception as e:\\n    print(f\"Error processing question: {e}\")\\n    # Handle the error, log, or notify the caller\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import ValidationError\n",
    "import json\n",
    "from json.decoder import JSONDecodeError\n",
    "\n",
    "# Function that takes the input, calls the retriever agent, and returns the parsed output\n",
    "def generate_and_parse_question(pydantic_model, query):\n",
    "    rag_chain = create_chain(create_system_prompt(pydantic_model), temperature=0.1, verbose=True, model_name=\"gpt-4-1106-preview\")\n",
    "    \n",
    "    try:\n",
    "        response = rag_chain(query)\n",
    "        report_on_message(response)  # print a summary of what was produced\n",
    "        parser = PydanticOutputParser(pydantic_object=pydantic_model)\n",
    "        return parser.parse(response[\"output\"])\n",
    "    except ValidationError as ve:\n",
    "        print(f\"Pydantic validation error: {ve}\")\n",
    "        # If Pydantic validation fails, fallback to json.loads\n",
    "        return json.loads(response[\"output\"])\n",
    "    except JSONDecodeError as json_error:\n",
    "        # If JSON decoding fails, perform json.loads and inform the caller about the error\n",
    "        result_output = json.loads(response[\"output\"])\n",
    "        print(f\"JSON decoding error: {json_error}\")\n",
    "        return result_output\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        # Handle other exceptions and fallback to json.loads\n",
    "        return json.loads(response[\"output\"])\n",
    "\n",
    "'''# Example usage\n",
    "try:\n",
    "    result = generate_and_parse_question(YourPydanticModel, \"Your Query\")\n",
    "    # Continue processing the result as needed\n",
    "except Exception as e:\n",
    "    print(f\"Error processing question: {e}\")\n",
    "    # Handle the error, log, or notify the caller\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1321739-6176-4c6a-95db-f8a101e38192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any intermediate_steps?:  True\n",
      "output:\n",
      " {\n",
      "  \"question_text\": \"Given the following DataFrame `df`, use the Pandas `groupby` method to calculate the mean value of the 'score' for each unique 'team'. Fill in the blanks to complete the code.\\n\\n```python\\ndf = pd.DataFrame({\\n    'team': ['A', 'A', 'B', 'B', 'C', 'C'],\\n    'score': [3, 4, 2, 5, 6, 1]\\n})\\n```\\n\",\n",
      "  \"difficulty\": 2,\n",
      "  \"topics\": [\"pandas\", \"groupby\", \"data analysis\"],\n",
      "  \"starting_code\": \"import pandas as pd\\n\\ndf = pd.DataFrame({\\n    'team': ['A', 'A', 'B', 'B', 'C', 'C'],\\n    'score': [3, 4, 2, 5, 6, 1]\\n})\\n\\nteam_means = df.groupby(___X)['score'].___X()\",\n",
      "  \"solution\": [\"'team'\", \"mean\"],\n",
      "  \"setup_code\": \"import pandas as pd\\n\\ndf = pd.DataFrame({\\n    'team': ['A', 'A', 'B', 'B', 'C', 'C'],\\n    'score': [3, 4, 2, 5, 6, 1]\\n})\",\n",
      "  \"test_code\": \"assert team_means.equals(pd.Series([3.5, 3.5, 1.0], index=['A', 'B', 'C'], name='score'))\"\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Given the following DataFrame `df`, use the Pandas `groupby` method to calculate the mean value of the 'score' for each unique 'team'. Fill in the blanks to complete the code.\n",
       "\n",
       "```python\n",
       "df = pd.DataFrame({\n",
       "    'team': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
       "    'score': [3, 4, 2, 5, 6, 1]\n",
       "})\n",
       "```\n",
       "\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "df = pd.DataFrame({\n",
       "    'team': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
       "    'score': [3, 4, 2, 5, 6, 1]\n",
       "})\n",
       "\n",
       "team_means = df.groupby(___X)['score'].___X()\n",
       "```\n",
       "\n",
       "**Solution**\n",
       "\n",
       "['team', mean]\n",
       "```\n",
       "\n",
       "**Rendered Solution**\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "df = pd.DataFrame({\n",
       "    'team': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
       "    'score': [3, 4, 2, 5, 6, 1]\n",
       "})\n",
       "\n",
       "team_means = df.groupby('team')['score'].mean()\n",
       "```\n",
       "\n",
       "**Test Suite**\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "df = pd.DataFrame({\n",
       "    'team': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
       "    'score': [3, 4, 2, 5, 6, 1]\n",
       "})\n",
       "\n",
       "import pandas as pd\n",
       "\n",
       "df = pd.DataFrame({\n",
       "    'team': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
       "    'score': [3, 4, 2, 5, 6, 1]\n",
       "})\n",
       "\n",
       "team_means = df.groupby('team')['score'].mean()\n",
       "\n",
       "assert team_means.equals(pd.Series([3.5, 3.5, 1.0], index=['A', 'B', 'C'], name='score'))\n",
       "```"
      ],
      "text/plain": [
       "Given the following DataFrame `df`, use the Pandas `groupby` method to calculate the mean value of the 'score' for each unique 'team'. Fill in the blanks to complete the code.\n",
       "\n",
       "```python\n",
       "df = pd.DataFrame({\n",
       "    'team': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
       "    'score': [3, 4, 2, 5, 6, 1]\n",
       "})\n",
       "```\n",
       "\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "df = pd.DataFrame({\n",
       "    'team': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
       "    'score': [3, 4, 2, 5, 6, 1]\n",
       "})\n",
       "\n",
       "team_means = df.groupby(___X)['score'].___X()\n",
       "```\n",
       "\n",
       "**Solution**\n",
       "\n",
       "['team', mean]\n",
       "```\n",
       "\n",
       "**Rendered Solution**\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "df = pd.DataFrame({\n",
       "    'team': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
       "    'score': [3, 4, 2, 5, 6, 1]\n",
       "})\n",
       "\n",
       "team_means = df.groupby('team')['score'].mean()\n",
       "```\n",
       "\n",
       "**Test Suite**\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "df = pd.DataFrame({\n",
       "    'team': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
       "    'score': [3, 4, 2, 5, 6, 1]\n",
       "})\n",
       "\n",
       "import pandas as pd\n",
       "\n",
       "df = pd.DataFrame({\n",
       "    'team': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
       "    'score': [3, 4, 2, 5, 6, 1]\n",
       "})\n",
       "\n",
       "team_means = df.groupby('team')['score'].mean()\n",
       "\n",
       "assert team_means.equals(pd.Series([3.5, 3.5, 1.0], index=['A', 'B', 'C'], name='score'))\n",
       "```"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_and_parse_question(FillInBlank, \"topic: pandas groupby\\ndifficulty: 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bdeb351-6a95-4037-810f-7804c8576463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any intermediate_steps?:  False\n",
      "output:\n",
      " {\n",
      "  \"description\": \"    Question type where the student is given a main question and then\\n    a code block with \\\"blanks\\\" (represented by `___X` in the source).\\n    The student must provide one string per blank. Correctness is evaluated\\n    based on a Python test suite based on the following template:\\n\\n    \\n    ```python\\n    {setup_code}\\n\\n    {code_block_with_blanks_filled_in}\\n\\n    {test_code}\\n    ```\\n\\n    There must be at least one `___X` (one blank) in `starting_code`\\n\\n\\n    Examples\\n    --------\\n    {\\n      \\\"question_text\\\": \\\"Suppose you have already executed the following code:\\n\\n```python\\nimport numpy as np\\n\\nA = np.array([[1, 2], [3, 4]])\\nb = np.array([10, 42])\\n```\\n\\nFill in the blanks below to solve the matrix equation $Ax = b$ for $x$\\n\\\",\\n      \\\"difficulty\\\": 2,\\n      \\\"topics\\\": [\\\"linear algebra\\\", \\\"regression\\\", \\\"numpy\\\"],\\n      \\\"starting_code\\\": \\\"from scipy.linalg import ___X\\n\\nx = ___X(A, ___X)\\\",\\n      \\\"solution\\\": [\\\"solve\\\", \\\"solve\\\", \\\"b\\\"],\\n      \\\"setup_code\\\": \\\"import numpy as np\\n\\nA = np.array([[1, 2], [3, 4]])\\nb = np.array([10, 42])\\n\\\",\\n      \\\"test_code\\\": \\\"assert np.allclose(x, [22, -6])\\\"\\n    }\\n    \", \n",
      "  \"properties\": {\n",
      "    \"question_text\": {\n",
      "      \"description\": \"The main text of the question. Markdown formatted\", \n",
      "      \"title\": \"Question Text\", \n",
      "      \"type\": \"string\"\n",
      "    }, \n",
      "    \"difficulty\": {\n",
      "      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\", \n",
      "      \"title\": \"Difficulty\", \n",
      "      \"type\": \"integer\"\n",
      "    }, \n",
      "    \"topics\": {\n",
      "      \"description\": \"A list of one or more topics that the question is testing\", \n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      }, \n",
      "      \"title\": \"Topics\", \n",
      "      \"type\": \"array\"\n",
      "    }, \n",
      "    \"starting_code\": {\n",
      "      \"description\": \" The starting code for the student. Must contain at least one `___X` (three underscores and capital `X`), which represents a blank that will be filled in by the student.\", \n",
      "      \"title\": \"Starting Code\", \n",
      "      \"type\": \"string\"\n",
      "    }, \n",
      "    \"solution\": {\n",
      "      \"description\": \"A list of strings representing the correct code to place in the blanks. Length must match number of `___X` that appear in `starting_code`.\", \n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      }, \n",
      "      \"title\": \"Solution\", \n",
      "      \"type\": \"array\"\n",
      "    }, \n",
      "    \"setup_code\": {\n",
      "      \"description\": \"Any code that needs to execute prior to the student code to ensure any libraries are imported and any variables are set up\", \n",
      "      \"title\": \"Setup Code\", \n",
      "      \"type\": \"string\"\n",
      "    }, \n",
      "    \"test_code\": {\n",
      "      \"description\": \"Code containing `assert` statements that verifies the correctness of the student's response\", \n",
      "      \"title\": \"Test Code\", \n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  }, \n",
      "  \"required\": [\n",
      "    \"question_text\", \n",
      "    \"difficulty\", \n",
      "    \"topics\", \n",
      "    \"starting_code\", \n",
      "    \"solution\", \n",
      "    \"setup_code\", \n",
      "    \"test_code\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"question_text\": \"Given the following Python code that defines a list of numbers:\\n\\n```python\\nnumbers = [1, 2, 3, 4, 5]\\n```\\n\\nWrite a function `multiply_elements` that takes a list and a multiplier as arguments and returns a new list with each element of the input list multiplied by the multiplier. Fill in the blanks to complete the function definition.\\n\",\n",
      "  \"difficulty\": 2,\n",
      "  \"topics\": [\"functions\", \"lists\", \"loops\"],\n",
      "  \"starting_code\": \"def multiply_elements(___X, multiplier):\\n    return [___X * multiplier for ___X in ___X]\",\n",
      "  \"solution\": [\"lst\", \"x\", \"x\", \"lst\"],\n",
      "  \"setup_code\": \"\",\n",
      "  \"test_code\": \"assert multiply_elements([1, 2, 3], 2) == [2, 4, 6], 'Test case 1 failed'\\nassert multiply_elements([7, 0, -1], 3) == [21, 0, -3], 'Test case 2 failed'\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "An error occurred: Failed to parse FillInBlank from completion {\n",
      "  \"description\": \"    Question type where the student is given a main question and then\\n    a code block with \\\"blanks\\\" (represented by `___X` in the source).\\n    The student must provide one string per blank. Correctness is evaluated\\n    based on a Python test suite based on the following template:\\n\\n    \\n    ```python\\n    {setup_code}\\n\\n    {code_block_with_blanks_filled_in}\\n\\n    {test_code}\\n    ```\\n\\n    There must be at least one `___X` (one blank) in `starting_code`\\n\\n\\n    Examples\\n    --------\\n    {\\n      \\\"question_text\\\": \\\"Suppose you have already executed the following code:\\n\\n```python\\nimport numpy as np\\n\\nA = np.array([[1, 2], [3, 4]])\\nb = np.array([10, 42])\\n```\\n\\nFill in the blanks below to solve the matrix equation $Ax = b$ for $x$\\n\\\",\\n      \\\"difficulty\\\": 2,\\n      \\\"topics\\\": [\\\"linear algebra\\\", \\\"regression\\\", \\\"numpy\\\"],\\n      \\\"starting_code\\\": \\\"from scipy.linalg import ___X\\n\\nx = ___X(A, ___X)\\\",\\n      \\\"solution\\\": [\\\"solve\\\", \\\"solve\\\", \\\"b\\\"],\\n      \\\"setup_code\\\": \\\"import numpy as np\\n\\nA = np.array([[1, 2], [3, 4]])\\nb = np.array([10, 42])\\n\\\",\\n      \\\"test_code\\\": \\\"assert np.allclose(x, [22, -6])\\\"\\n    }\\n    \", \n",
      "  \"properties\": {\n",
      "    \"question_text\": {\n",
      "      \"description\": \"The main text of the question. Markdown formatted\", \n",
      "      \"title\": \"Question Text\", \n",
      "      \"type\": \"string\"\n",
      "    }, \n",
      "    \"difficulty\": {\n",
      "      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\", \n",
      "      \"title\": \"Difficulty\", \n",
      "      \"type\": \"integer\"\n",
      "    }, \n",
      "    \"topics\": {\n",
      "      \"description\": \"A list of one or more topics that the question is testing\", \n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      }, \n",
      "      \"title\": \"Topics\", \n",
      "      \"type\": \"array\"\n",
      "    }, \n",
      "    \"starting_code\": {\n",
      "      \"description\": \" The starting code for the student. Must contain at least one `___X` (three underscores and capital `X`), which represents a blank that will be filled in by the student.\", \n",
      "      \"title\": \"Starting Code\", \n",
      "      \"type\": \"string\"\n",
      "    }, \n",
      "    \"solution\": {\n",
      "      \"description\": \"A list of strings representing the correct code to place in the blanks. Length must match number of `___X` that appear in `starting_code`.\", \n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      }, \n",
      "      \"title\": \"Solution\", \n",
      "      \"type\": \"array\"\n",
      "    }, \n",
      "    \"setup_code\": {\n",
      "      \"description\": \"Any code that needs to execute prior to the student code to ensure any libraries are imported and any variables are set up\", \n",
      "      \"title\": \"Setup Code\", \n",
      "      \"type\": \"string\"\n",
      "    }, \n",
      "    \"test_code\": {\n",
      "      \"description\": \"Code containing `assert` statements that verifies the correctness of the student's response\", \n",
      "      \"title\": \"Test Code\", \n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  }, \n",
      "  \"required\": [\n",
      "    \"question_text\", \n",
      "    \"difficulty\", \n",
      "    \"topics\", \n",
      "    \"starting_code\", \n",
      "    \"solution\", \n",
      "    \"setup_code\", \n",
      "    \"test_code\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"question_text\": \"Given the following Python code that defines a list of numbers:\\n\\n```python\\nnumbers = [1, 2, 3, 4, 5]\\n```\\n\\nWrite a function `multiply_elements` that takes a list and a multiplier as arguments and returns a new list with each element of the input list multiplied by the multiplier. Fill in the blanks to complete the function definition.\\n\",\n",
      "  \"difficulty\": 2,\n",
      "  \"topics\": [\"functions\", \"lists\", \"loops\"],\n",
      "  \"starting_code\": \"def multiply_elements(___X, multiplier):\\n    return [___X * multiplier for ___X in ___X]\",\n",
      "  \"solution\": [\"lst\", \"x\", \"x\", \"lst\"],\n",
      "  \"setup_code\": \"\",\n",
      "  \"test_code\": \"assert multiply_elements([1, 2, 3], 2) == [2, 4, 6], 'Test case 1 failed'\\nassert multiply_elements([7, 0, -1], 3) == [21, 0, -3], 'Test case 2 failed'\"\n",
      "}. Got: Extra data: line 56 column 1 (char 2945)\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 56 column 1 (char 2945)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:27\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     26\u001b[0m     json_str \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup()\n\u001b[0;32m---> 27\u001b[0m json_object \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object\u001b[38;5;241m.\u001b[39mparse_obj(json_object)\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 56 column 1 (char 2945)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mgenerate_and_parse_question\u001b[0;34m(pydantic_model, query)\u001b[0m\n\u001b[1;32m     12\u001b[0m     parser \u001b[38;5;241m=\u001b[39m PydanticOutputParser(pydantic_object\u001b[38;5;241m=\u001b[39mpydantic_model)\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m ve:\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:33\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     32\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to parse \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from completion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[38;5;241m=\u001b[39mtext)\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Failed to parse FillInBlank from completion {\n  \"description\": \"    Question type where the student is given a main question and then\\n    a code block with \\\"blanks\\\" (represented by `___X` in the source).\\n    The student must provide one string per blank. Correctness is evaluated\\n    based on a Python test suite based on the following template:\\n\\n    \\n    ```python\\n    {setup_code}\\n\\n    {code_block_with_blanks_filled_in}\\n\\n    {test_code}\\n    ```\\n\\n    There must be at least one `___X` (one blank) in `starting_code`\\n\\n\\n    Examples\\n    --------\\n    {\\n      \\\"question_text\\\": \\\"Suppose you have already executed the following code:\\n\\n```python\\nimport numpy as np\\n\\nA = np.array([[1, 2], [3, 4]])\\nb = np.array([10, 42])\\n```\\n\\nFill in the blanks below to solve the matrix equation $Ax = b$ for $x$\\n\\\",\\n      \\\"difficulty\\\": 2,\\n      \\\"topics\\\": [\\\"linear algebra\\\", \\\"regression\\\", \\\"numpy\\\"],\\n      \\\"starting_code\\\": \\\"from scipy.linalg import ___X\\n\\nx = ___X(A, ___X)\\\",\\n      \\\"solution\\\": [\\\"solve\\\", \\\"solve\\\", \\\"b\\\"],\\n      \\\"setup_code\\\": \\\"import numpy as np\\n\\nA = np.array([[1, 2], [3, 4]])\\nb = np.array([10, 42])\\n\\\",\\n      \\\"test_code\\\": \\\"assert np.allclose(x, [22, -6])\\\"\\n    }\\n    \", \n  \"properties\": {\n    \"question_text\": {\n      \"description\": \"The main text of the question. Markdown formatted\", \n      \"title\": \"Question Text\", \n      \"type\": \"string\"\n    }, \n    \"difficulty\": {\n      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\", \n      \"title\": \"Difficulty\", \n      \"type\": \"integer\"\n    }, \n    \"topics\": {\n      \"description\": \"A list of one or more topics that the question is testing\", \n      \"items\": {\n        \"type\": \"string\"\n      }, \n      \"title\": \"Topics\", \n      \"type\": \"array\"\n    }, \n    \"starting_code\": {\n      \"description\": \" The starting code for the student. Must contain at least one `___X` (three underscores and capital `X`), which represents a blank that will be filled in by the student.\", \n      \"title\": \"Starting Code\", \n      \"type\": \"string\"\n    }, \n    \"solution\": {\n      \"description\": \"A list of strings representing the correct code to place in the blanks. Length must match number of `___X` that appear in `starting_code`.\", \n      \"items\": {\n        \"type\": \"string\"\n      }, \n      \"title\": \"Solution\", \n      \"type\": \"array\"\n    }, \n    \"setup_code\": {\n      \"description\": \"Any code that needs to execute prior to the student code to ensure any libraries are imported and any variables are set up\", \n      \"title\": \"Setup Code\", \n      \"type\": \"string\"\n    }, \n    \"test_code\": {\n      \"description\": \"Code containing `assert` statements that verifies the correctness of the student's response\", \n      \"title\": \"Test Code\", \n      \"type\": \"string\"\n    }\n  }, \n  \"required\": [\n    \"question_text\", \n    \"difficulty\", \n    \"topics\", \n    \"starting_code\", \n    \"solution\", \n    \"setup_code\", \n    \"test_code\"\n  ]\n}\n{\n  \"question_text\": \"Given the following Python code that defines a list of numbers:\\n\\n```python\\nnumbers = [1, 2, 3, 4, 5]\\n```\\n\\nWrite a function `multiply_elements` that takes a list and a multiplier as arguments and returns a new list with each element of the input list multiplied by the multiplier. Fill in the blanks to complete the function definition.\\n\",\n  \"difficulty\": 2,\n  \"topics\": [\"functions\", \"lists\", \"loops\"],\n  \"starting_code\": \"def multiply_elements(___X, multiplier):\\n    return [___X * multiplier for ___X in ___X]\",\n  \"solution\": [\"lst\", \"x\", \"x\", \"lst\"],\n  \"setup_code\": \"\",\n  \"test_code\": \"assert multiply_elements([1, 2, 3], 2) == [2, 4, 6], 'Test case 1 failed'\\nassert multiply_elements([7, 0, -1], 3) == [21, 0, -3], 'Test case 2 failed'\"\n}. Got: Extra data: line 56 column 1 (char 2945)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_and_parse_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFillInBlank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGive me one more question on the same\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m, in \u001b[0;36mgenerate_and_parse_question\u001b[0;34m(pydantic_model, query)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Handle other exceptions and fallback to json.loads\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 56 column 1 (char 2945)"
     ]
    }
   ],
   "source": [
    "generate_and_parse_question(FillInBlank, \"Give me one more question on the same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d368e9d-e392-43bc-90b5-97520ad4c29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any intermediate_steps?:  True\n",
      "output:\n",
      " {\n",
      "  \"description\": \"Question where user is presented a prompt in `question_text` and \\na list of `choices`. They are supposed to provide all answers that\\napply (`solution`)\\n\\nAll questions must have a minimum of 3 options\\n\\nExamples\\n--------\\n{\\n  \\\"question_text\\\": \\\"What are some possible consequences of a learning rate that is too large?\\\",\\n  \\\"difficulty\\\": 2,\\n  \\\"topics\\\": [\\\"optimization\\\", \\\"gradient descent\\\"],\\n  \\\"choices\\\": [\\n    \\\"The algorithm never converges\\\",\\n    \\\"The algorithm becomes unstable\\\",\\n    \\\"Learning is stable, but very slow\\\"\\n  ],\\n  \\\"solution\\\": [0, 1]\\n}\",\n",
      "  \"properties\": {\n",
      "    \"question_text\": {\n",
      "      \"description\": \"The main text of the question. Markdown formatted\",\n",
      "      \"title\": \"Question Text\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"difficulty\": {\n",
      "      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n",
      "      \"title\": \"Difficulty\",\n",
      "      \"type\": \"integer\"\n",
      "    },\n",
      "    \"topics\": {\n",
      "      \"description\": \"A list of one or more topics that the question is testing\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Topics\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"choices\": {\n",
      "      \"description\": \"A list of markdown formatted strings representing the options for the student. Minimum length of 3.\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Choices\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"solution\": {\n",
      "      \"description\": \"List of indices into choices representing correct answers. Zero based\",\n",
      "      \"items\": {\n",
      "        \"type\": \"integer\"\n",
      "      },\n",
      "      \"title\": \"Solution\",\n",
      "      \"type\": \"array\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"question_text\",\n",
      "    \"difficulty\",\n",
      "    \"topics\",\n",
      "    \"choices\",\n",
      "    \"solution\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"question_text\": \"Which of the following NumPy functions can be used to calculate the dot product of two arrays?\",\n",
      "  \"difficulty\": 2,\n",
      "  \"topics\": [\"numpy\", \"linear algebra\"],\n",
      "  \"choices\": [\n",
      "    \"`np.dot`\",\n",
      "    \"`np.cross`\",\n",
      "    \"`np.matmul`\",\n",
      "    \"`np.divide`\"\n",
      "  ],\n",
      "  \"solution\": [0, 2]\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "An error occurred: Failed to parse MultipleSelection from completion {\n",
      "  \"description\": \"Question where user is presented a prompt in `question_text` and \\na list of `choices`. They are supposed to provide all answers that\\napply (`solution`)\\n\\nAll questions must have a minimum of 3 options\\n\\nExamples\\n--------\\n{\\n  \\\"question_text\\\": \\\"What are some possible consequences of a learning rate that is too large?\\\",\\n  \\\"difficulty\\\": 2,\\n  \\\"topics\\\": [\\\"optimization\\\", \\\"gradient descent\\\"],\\n  \\\"choices\\\": [\\n    \\\"The algorithm never converges\\\",\\n    \\\"The algorithm becomes unstable\\\",\\n    \\\"Learning is stable, but very slow\\\"\\n  ],\\n  \\\"solution\\\": [0, 1]\\n}\",\n",
      "  \"properties\": {\n",
      "    \"question_text\": {\n",
      "      \"description\": \"The main text of the question. Markdown formatted\",\n",
      "      \"title\": \"Question Text\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"difficulty\": {\n",
      "      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n",
      "      \"title\": \"Difficulty\",\n",
      "      \"type\": \"integer\"\n",
      "    },\n",
      "    \"topics\": {\n",
      "      \"description\": \"A list of one or more topics that the question is testing\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Topics\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"choices\": {\n",
      "      \"description\": \"A list of markdown formatted strings representing the options for the student. Minimum length of 3.\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Choices\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"solution\": {\n",
      "      \"description\": \"List of indices into choices representing correct answers. Zero based\",\n",
      "      \"items\": {\n",
      "        \"type\": \"integer\"\n",
      "      },\n",
      "      \"title\": \"Solution\",\n",
      "      \"type\": \"array\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"question_text\",\n",
      "    \"difficulty\",\n",
      "    \"topics\",\n",
      "    \"choices\",\n",
      "    \"solution\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"question_text\": \"Which of the following NumPy functions can be used to calculate the dot product of two arrays?\",\n",
      "  \"difficulty\": 2,\n",
      "  \"topics\": [\"numpy\", \"linear algebra\"],\n",
      "  \"choices\": [\n",
      "    \"`np.dot`\",\n",
      "    \"`np.cross`\",\n",
      "    \"`np.matmul`\",\n",
      "    \"`np.divide`\"\n",
      "  ],\n",
      "  \"solution\": [0, 2]\n",
      "}. Got: Extra data: line 47 column 1 (char 1767)\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 47 column 1 (char 1767)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:27\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     26\u001b[0m     json_str \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup()\n\u001b[0;32m---> 27\u001b[0m json_object \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object\u001b[38;5;241m.\u001b[39mparse_obj(json_object)\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 47 column 1 (char 1767)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mgenerate_and_parse_question\u001b[0;34m(pydantic_model, query)\u001b[0m\n\u001b[1;32m     12\u001b[0m     parser \u001b[38;5;241m=\u001b[39m PydanticOutputParser(pydantic_object\u001b[38;5;241m=\u001b[39mpydantic_model)\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m ve:\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:33\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     32\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to parse \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from completion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[38;5;241m=\u001b[39mtext)\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Failed to parse MultipleSelection from completion {\n  \"description\": \"Question where user is presented a prompt in `question_text` and \\na list of `choices`. They are supposed to provide all answers that\\napply (`solution`)\\n\\nAll questions must have a minimum of 3 options\\n\\nExamples\\n--------\\n{\\n  \\\"question_text\\\": \\\"What are some possible consequences of a learning rate that is too large?\\\",\\n  \\\"difficulty\\\": 2,\\n  \\\"topics\\\": [\\\"optimization\\\", \\\"gradient descent\\\"],\\n  \\\"choices\\\": [\\n    \\\"The algorithm never converges\\\",\\n    \\\"The algorithm becomes unstable\\\",\\n    \\\"Learning is stable, but very slow\\\"\\n  ],\\n  \\\"solution\\\": [0, 1]\\n}\",\n  \"properties\": {\n    \"question_text\": {\n      \"description\": \"The main text of the question. Markdown formatted\",\n      \"title\": \"Question Text\",\n      \"type\": \"string\"\n    },\n    \"difficulty\": {\n      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n      \"title\": \"Difficulty\",\n      \"type\": \"integer\"\n    },\n    \"topics\": {\n      \"description\": \"A list of one or more topics that the question is testing\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"title\": \"Topics\",\n      \"type\": \"array\"\n    },\n    \"choices\": {\n      \"description\": \"A list of markdown formatted strings representing the options for the student. Minimum length of 3.\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"title\": \"Choices\",\n      \"type\": \"array\"\n    },\n    \"solution\": {\n      \"description\": \"List of indices into choices representing correct answers. Zero based\",\n      \"items\": {\n        \"type\": \"integer\"\n      },\n      \"title\": \"Solution\",\n      \"type\": \"array\"\n    }\n  },\n  \"required\": [\n    \"question_text\",\n    \"difficulty\",\n    \"topics\",\n    \"choices\",\n    \"solution\"\n  ]\n}\n{\n  \"question_text\": \"Which of the following NumPy functions can be used to calculate the dot product of two arrays?\",\n  \"difficulty\": 2,\n  \"topics\": [\"numpy\", \"linear algebra\"],\n  \"choices\": [\n    \"`np.dot`\",\n    \"`np.cross`\",\n    \"`np.matmul`\",\n    \"`np.divide`\"\n  ],\n  \"solution\": [0, 2]\n}. Got: Extra data: line 47 column 1 (char 1767)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_and_parse_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMultipleSelection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQuestion on numpy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m, in \u001b[0;36mgenerate_and_parse_question\u001b[0;34m(pydantic_model, query)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Handle other exceptions and fallback to json.loads\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 47 column 1 (char 1767)"
     ]
    }
   ],
   "source": [
    "generate_and_parse_question(MultipleSelection, \"Question on topic numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c846b7c8-1ddd-4208-9f96-1ee6e96645e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any intermediate_steps?:  True\n",
      "output:\n",
      " {\n",
      "  \"description\": \"Question where user is presented a prompt in `question_text` and \\na list of `choices`. They are supposed to provide all answers that\\napply (`solution`)\\n\\nAll questions must have a minimum of 3 options\\n\\nExamples\\n--------\\n{\\n  \\\"question_text\\\": \\\"What are some possible consequences of a learning rate that is too large?\\\",\\n  \\\"difficulty\\\": 2,\\n  \\\"topics\\\": [\\\"optimization\\\", \\\"gradient descent\\\"],\\n  \\\"choices\\\": [\\n    \\\"The algorithm never converges\\\",\\n    \\\"The algorithm becomes unstable\\\",\\n    \\\"Learning is stable, but very slow\\\"\\n  ],\\n  \\\"solution\\\": [0, 1]\\n}\",\n",
      "  \"properties\": {\n",
      "    \"question_text\": {\n",
      "      \"description\": \"The main text of the question. Markdown formatted\",\n",
      "      \"title\": \"Question Text\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"difficulty\": {\n",
      "      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n",
      "      \"title\": \"Difficulty\",\n",
      "      \"type\": \"integer\"\n",
      "    },\n",
      "    \"topics\": {\n",
      "      \"description\": \"A list of one or more topics that the question is testing\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Topics\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"choices\": {\n",
      "      \"description\": \"A list of markdown formatted strings representing the options for the student. Minimum length of 3.\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Choices\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"solution\": {\n",
      "      \"description\": \"List of indices into choices representing correct answers. Zero based\",\n",
      "      \"items\": {\n",
      "        \"type\": \"integer\"\n",
      "      },\n",
      "      \"title\": \"Solution\",\n",
      "      \"type\": \"array\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"question_text\",\n",
      "    \"difficulty\",\n",
      "    \"topics\",\n",
      "    \"choices\",\n",
      "    \"solution\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"question_text\": \"Which of the following NumPy functions can be used to calculate the dot product of two arrays?\",\n",
      "  \"difficulty\": 2,\n",
      "  \"topics\": [\"numpy\", \"linear algebra\"],\n",
      "  \"choices\": [\n",
      "    \"`np.dot`\",\n",
      "    \"`np.cross`\",\n",
      "    \"`np.matmul`\",\n",
      "    \"`np.divide`\"\n",
      "  ],\n",
      "  \"solution\": [0, 2]\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "An error occurred: Failed to parse MultipleSelection from completion {\n",
      "  \"description\": \"Question where user is presented a prompt in `question_text` and \\na list of `choices`. They are supposed to provide all answers that\\napply (`solution`)\\n\\nAll questions must have a minimum of 3 options\\n\\nExamples\\n--------\\n{\\n  \\\"question_text\\\": \\\"What are some possible consequences of a learning rate that is too large?\\\",\\n  \\\"difficulty\\\": 2,\\n  \\\"topics\\\": [\\\"optimization\\\", \\\"gradient descent\\\"],\\n  \\\"choices\\\": [\\n    \\\"The algorithm never converges\\\",\\n    \\\"The algorithm becomes unstable\\\",\\n    \\\"Learning is stable, but very slow\\\"\\n  ],\\n  \\\"solution\\\": [0, 1]\\n}\",\n",
      "  \"properties\": {\n",
      "    \"question_text\": {\n",
      "      \"description\": \"The main text of the question. Markdown formatted\",\n",
      "      \"title\": \"Question Text\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"difficulty\": {\n",
      "      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n",
      "      \"title\": \"Difficulty\",\n",
      "      \"type\": \"integer\"\n",
      "    },\n",
      "    \"topics\": {\n",
      "      \"description\": \"A list of one or more topics that the question is testing\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Topics\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"choices\": {\n",
      "      \"description\": \"A list of markdown formatted strings representing the options for the student. Minimum length of 3.\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Choices\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"solution\": {\n",
      "      \"description\": \"List of indices into choices representing correct answers. Zero based\",\n",
      "      \"items\": {\n",
      "        \"type\": \"integer\"\n",
      "      },\n",
      "      \"title\": \"Solution\",\n",
      "      \"type\": \"array\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"question_text\",\n",
      "    \"difficulty\",\n",
      "    \"topics\",\n",
      "    \"choices\",\n",
      "    \"solution\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"question_text\": \"Which of the following NumPy functions can be used to calculate the dot product of two arrays?\",\n",
      "  \"difficulty\": 2,\n",
      "  \"topics\": [\"numpy\", \"linear algebra\"],\n",
      "  \"choices\": [\n",
      "    \"`np.dot`\",\n",
      "    \"`np.cross`\",\n",
      "    \"`np.matmul`\",\n",
      "    \"`np.divide`\"\n",
      "  ],\n",
      "  \"solution\": [0, 2]\n",
      "}. Got: Extra data: line 47 column 1 (char 1767)\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 47 column 1 (char 1767)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:27\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     26\u001b[0m     json_str \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup()\n\u001b[0;32m---> 27\u001b[0m json_object \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object\u001b[38;5;241m.\u001b[39mparse_obj(json_object)\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 47 column 1 (char 1767)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mgenerate_and_parse_question\u001b[0;34m(pydantic_model, query)\u001b[0m\n\u001b[1;32m     12\u001b[0m     parser \u001b[38;5;241m=\u001b[39m PydanticOutputParser(pydantic_object\u001b[38;5;241m=\u001b[39mpydantic_model)\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m ve:\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:33\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     32\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to parse \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from completion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[38;5;241m=\u001b[39mtext)\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Failed to parse MultipleSelection from completion {\n  \"description\": \"Question where user is presented a prompt in `question_text` and \\na list of `choices`. They are supposed to provide all answers that\\napply (`solution`)\\n\\nAll questions must have a minimum of 3 options\\n\\nExamples\\n--------\\n{\\n  \\\"question_text\\\": \\\"What are some possible consequences of a learning rate that is too large?\\\",\\n  \\\"difficulty\\\": 2,\\n  \\\"topics\\\": [\\\"optimization\\\", \\\"gradient descent\\\"],\\n  \\\"choices\\\": [\\n    \\\"The algorithm never converges\\\",\\n    \\\"The algorithm becomes unstable\\\",\\n    \\\"Learning is stable, but very slow\\\"\\n  ],\\n  \\\"solution\\\": [0, 1]\\n}\",\n  \"properties\": {\n    \"question_text\": {\n      \"description\": \"The main text of the question. Markdown formatted\",\n      \"title\": \"Question Text\",\n      \"type\": \"string\"\n    },\n    \"difficulty\": {\n      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n      \"title\": \"Difficulty\",\n      \"type\": \"integer\"\n    },\n    \"topics\": {\n      \"description\": \"A list of one or more topics that the question is testing\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"title\": \"Topics\",\n      \"type\": \"array\"\n    },\n    \"choices\": {\n      \"description\": \"A list of markdown formatted strings representing the options for the student. Minimum length of 3.\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"title\": \"Choices\",\n      \"type\": \"array\"\n    },\n    \"solution\": {\n      \"description\": \"List of indices into choices representing correct answers. Zero based\",\n      \"items\": {\n        \"type\": \"integer\"\n      },\n      \"title\": \"Solution\",\n      \"type\": \"array\"\n    }\n  },\n  \"required\": [\n    \"question_text\",\n    \"difficulty\",\n    \"topics\",\n    \"choices\",\n    \"solution\"\n  ]\n}\n{\n  \"question_text\": \"Which of the following NumPy functions can be used to calculate the dot product of two arrays?\",\n  \"difficulty\": 2,\n  \"topics\": [\"numpy\", \"linear algebra\"],\n  \"choices\": [\n    \"`np.dot`\",\n    \"`np.cross`\",\n    \"`np.matmul`\",\n    \"`np.divide`\"\n  ],\n  \"solution\": [0, 2]\n}. Got: Extra data: line 47 column 1 (char 1767)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_and_parse_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMultipleSelection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQuestion on topic numpy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m, in \u001b[0;36mgenerate_and_parse_question\u001b[0;34m(pydantic_model, query)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Handle other exceptions and fallback to json.loads\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 47 column 1 (char 1767)"
     ]
    }
   ],
   "source": [
    "generate_and_parse_question(MultipleSelection, \"Question on topic numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e86886a-5e45-4407-ac3d-1276ab659058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any intermediate_steps?:  True\n",
      "output:\n",
      " {\n",
      "  \"description\": \"Question where user is presented a prompt in `question_text` and \\na list of `choices`. They are supposed to provide all answers that\\napply (`solution`)\\n\\nAll questions must have a minimum of 3 options\\n\\nExamples\\n--------\\n{\\n  \\\"question_text\\\": \\\"Given a 3D NumPy array, which of the following operations can be used to obtain the sum of elements along the second axis?\\\",\\n  \\\"difficulty\\\": 3,\\n  \\\"topics\\\": [\\\"numpy\\\", \\\"array operations\\\"],\\n  \\\"choices\\\": [\\n    \\\"np.sum(array, axis=1)\\\",\\n    \\\"array.sum(axis=2)\\\",\\n    \\\"np.cumsum(array, axis=1)\\\",\\n    \\\"array.sum(axis=1)\\\"\\n  ],\\n  \\\"solution\\\": [0, 3]\\n}\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Pydantic validation error: 5 validation errors for MultipleSelection\n",
      "question_text\n",
      "  Field required [type=missing, input_value={'description': 'Question... \"solution\": [0, 3]\\n}'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n",
      "difficulty\n",
      "  Field required [type=missing, input_value={'description': 'Question... \"solution\": [0, 3]\\n}'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n",
      "topics\n",
      "  Field required [type=missing, input_value={'description': 'Question... \"solution\": [0, 3]\\n}'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n",
      "choices\n",
      "  Field required [type=missing, input_value={'description': 'Question... \"solution\": [0, 3]\\n}'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n",
      "solution\n",
      "  Field required [type=missing, input_value={'description': 'Question... \"solution\": [0, 3]\\n}'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'description': 'Question where user is presented a prompt in `question_text` and \\na list of `choices`. They are supposed to provide all answers that\\napply (`solution`)\\n\\nAll questions must have a minimum of 3 options\\n\\nExamples\\n--------\\n{\\n  \"question_text\": \"Given a 3D NumPy array, which of the following operations can be used to obtain the sum of elements along the second axis?\",\\n  \"difficulty\": 3,\\n  \"topics\": [\"numpy\", \"array operations\"],\\n  \"choices\": [\\n    \"np.sum(array, axis=1)\",\\n    \"array.sum(axis=2)\",\\n    \"np.cumsum(array, axis=1)\",\\n    \"array.sum(axis=1)\"\\n  ],\\n  \"solution\": [0, 3]\\n}'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_and_parse_question(MultipleSelection, \"Question on topic numpy, difficulty: 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "195fac45-1316-4388-af1e-0927c69f3156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any intermediate_steps?:  False\n",
      "output:\n",
      " {\n",
      "  \"description\": \"Question where user is presented a prompt in `question_text` and \\n    given `starting_code`. They are then supposed to modify the `starting_code`\\n    to complete the question. After doing so the code will be verified by running\\n    the following template as if it were python code:\\n\\n    ```python\\n    {setup_code}\\n\\n    {student_response}\\n\\n    {test_code}\\n    ```\\n\\n    The test code should have `assert` statements that verify the correctness of\\n    the `student_response`\\n\\n    Examples\\n    --------\\n    {\\n      \\\"question_text\\\": \\\"How would you create a `DatetimeIndex` starting on January 1, 2022 and ending on June 1, 2022 with the values taking every hour in between?\\n\\nSave this to a variable called `dates`\\\",\\n      \\\"difficulty\\\": 2,\\n      \\\"topics\\\": [\\\"pandas\\\", \\\"dates\\\"],\\n      \\\"starting_code\\\": \\\"dates = ...\\\",\\n      \\\"solution\\\": \\\"dates = pd.date_range(\\\"2022-01-01\\\", \\\"2022-06-01\\\", freq=\\\"h\\\")\\\",\\n      \\\"setup_code\\\": \\\"import pandas as pd\\\",\\n      \\\"test_code\\\": \\\"assert dates.sort_values()[0].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-01-01\\\"\\nassert dates.sort_values()[-1].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-06-01\\\"\\nassert dates.shape[0] == 3625\\\"\\n    }\\n    \",\n",
      "  \"properties\": {\n",
      "    \"question_text\": {\n",
      "      \"description\": \"The main text of the question. Markdown formatted\",\n",
      "      \"title\": \"Question Text\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"difficulty\": {\n",
      "      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n",
      "      \"title\": \"Difficulty\",\n",
      "      \"type\": \"integer\"\n",
      "    },\n",
      "    \"topics\": {\n",
      "      \"description\": \"A list of one or more topics that the question is testing\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Topics\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"starting_code\": {\n",
      "      \"description\": \"Starting code that will be the initial contents of the student's text editor. Used to provide scaffold/skeleton code\",\n",
      "      \"title\": \"Starting Code\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"solution\": {\n",
      "      \"description\": \"The correct code\",\n",
      "      \"title\": \"Solution\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"setup_code\": {\n",
      "      \"description\": \"Any code that needs to execute prior to the student code to ensure any libraries are imported and any variables are set up\",\n",
      "      \"title\": \"Setup Code\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"test_code\": {\n",
      "      \"description\": \"Code containing `assert` statements that verifies the correctnessof the student's response\",\n",
      "      \"title\": \"Test Code\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"question_text\",\n",
      "    \"difficulty\",\n",
      "    \"topics\",\n",
      "    \"starting_code\",\n",
      "    \"solution\",\n",
      "    \"setup_code\",\n",
      "    \"test_code\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"question_text\": \"Write a function `normalize_columns` that takes a NumPy array `data` and normalizes each column of the array so that the minimum value of each column is 0 and the maximum value is 1. The function should return the normalized array. Assume that `data` is a 2D array with at least one element in each column.\",\n",
      "  \"difficulty\": 3,\n",
      "  \"topics\": [\"numpy\", \"data normalization\"],\n",
      "  \"starting_code\": \"def normalize_columns(data):\\n    # Your code here\\n    return ...\",\n",
      "  \"solution\": \"def normalize_columns(data):\\n    min_vals = data.min(axis=0)\\n    max_vals = data.max(axis=0)\\n    return (data - min_vals) / (max_vals - min_vals)\",\n",
      "  \"setup_code\": \"import numpy as np\",\n",
      "  \"test_code\": \"data = np.array([[1, 2], [3, 4]])\\nnormalized_data = normalize_columns(data)\\nassert normalized_data[0, 0] == 0\\nassert normalized_data[1, 0] == 1\\nassert normalized_data[0, 1] == 0\\nassert normalized_data[1, 1] == 1\\n\\n# Test with another array\\ndata2 = np.array([[2, 10], [5, 15], [7, 20]])\\nnormalized_data2 = normalize_columns(data2)\\nassert np.allclose(normalized_data2[:, 0], [0, 0.5, 1])\\nassert np.allclose(normalized_data2[:, 1], [0, 0.33333333, 1])\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "An error occurred: Failed to parse Code from completion {\n",
      "  \"description\": \"Question where user is presented a prompt in `question_text` and \\n    given `starting_code`. They are then supposed to modify the `starting_code`\\n    to complete the question. After doing so the code will be verified by running\\n    the following template as if it were python code:\\n\\n    ```python\\n    {setup_code}\\n\\n    {student_response}\\n\\n    {test_code}\\n    ```\\n\\n    The test code should have `assert` statements that verify the correctness of\\n    the `student_response`\\n\\n    Examples\\n    --------\\n    {\\n      \\\"question_text\\\": \\\"How would you create a `DatetimeIndex` starting on January 1, 2022 and ending on June 1, 2022 with the values taking every hour in between?\\n\\nSave this to a variable called `dates`\\\",\\n      \\\"difficulty\\\": 2,\\n      \\\"topics\\\": [\\\"pandas\\\", \\\"dates\\\"],\\n      \\\"starting_code\\\": \\\"dates = ...\\\",\\n      \\\"solution\\\": \\\"dates = pd.date_range(\\\"2022-01-01\\\", \\\"2022-06-01\\\", freq=\\\"h\\\")\\\",\\n      \\\"setup_code\\\": \\\"import pandas as pd\\\",\\n      \\\"test_code\\\": \\\"assert dates.sort_values()[0].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-01-01\\\"\\nassert dates.sort_values()[-1].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-06-01\\\"\\nassert dates.shape[0] == 3625\\\"\\n    }\\n    \",\n",
      "  \"properties\": {\n",
      "    \"question_text\": {\n",
      "      \"description\": \"The main text of the question. Markdown formatted\",\n",
      "      \"title\": \"Question Text\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"difficulty\": {\n",
      "      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n",
      "      \"title\": \"Difficulty\",\n",
      "      \"type\": \"integer\"\n",
      "    },\n",
      "    \"topics\": {\n",
      "      \"description\": \"A list of one or more topics that the question is testing\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Topics\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"starting_code\": {\n",
      "      \"description\": \"Starting code that will be the initial contents of the student's text editor. Used to provide scaffold/skeleton code\",\n",
      "      \"title\": \"Starting Code\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"solution\": {\n",
      "      \"description\": \"The correct code\",\n",
      "      \"title\": \"Solution\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"setup_code\": {\n",
      "      \"description\": \"Any code that needs to execute prior to the student code to ensure any libraries are imported and any variables are set up\",\n",
      "      \"title\": \"Setup Code\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"test_code\": {\n",
      "      \"description\": \"Code containing `assert` statements that verifies the correctnessof the student's response\",\n",
      "      \"title\": \"Test Code\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"question_text\",\n",
      "    \"difficulty\",\n",
      "    \"topics\",\n",
      "    \"starting_code\",\n",
      "    \"solution\",\n",
      "    \"setup_code\",\n",
      "    \"test_code\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"question_text\": \"Write a function `normalize_columns` that takes a NumPy array `data` and normalizes each column of the array so that the minimum value of each column is 0 and the maximum value is 1. The function should return the normalized array. Assume that `data` is a 2D array with at least one element in each column.\",\n",
      "  \"difficulty\": 3,\n",
      "  \"topics\": [\"numpy\", \"data normalization\"],\n",
      "  \"starting_code\": \"def normalize_columns(data):\\n    # Your code here\\n    return ...\",\n",
      "  \"solution\": \"def normalize_columns(data):\\n    min_vals = data.min(axis=0)\\n    max_vals = data.max(axis=0)\\n    return (data - min_vals) / (max_vals - min_vals)\",\n",
      "  \"setup_code\": \"import numpy as np\",\n",
      "  \"test_code\": \"data = np.array([[1, 2], [3, 4]])\\nnormalized_data = normalize_columns(data)\\nassert normalized_data[0, 0] == 0\\nassert normalized_data[1, 0] == 1\\nassert normalized_data[0, 1] == 0\\nassert normalized_data[1, 1] == 1\\n\\n# Test with another array\\ndata2 = np.array([[2, 10], [5, 15], [7, 20]])\\nnormalized_data2 = normalize_columns(data2)\\nassert np.allclose(normalized_data2[:, 0], [0, 0.5, 1])\\nassert np.allclose(normalized_data2[:, 1], [0, 0.33333333, 1])\"\n",
      "}. Got: Extra data: line 53 column 1 (char 2720)\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 53 column 1 (char 2720)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:27\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     26\u001b[0m     json_str \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup()\n\u001b[0;32m---> 27\u001b[0m json_object \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object\u001b[38;5;241m.\u001b[39mparse_obj(json_object)\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 53 column 1 (char 2720)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mgenerate_and_parse_question\u001b[0;34m(pydantic_model, query)\u001b[0m\n\u001b[1;32m     12\u001b[0m     parser \u001b[38;5;241m=\u001b[39m PydanticOutputParser(pydantic_object\u001b[38;5;241m=\u001b[39mpydantic_model)\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m ve:\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:33\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     32\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to parse \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from completion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[38;5;241m=\u001b[39mtext)\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Failed to parse Code from completion {\n  \"description\": \"Question where user is presented a prompt in `question_text` and \\n    given `starting_code`. They are then supposed to modify the `starting_code`\\n    to complete the question. After doing so the code will be verified by running\\n    the following template as if it were python code:\\n\\n    ```python\\n    {setup_code}\\n\\n    {student_response}\\n\\n    {test_code}\\n    ```\\n\\n    The test code should have `assert` statements that verify the correctness of\\n    the `student_response`\\n\\n    Examples\\n    --------\\n    {\\n      \\\"question_text\\\": \\\"How would you create a `DatetimeIndex` starting on January 1, 2022 and ending on June 1, 2022 with the values taking every hour in between?\\n\\nSave this to a variable called `dates`\\\",\\n      \\\"difficulty\\\": 2,\\n      \\\"topics\\\": [\\\"pandas\\\", \\\"dates\\\"],\\n      \\\"starting_code\\\": \\\"dates = ...\\\",\\n      \\\"solution\\\": \\\"dates = pd.date_range(\\\"2022-01-01\\\", \\\"2022-06-01\\\", freq=\\\"h\\\")\\\",\\n      \\\"setup_code\\\": \\\"import pandas as pd\\\",\\n      \\\"test_code\\\": \\\"assert dates.sort_values()[0].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-01-01\\\"\\nassert dates.sort_values()[-1].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-06-01\\\"\\nassert dates.shape[0] == 3625\\\"\\n    }\\n    \",\n  \"properties\": {\n    \"question_text\": {\n      \"description\": \"The main text of the question. Markdown formatted\",\n      \"title\": \"Question Text\",\n      \"type\": \"string\"\n    },\n    \"difficulty\": {\n      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n      \"title\": \"Difficulty\",\n      \"type\": \"integer\"\n    },\n    \"topics\": {\n      \"description\": \"A list of one or more topics that the question is testing\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"title\": \"Topics\",\n      \"type\": \"array\"\n    },\n    \"starting_code\": {\n      \"description\": \"Starting code that will be the initial contents of the student's text editor. Used to provide scaffold/skeleton code\",\n      \"title\": \"Starting Code\",\n      \"type\": \"string\"\n    },\n    \"solution\": {\n      \"description\": \"The correct code\",\n      \"title\": \"Solution\",\n      \"type\": \"string\"\n    },\n    \"setup_code\": {\n      \"description\": \"Any code that needs to execute prior to the student code to ensure any libraries are imported and any variables are set up\",\n      \"title\": \"Setup Code\",\n      \"type\": \"string\"\n    },\n    \"test_code\": {\n      \"description\": \"Code containing `assert` statements that verifies the correctnessof the student's response\",\n      \"title\": \"Test Code\",\n      \"type\": \"string\"\n    }\n  },\n  \"required\": [\n    \"question_text\",\n    \"difficulty\",\n    \"topics\",\n    \"starting_code\",\n    \"solution\",\n    \"setup_code\",\n    \"test_code\"\n  ]\n}\n{\n  \"question_text\": \"Write a function `normalize_columns` that takes a NumPy array `data` and normalizes each column of the array so that the minimum value of each column is 0 and the maximum value is 1. The function should return the normalized array. Assume that `data` is a 2D array with at least one element in each column.\",\n  \"difficulty\": 3,\n  \"topics\": [\"numpy\", \"data normalization\"],\n  \"starting_code\": \"def normalize_columns(data):\\n    # Your code here\\n    return ...\",\n  \"solution\": \"def normalize_columns(data):\\n    min_vals = data.min(axis=0)\\n    max_vals = data.max(axis=0)\\n    return (data - min_vals) / (max_vals - min_vals)\",\n  \"setup_code\": \"import numpy as np\",\n  \"test_code\": \"data = np.array([[1, 2], [3, 4]])\\nnormalized_data = normalize_columns(data)\\nassert normalized_data[0, 0] == 0\\nassert normalized_data[1, 0] == 1\\nassert normalized_data[0, 1] == 0\\nassert normalized_data[1, 1] == 1\\n\\n# Test with another array\\ndata2 = np.array([[2, 10], [5, 15], [7, 20]])\\nnormalized_data2 = normalize_columns(data2)\\nassert np.allclose(normalized_data2[:, 0], [0, 0.5, 1])\\nassert np.allclose(normalized_data2[:, 1], [0, 0.33333333, 1])\"\n}. Got: Extra data: line 53 column 1 (char 2720)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_and_parse_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQuestion on topic numpy, difficulty: 3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m, in \u001b[0;36mgenerate_and_parse_question\u001b[0;34m(pydantic_model, query)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Handle other exceptions and fallback to json.loads\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 53 column 1 (char 2720)"
     ]
    }
   ],
   "source": [
    "generate_and_parse_question(Code, \"Question on topic numpy, difficulty: 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a58da7a-d4d7-4967-9310-6001cafde22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any intermediate_steps?:  True\n",
      "output:\n",
      " {\n",
      "  \"description\": \"    Question where user is presented a prompt in `question_text` and \\n    given `starting_code`. They are then supposed to modify the `starting_code`\\n    to complete the question. After doing so the code will be verified by running\\n    the following template as if it were python code:\\n\\n    ```python\\n    {setup_code}\\n\\n    {student_response}\\n\\n    {test_code}\\n    ```\\n\\n    The test code should have `assert` statements that verify the correctness of\\n    the `student_response`\\n\\n    Examples\\n    --------\\n    {\\n      \\\"question_text\\\": \\\"How would you create a `DatetimeIndex` starting on January 1, 2022 and ending on June 1, 2022 with the values taking every hour in between?\\n\\nSave this to a variable called `dates`\\\",\\n      \\\"difficulty\\\": 2,\\n      \\\"topics\\\": [\\\"pandas\\\", \\\"dates\\\"],\\n      \\\"starting_code\\\": \\\"dates = ...\\\",\\n      \\\"solution\\\": \\\"dates = pd.date_range(\\\"2022-01-01\\\", \\\"2022-06-01\\\", freq=\\\"h\\\")\\\",\\n      \\\"setup_code\\\": \\\"import pandas as pd\\\",\\n      \\\"test_code\\\": \\\"assert dates.sort_values()[0].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-01-01\\\"\\nassert dates.sort_values()[-1].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-06-01\\\"\\nassert dates.shape[0] == 3625\\\"\\n    }\\n    \",\n",
      "  \"properties\": {\n",
      "    \"question_text\": {\n",
      "      \"description\": \"The main text of the question. Markdown formatted\",\n",
      "      \"title\": \"Question Text\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"difficulty\": {\n",
      "      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n",
      "      \"title\": \"Difficulty\",\n",
      "      \"type\": \"integer\"\n",
      "    },\n",
      "    \"topics\": {\n",
      "      \"description\": \"A list of one or more topics that the question is testing\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Topics\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"starting_code\": {\n",
      "      \"description\": \"Starting code that will be the initial contents of the student's text editor. Used to provide scaffold/skeleton code\",\n",
      "      \"title\": \"Starting Code\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"solution\": {\n",
      "      \"description\": \"The correct code\",\n",
      "      \"title\": \"Solution\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"setup_code\": {\n",
      "      \"description\": \"Any code that needs to execute prior to the student code to ensure any libraries are imported and any variables are set up\",\n",
      "      \"title\": \"Setup Code\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"test_code\": {\n",
      "      \"description\": \"Code containing `assert` statements that verifies the correctnessof the student's response\",\n",
      "      \"title\": \"Test Code\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"question_text\",\n",
      "    \"difficulty\",\n",
      "    \"topics\",\n",
      "    \"starting_code\",\n",
      "    \"solution\",\n",
      "    \"setup_code\",\n",
      "    \"test_code\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"question_text\": \"Given a 2D NumPy array `data`, normalize the data in each column such that each value is scaled to have a mean of 0 and a standard deviation of 1. Save the result to a variable called `normalized_data`.\",\n",
      "  \"difficulty\": 3,\n",
      "  \"topics\": [\"numpy\", \"data normalization\", \"statistics\"],\n",
      "  \"starting_code\": \"normalized_data = ...\",\n",
      "  \"solution\": \"normalized_data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\",\n",
      "  \"setup_code\": \"import numpy as np\\\\ndata = np.random.rand(100, 5) * 20 + 5\",\n",
      "  \"test_code\": \"assert normalized_data.shape == data.shape\\\\nassert np.allclose(np.mean(normalized_data, axis=0), np.zeros(data.shape[1]), atol=1e-7)\\\\nassert np.allclose(np.std(normalized_data, axis=0), np.ones(data.shape[1]), atol=1e-7)\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "An error occurred: Failed to parse Code from completion {\n",
      "  \"description\": \"    Question where user is presented a prompt in `question_text` and \\n    given `starting_code`. They are then supposed to modify the `starting_code`\\n    to complete the question. After doing so the code will be verified by running\\n    the following template as if it were python code:\\n\\n    ```python\\n    {setup_code}\\n\\n    {student_response}\\n\\n    {test_code}\\n    ```\\n\\n    The test code should have `assert` statements that verify the correctness of\\n    the `student_response`\\n\\n    Examples\\n    --------\\n    {\\n      \\\"question_text\\\": \\\"How would you create a `DatetimeIndex` starting on January 1, 2022 and ending on June 1, 2022 with the values taking every hour in between?\\n\\nSave this to a variable called `dates`\\\",\\n      \\\"difficulty\\\": 2,\\n      \\\"topics\\\": [\\\"pandas\\\", \\\"dates\\\"],\\n      \\\"starting_code\\\": \\\"dates = ...\\\",\\n      \\\"solution\\\": \\\"dates = pd.date_range(\\\"2022-01-01\\\", \\\"2022-06-01\\\", freq=\\\"h\\\")\\\",\\n      \\\"setup_code\\\": \\\"import pandas as pd\\\",\\n      \\\"test_code\\\": \\\"assert dates.sort_values()[0].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-01-01\\\"\\nassert dates.sort_values()[-1].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-06-01\\\"\\nassert dates.shape[0] == 3625\\\"\\n    }\\n    \",\n",
      "  \"properties\": {\n",
      "    \"question_text\": {\n",
      "      \"description\": \"The main text of the question. Markdown formatted\",\n",
      "      \"title\": \"Question Text\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"difficulty\": {\n",
      "      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n",
      "      \"title\": \"Difficulty\",\n",
      "      \"type\": \"integer\"\n",
      "    },\n",
      "    \"topics\": {\n",
      "      \"description\": \"A list of one or more topics that the question is testing\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Topics\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"starting_code\": {\n",
      "      \"description\": \"Starting code that will be the initial contents of the student's text editor. Used to provide scaffold/skeleton code\",\n",
      "      \"title\": \"Starting Code\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"solution\": {\n",
      "      \"description\": \"The correct code\",\n",
      "      \"title\": \"Solution\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"setup_code\": {\n",
      "      \"description\": \"Any code that needs to execute prior to the student code to ensure any libraries are imported and any variables are set up\",\n",
      "      \"title\": \"Setup Code\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"test_code\": {\n",
      "      \"description\": \"Code containing `assert` statements that verifies the correctnessof the student's response\",\n",
      "      \"title\": \"Test Code\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"question_text\",\n",
      "    \"difficulty\",\n",
      "    \"topics\",\n",
      "    \"starting_code\",\n",
      "    \"solution\",\n",
      "    \"setup_code\",\n",
      "    \"test_code\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"question_text\": \"Given a 2D NumPy array `data`, normalize the data in each column such that each value is scaled to have a mean of 0 and a standard deviation of 1. Save the result to a variable called `normalized_data`.\",\n",
      "  \"difficulty\": 3,\n",
      "  \"topics\": [\"numpy\", \"data normalization\", \"statistics\"],\n",
      "  \"starting_code\": \"normalized_data = ...\",\n",
      "  \"solution\": \"normalized_data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\",\n",
      "  \"setup_code\": \"import numpy as np\\\\ndata = np.random.rand(100, 5) * 20 + 5\",\n",
      "  \"test_code\": \"assert normalized_data.shape == data.shape\\\\nassert np.allclose(np.mean(normalized_data, axis=0), np.zeros(data.shape[1]), atol=1e-7)\\\\nassert np.allclose(np.std(normalized_data, axis=0), np.ones(data.shape[1]), atol=1e-7)\"\n",
      "}. Got: Extra data: line 53 column 1 (char 2724)\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 53 column 1 (char 2724)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:27\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     26\u001b[0m     json_str \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup()\n\u001b[0;32m---> 27\u001b[0m json_object \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object\u001b[38;5;241m.\u001b[39mparse_obj(json_object)\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 53 column 1 (char 2724)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mgenerate_and_parse_question\u001b[0;34m(pydantic_model, query)\u001b[0m\n\u001b[1;32m     12\u001b[0m     parser \u001b[38;5;241m=\u001b[39m PydanticOutputParser(pydantic_object\u001b[38;5;241m=\u001b[39mpydantic_model)\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m ve:\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:33\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     32\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to parse \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from completion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[38;5;241m=\u001b[39mtext)\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Failed to parse Code from completion {\n  \"description\": \"    Question where user is presented a prompt in `question_text` and \\n    given `starting_code`. They are then supposed to modify the `starting_code`\\n    to complete the question. After doing so the code will be verified by running\\n    the following template as if it were python code:\\n\\n    ```python\\n    {setup_code}\\n\\n    {student_response}\\n\\n    {test_code}\\n    ```\\n\\n    The test code should have `assert` statements that verify the correctness of\\n    the `student_response`\\n\\n    Examples\\n    --------\\n    {\\n      \\\"question_text\\\": \\\"How would you create a `DatetimeIndex` starting on January 1, 2022 and ending on June 1, 2022 with the values taking every hour in between?\\n\\nSave this to a variable called `dates`\\\",\\n      \\\"difficulty\\\": 2,\\n      \\\"topics\\\": [\\\"pandas\\\", \\\"dates\\\"],\\n      \\\"starting_code\\\": \\\"dates = ...\\\",\\n      \\\"solution\\\": \\\"dates = pd.date_range(\\\"2022-01-01\\\", \\\"2022-06-01\\\", freq=\\\"h\\\")\\\",\\n      \\\"setup_code\\\": \\\"import pandas as pd\\\",\\n      \\\"test_code\\\": \\\"assert dates.sort_values()[0].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-01-01\\\"\\nassert dates.sort_values()[-1].strftime(\\\"%Y-%m-%d\\\") == \\\"2022-06-01\\\"\\nassert dates.shape[0] == 3625\\\"\\n    }\\n    \",\n  \"properties\": {\n    \"question_text\": {\n      \"description\": \"The main text of the question. Markdown formatted\",\n      \"title\": \"Question Text\",\n      \"type\": \"string\"\n    },\n    \"difficulty\": {\n      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n      \"title\": \"Difficulty\",\n      \"type\": \"integer\"\n    },\n    \"topics\": {\n      \"description\": \"A list of one or more topics that the question is testing\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"title\": \"Topics\",\n      \"type\": \"array\"\n    },\n    \"starting_code\": {\n      \"description\": \"Starting code that will be the initial contents of the student's text editor. Used to provide scaffold/skeleton code\",\n      \"title\": \"Starting Code\",\n      \"type\": \"string\"\n    },\n    \"solution\": {\n      \"description\": \"The correct code\",\n      \"title\": \"Solution\",\n      \"type\": \"string\"\n    },\n    \"setup_code\": {\n      \"description\": \"Any code that needs to execute prior to the student code to ensure any libraries are imported and any variables are set up\",\n      \"title\": \"Setup Code\",\n      \"type\": \"string\"\n    },\n    \"test_code\": {\n      \"description\": \"Code containing `assert` statements that verifies the correctnessof the student's response\",\n      \"title\": \"Test Code\",\n      \"type\": \"string\"\n    }\n  },\n  \"required\": [\n    \"question_text\",\n    \"difficulty\",\n    \"topics\",\n    \"starting_code\",\n    \"solution\",\n    \"setup_code\",\n    \"test_code\"\n  ]\n}\n{\n  \"question_text\": \"Given a 2D NumPy array `data`, normalize the data in each column such that each value is scaled to have a mean of 0 and a standard deviation of 1. Save the result to a variable called `normalized_data`.\",\n  \"difficulty\": 3,\n  \"topics\": [\"numpy\", \"data normalization\", \"statistics\"],\n  \"starting_code\": \"normalized_data = ...\",\n  \"solution\": \"normalized_data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\",\n  \"setup_code\": \"import numpy as np\\\\ndata = np.random.rand(100, 5) * 20 + 5\",\n  \"test_code\": \"assert normalized_data.shape == data.shape\\\\nassert np.allclose(np.mean(normalized_data, axis=0), np.zeros(data.shape[1]), atol=1e-7)\\\\nassert np.allclose(np.std(normalized_data, axis=0), np.ones(data.shape[1]), atol=1e-7)\"\n}. Got: Extra data: line 53 column 1 (char 2724)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_and_parse_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtopic:numpy, difficulty: 3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m, in \u001b[0;36mgenerate_and_parse_question\u001b[0;34m(pydantic_model, query)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Handle other exceptions and fallback to json.loads\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 53 column 1 (char 2724)"
     ]
    }
   ],
   "source": [
    "generate_and_parse_question(Code, \"topic:numpy, difficulty: 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06922d5c-e561-4fcf-814d-0e544e898185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any intermediate_steps?:  False\n",
      "output:\n",
      " {\n",
      "  \"description\": \"Please provide the topic and the current difficulty level to increase the difficulty of the question.\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "An error occurred: 7 validation errors for FillInBlank\n",
      "question_text\n",
      "  Field required [type=missing, input_value={'description': 'Please p...culty of the question.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n",
      "difficulty\n",
      "  Field required [type=missing, input_value={'description': 'Please p...culty of the question.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n",
      "topics\n",
      "  Field required [type=missing, input_value={'description': 'Please p...culty of the question.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n",
      "starting_code\n",
      "  Field required [type=missing, input_value={'description': 'Please p...culty of the question.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n",
      "solution\n",
      "  Field required [type=missing, input_value={'description': 'Please p...culty of the question.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n",
      "setup_code\n",
      "  Field required [type=missing, input_value={'description': 'Please p...culty of the question.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n",
      "test_code\n",
      "  Field required [type=missing, input_value={'description': 'Please p...culty of the question.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    generate_and_parse_question(FillInBlank, \"give me one more questions \")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "609d7fe2-77b3-4baa-a28d-618e8b6c4b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any intermediate_steps?:  True\n",
      "output:\n",
      " {\n",
      "  \"question_text\": \"Which of the following are main components of computational social science as discussed in the lecture?\",\n",
      "  \"difficulty\": 1,\n",
      "  \"topics\": [\"computational social science\", \"modeling\"],\n",
      "  \"choices\": [\n",
      "    \"Data and real-world observations\",\n",
      "    \"Statistical models and parameter adjustment\",\n",
      "    \"Prior beliefs and parameter plausibility\",\n",
      "    \"Physical experiments and laboratory tests\"\n",
      "  ],\n",
      "  \"solution\": [0, 1, 2]\n",
      "}\n",
      "{\n",
      "  \"question_text\": \"In the context of computational social science, what role do prior beliefs play in model parameter selection?\",\n",
      "  \"difficulty\": 1,\n",
      "  \"topics\": [\"computational social science\", \"modeling\"],\n",
      "  \"choices\": [\n",
      "    \"They are used to validate the final results of the model.\",\n",
      "    \"They guide the selection of parameters that match both the data and our understanding of the world.\",\n",
      "    \"They are irrelevant and should not influence the model.\",\n",
      "    \"They are used to replace real-world data when it is not available.\"\n",
      "  ],\n",
      "  \"solution\": [1]\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "An error occurred: Failed to parse MultipleSelection from completion {\n",
      "  \"question_text\": \"Which of the following are main components of computational social science as discussed in the lecture?\",\n",
      "  \"difficulty\": 1,\n",
      "  \"topics\": [\"computational social science\", \"modeling\"],\n",
      "  \"choices\": [\n",
      "    \"Data and real-world observations\",\n",
      "    \"Statistical models and parameter adjustment\",\n",
      "    \"Prior beliefs and parameter plausibility\",\n",
      "    \"Physical experiments and laboratory tests\"\n",
      "  ],\n",
      "  \"solution\": [0, 1, 2]\n",
      "}\n",
      "{\n",
      "  \"question_text\": \"In the context of computational social science, what role do prior beliefs play in model parameter selection?\",\n",
      "  \"difficulty\": 1,\n",
      "  \"topics\": [\"computational social science\", \"modeling\"],\n",
      "  \"choices\": [\n",
      "    \"They are used to validate the final results of the model.\",\n",
      "    \"They guide the selection of parameters that match both the data and our understanding of the world.\",\n",
      "    \"They are irrelevant and should not influence the model.\",\n",
      "    \"They are used to replace real-world data when it is not available.\"\n",
      "  ],\n",
      "  \"solution\": [1]\n",
      "}. Got: Extra data: line 13 column 1 (char 438)\n",
      "An error occurred: Extra data: line 13 column 1 (char 438)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    generate_and_parse_question(MultipleSelection, \"Give me 2 more questions on the previous topic with diffculty 1 \")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07d420c5-ef00-4fcb-b94f-985fbc8c4b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any intermediate_steps?:  False\n",
      "output:\n",
      " {\n",
      "  \"error\": \"Please provide a topic and a difficulty level for the question.\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Pydantic validation error: 5 validation errors for MultipleSelection\n",
      "question_text\n",
      "  Field required [type=missing, input_value={'error': 'Please provide...evel for the question.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n",
      "difficulty\n",
      "  Field required [type=missing, input_value={'error': 'Please provide...evel for the question.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n",
      "topics\n",
      "  Field required [type=missing, input_value={'error': 'Please provide...evel for the question.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n",
      "choices\n",
      "  Field required [type=missing, input_value={'error': 'Please provide...evel for the question.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n",
      "solution\n",
      "  Field required [type=missing, input_value={'error': 'Please provide...evel for the question.'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/missing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'error': 'Please provide a topic and a difficulty level for the question.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_and_parse_question(MultipleSelection, \"Give me an easier question \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyteach)",
   "language": "python",
   "name": "jupyteach"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
