{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9968ecd3-1eda-4e72-a77b-d3bffc8e0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.messages import SystemMessage\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "import textwrap\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from question_generator_model import SingleSelection, Code, AnyQuestion, FillInBlank, MultipleSelection\n",
    "\n",
    "load_dotenv(\"/home/jupyteach-msda/jupyteach-ai/.env\")\n",
    "\n",
    "COLLECTION_NAME = \"documents\"\n",
    "DB_CONNECTION = \"postgresql://postgres:supa-jupyteach@192.168.0.77:54328/postgres\"\n",
    "\n",
    "\n",
    "def get_vectorstore():\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    db = PGVector(embedding_function=embeddings,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        connection_string=DB_CONNECTION,\n",
    "    )\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e410d458-7f99-4368-a69e-a34f423791eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that takes the input and returns the output from the retreival agent\n",
    "def create_chain(\n",
    "        system_message_text, \n",
    "        temperature=0, \n",
    "        model_name=\"gpt-3.5-turbo-1106\", \n",
    "        model_kwargs={\"response_format\": {\"type\": \"json_object\"}},\n",
    "        verbose=False,\n",
    "    ):\n",
    "    # step 1: create llm\n",
    "    retriever = get_vectorstore().as_retriever()\n",
    "    llm = ChatOpenAI(temperature=temperature, model_name=model_name, model_kwargs=model_kwargs, verbose=verbose)\n",
    "    \n",
    "    # step 2: create retriever tool\n",
    "    tool = create_retriever_tool(\n",
    "        retriever,\n",
    "        \"search_course_content\",\n",
    "        \"Searches and returns documents regarding the contents of the course and notes from the instructor.\",\n",
    "    )\n",
    "    tools = [tool]\n",
    "\n",
    "    # step 3: create system message from the text passed in as an argument\n",
    "    system_message = SystemMessage(content=system_message_text)\n",
    "\n",
    "    # return the chain\n",
    "    return create_conversational_retrieval_agent(\n",
    "        llm=llm, \n",
    "        tools=tools, \n",
    "        verbose=verbose, \n",
    "        system_message=system_message\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d30f26d-5f64-488b-aa4c-c0150387dfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to check if the retrieval is happening\n",
    "def report_on_message(msg):\n",
    "    print(\"any intermediate_steps?: \", len(msg[\"intermediate_steps\"]) > 0)\n",
    "    print(\"output:\\n\", msg[\"output\"])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a67f269c-5ff9-4bd0-a256-1edd5bc0a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fucntion that returns the system prompt with the format of the question requested \n",
    "def create_system_prompt(pydantic_object):\n",
    "    common_system_prompt = textwrap.dedent(\"\"\"\n",
    "    You are a smart, helpful teaching assistant chatbot named AcademiaGPT.\n",
    "\n",
    "    You are an expert Python programmer with 15+ year experience and have used all the most popular\n",
    "    libraries for data analysis, machine learning, and artificial intelligence.\n",
    "\n",
    "    You assist professors that teach courses about Python, data science, and machine learning\n",
    "    to college students.\n",
    "\n",
    "    Your task is to help professors produce practice questions to help students solidify \n",
    "    their understanding of specific topics\n",
    "\n",
    "    In your conversations with a professor you  will be given a topic (string) and an\n",
    "    expected difficulty level (integer)\n",
    "    \n",
    "    The difficulty will be a number between 1 and 3, with 1 corresponding to a request \n",
    "    for an easy question, and 3 for the most difficult question.\n",
    "\n",
    "    If the difficulty or the topic is not mentioned by the professor in the message for you to generate a question, use the difficulty or topic or both from the previous question generated.\n",
    "\n",
    "    You must always generate questions that have more than one option as solution for the MultipleSelection question type.\n",
    "\n",
    "    \n",
    "    Occasionaly the professor may ask you to do something like produce a similar question,\n",
    "    or try again and make it more difficult or easy. You need to assist the professor with the same.\n",
    "\n",
    "    You are encouraged to use any tools available to look up relevant informati on, onlyif necessary.\n",
    "\n",
    "    If the professor ask for more than one question in a single message, you need to apologize and inform that you can only generate one \n",
    "    question at a time. You need to also ask the professor to put in a new message with the topic and difficulty to generate a new question.\n",
    "\n",
    "    Your responses must always exactly match the specified JSON format with no extra words or content.\n",
    "\n",
    "    You must always produce exactly one JSON object.\n",
    "\n",
    "    Your responses should always be consistent.\n",
    "    \n",
    "    {format_instructions}\n",
    "    \"\"\")\n",
    "\n",
    "    parser = PydanticOutputParser(pydantic_object=pydantic_object)\n",
    "    return common_system_prompt.format(format_instructions=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b70a3eb7-4228-4c08-bd9d-d19d3776fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fucntion that takes the input, call the retreiver agent, and returns the parsed output\n",
    "def generate_and_parse_question(pydantic_model, query):\n",
    "    rag_chain = create_chain(create_system_prompt(pydantic_model), temperature=0.1, verbose=True, model_name=\"gpt-4-1106-preview\")\n",
    "    response = rag_chain(query)\n",
    "    report_on_message(response)  # print a summary of what was produced\n",
    "    parser = PydanticOutputParser(pydantic_object=pydantic_model)\n",
    "    return parser.parse(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1321739-6176-4c6a-95db-f8a101e38192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "  \"description\": \"Question where user is presented a prompt in `question_text` and \\na list of `choices`. They are supposed to provide all answers that\\napply (`solution`)\\n\\nAll questions must have a minimum of 3 options\\n\\nExamples\\n--------\\n{\\n  \\\"question_text\\\": \\\"Using the pandas `groupby` method, which of the following operations can you perform after grouping a DataFrame by one or more columns?\\\",\\n  \\\"difficulty\\\": 2,\\n  \\\"topics\\\": [\\\"pandas\\\", \\\"data analysis\\\", \\\"groupby\\\"],\\n  \\\"choices\\\": [\\n    \\\"Calculate the sum of each group\\\",\\n    \\\"Find the maximum value in each group\\\",\\n    \\\"Perform a linear regression on each group\\\",\\n    \\\"Apply a custom function to each group\\\"\\n  ],\\n  \\\"solution\\\": [0, 1, 3]\\n}\",\n",
      "  \"properties\": {\n",
      "    \"question_text\": {\n",
      "      \"description\": \"The main text of the question. Markdown formatted\",\n",
      "      \"title\": \"Question Text\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"difficulty\": {\n",
      "      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n",
      "      \"title\": \"Difficulty\",\n",
      "      \"type\": \"integer\"\n",
      "    },\n",
      "    \"topics\": {\n",
      "      \"description\": \"A list of one or more topics that the question is testing\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Topics\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"choices\": {\n",
      "      \"description\": \"A list of markdown formatted strings representing the options for the student. Minimum length of 3.\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Choices\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"solution\": {\n",
      "      \"description\": \"List of indices into choices representing correct answers. Zero based\",\n",
      "      \"items\": {\n",
      "        \"type\": \"integer\"\n",
      "      },\n",
      "      \"title\": \"Solution\",\n",
      "      \"type\": \"array\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\"question_text\", \"difficulty\", \"topics\", \"choices\", \"solution\"]\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "any intermediate_steps?:  False\n",
      "output:\n",
      " {\n",
      "  \"description\": \"Question where user is presented a prompt in `question_text` and \\na list of `choices`. They are supposed to provide all answers that\\napply (`solution`)\\n\\nAll questions must have a minimum of 3 options\\n\\nExamples\\n--------\\n{\\n  \\\"question_text\\\": \\\"Using the pandas `groupby` method, which of the following operations can you perform after grouping a DataFrame by one or more columns?\\\",\\n  \\\"difficulty\\\": 2,\\n  \\\"topics\\\": [\\\"pandas\\\", \\\"data analysis\\\", \\\"groupby\\\"],\\n  \\\"choices\\\": [\\n    \\\"Calculate the sum of each group\\\",\\n    \\\"Find the maximum value in each group\\\",\\n    \\\"Perform a linear regression on each group\\\",\\n    \\\"Apply a custom function to each group\\\"\\n  ],\\n  \\\"solution\\\": [0, 1, 3]\\n}\",\n",
      "  \"properties\": {\n",
      "    \"question_text\": {\n",
      "      \"description\": \"The main text of the question. Markdown formatted\",\n",
      "      \"title\": \"Question Text\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"difficulty\": {\n",
      "      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n",
      "      \"title\": \"Difficulty\",\n",
      "      \"type\": \"integer\"\n",
      "    },\n",
      "    \"topics\": {\n",
      "      \"description\": \"A list of one or more topics that the question is testing\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Topics\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"choices\": {\n",
      "      \"description\": \"A list of markdown formatted strings representing the options for the student. Minimum length of 3.\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Choices\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"solution\": {\n",
      "      \"description\": \"List of indices into choices representing correct answers. Zero based\",\n",
      "      \"items\": {\n",
      "        \"type\": \"integer\"\n",
      "      },\n",
      "      \"title\": \"Solution\",\n",
      "      \"type\": \"array\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\"question_text\", \"difficulty\", \"topics\", \"choices\", \"solution\"]\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "5 validation errors for MultipleSelection\nquestion_text\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ndifficulty\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ntopics\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nchoices\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nsolution\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_and_parse_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMultipleSelection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpandas groupby with difficulty 2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36mgenerate_and_parse_question\u001b[0;34m(pydantic_model, query)\u001b[0m\n\u001b[1;32m      5\u001b[0m report_on_message(response)  \u001b[38;5;66;03m# print a summary of what was produced\u001b[39;00m\n\u001b[1;32m      6\u001b[0m parser \u001b[38;5;241m=\u001b[39m PydanticOutputParser(pydantic_object\u001b[38;5;241m=\u001b[39mpydantic_model)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:28\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     26\u001b[0m         json_str \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup()\n\u001b[1;32m     27\u001b[0m     json_object \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(json_str, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpydantic_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (json\u001b[38;5;241m.\u001b[39mJSONDecodeError, ValidationError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     31\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/typing_extensions.py:2360\u001b[0m, in \u001b[0;36mdeprecated.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2357\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(arg)\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2359\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, category\u001b[38;5;241m=\u001b[39mcategory, stacklevel\u001b[38;5;241m=\u001b[39mstacklevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 2360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/pydantic/main.py:1010\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;129m@typing_extensions\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated(\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39mPydanticDeprecatedSince20\n\u001b[1;32m   1007\u001b[0m )\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_obj\u001b[39m(\u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[Model], obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Model:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/pydantic/main.py:503\u001b[0m, in \u001b[0;36mBaseModel.model_validate\u001b[0;34m(cls, obj, strict, from_attributes, context)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    502\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 5 validation errors for MultipleSelection\nquestion_text\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ndifficulty\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ntopics\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nchoices\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nsolution\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing"
     ]
    }
   ],
   "source": [
    "generate_and_parse_question(MultipleSelection, \"pandas groupby with difficulty 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bdeb351-6a95-4037-810f-7804c8576463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "  \"question_text\": \"What are the characteristics of a scale-free network?\",\n",
      "  \"difficulty\": 1,\n",
      "  \"topics\": [\"scale-free network\"],\n",
      "  \"choices\": [\n",
      "    \"The network follows a power-law degree distribution\",\n",
      "    \"All nodes have the same number of connections\",\n",
      "    \"The network is immune to random failures\",\n",
      "    \"Most nodes have a few connections, while a few nodes have many connections\"\n",
      "  ],\n",
      "  \"solution\": [0, 3]\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "any intermediate_steps?:  False\n",
      "output:\n",
      " {\n",
      "  \"question_text\": \"What are the characteristics of a scale-free network?\",\n",
      "  \"difficulty\": 1,\n",
      "  \"topics\": [\"scale-free network\"],\n",
      "  \"choices\": [\n",
      "    \"The network follows a power-law degree distribution\",\n",
      "    \"All nodes have the same number of connections\",\n",
      "    \"The network is immune to random failures\",\n",
      "    \"Most nodes have a few connections, while a few nodes have many connections\"\n",
      "  ],\n",
      "  \"solution\": [0, 3]\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "What are the characteristics of a scale-free network?\n",
       "\n",
       "- [x] The network follows a power-law degree distribution\n",
       "- [ ] All nodes have the same number of connections\n",
       "- [ ] The network is immune to random failures\n",
       "- [x] Most nodes have a few connections, while a few nodes have many connections\n"
      ],
      "text/plain": [
       "What are the characteristics of a scale-free network?\n",
       "\n",
       "- [x] The network follows a power-law degree distribution\n",
       "- [ ] All nodes have the same number of connections\n",
       "- [ ] The network is immune to random failures\n",
       "- [x] Most nodes have a few connections, while a few nodes have many connections"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_and_parse_question(MultipleSelection, \"topic scale-free network, difficulty 1 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c98d811b-fc2a-4d90-850d-23170ded325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_course_content` with `convex optimization`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(page_content=\"these model these problems are that they use the same statistical model F of a given data. There are some tools that allow us to solve the direct problem which again relates to simulating artificial data and these tools in fact turn out to be helpful when solving the inverse problem or learning something about the parameter vector theta. We're going to be continuing in this general framework of a statistical model the direct problem in the inverse problem as we talk today about the lake model of unemployment that we've been working with and we want to make sure that as we work through the materials in this lecture that you keep this overall framework in mind and our goal today will be to use the lake model and its parameters and inferences we can make about its parameters given real world data from the BLS and it will help us understand the unemployment and employment rates over time and how they may change in various settings or in various economic climates. This first code cell here will just import some of the tools we'll be using.\", metadata={'source': 'videos/transcripts_tiny/2.11.2 Lake Model Meets Data (1 of 2).srt', 'chunk_number': 3, 'timestamps': '00:04:11 --> 00:05:38'}), Document(page_content=\"So Jim's not a particularly. Hard guy to get along with. He's actually very friendly. And so his choice of the word argue. I think tells you a little bit about who you should be talking to about this. You don't want someone that's going to just tell you that it's nice work. You want someone that's going to be able to ask you questions and say, why did you do that? Well, what if you did this instead? So you want someone that's going to push back a little bit. Step eight is then returned to step two and work with a slightly richer model and we repeat steps three, four, five, six and seven. And then once you've done this with a sufficiently rich model, you should think about what decisions are going to be made from this analysis. Figure out what your loss function will be, kind of what are the costs of getting this right or wrong. And then you should perform make decisions based on statistical decision analysis. And so later in the semester, we'll talk more formally about what we mean by fitting your model and the work that goes along with it.\", metadata={'source': 'videos/transcripts_tiny/2.11.1 Lake Model.srt', 'chunk_number': 3, 'timestamps': '00:03:52 --> 00:05:05'}), Document(page_content=\"the average squared deviation of our steady state model for our good recession data ended up being about 29%. Or value 29%age points. Remember that was the units we chose. So the mean squared error was about 29 and for the COVID data it was about 12. So just kind of keep these numbers in the back your head as these are going to be our benchmark for evaluating one model versus another one. And in particular the use of a loss function allows us to be precise about what we mean when we say a model is better or has improved upon a different model. It allows us to move from a qualitative notion of how good a model fits the data to a very quantitative version. So for example instead of saying model 2 appears to do better than model 1 that matching the spike in the COVID error unemployment. We could say that the MSC COVID from model 2 is 5.1 relative to the value of 11.5 from model 1. So we've moved from a qualitative statement here to a quantitative numerical statement down below. And this will make it easier to have\", metadata={'source': 'videos/transcripts_tiny/2.11.2 Lake Model Meets Data (1 of 2).srt', 'chunk_number': 27, 'timestamps': '00:35:11 --> 00:36:31'}), Document(page_content=\"model and the blue line representing the COVID era data. So these initial test values as we just noticed did improve the MSC but we didn't have any reason to believe that the values we picked were going to be the optimal or best values. There are infinite numbers of configurations of alpha hat, beta hat and end we could have tried or infinite number of other models we could have used. And so what we're going to do next is we're going to assume the role of the visual econometrition and hard goals will be to look at these graphs and graphs and the MSC to try to manually adjust alpha hat, beta hat and end to improve upon this MSC of 2.6. So we're going to utilize the ipy widgets library to create an interactive version of our chart. So here we see that we're going to wrap the simulate plot and MSC steps in a function and then we're going to use the intractor team and say how we'd like alpha hat to be manipulated, beta hat to be manipulated and then a starting value for end. And what this did was it returned our MSC like we had before and we see that we're still near\", metadata={'source': 'videos/transcripts_tiny/2.11.2 Lake Model Meets Data (1 of 2).srt', 'chunk_number': 42, 'timestamps': '00:55:22 --> 00:56:55'})]\u001b[0m\u001b[32;1m\u001b[1;3m{\n",
      "  \"question_text\": \"In the context of convex optimization, which of the following statements are true regarding the use of a loss function?\",\n",
      "  \"difficulty\": 3,\n",
      "  \"topics\": [\"convex optimization\", \"loss function\", \"model evaluation\"],\n",
      "  \"choices\": [\n",
      "    \"A loss function allows us to move from a qualitative notion of how good a model fits the data to a very quantitative version.\",\n",
      "    \"A loss function is only useful for qualitative comparisons between models.\",\n",
      "    \"The mean squared error (MSE) is an example of a loss function that can be used to evaluate the performance of a model.\"\n",
      "  ],\n",
      "  \"solution\": 0\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "any intermediate_steps?:  True\n",
      "output:\n",
      " {\n",
      "  \"question_text\": \"In the context of convex optimization, which of the following statements are true regarding the use of a loss function?\",\n",
      "  \"difficulty\": 3,\n",
      "  \"topics\": [\"convex optimization\", \"loss function\", \"model evaluation\"],\n",
      "  \"choices\": [\n",
      "    \"A loss function allows us to move from a qualitative notion of how good a model fits the data to a very quantitative version.\",\n",
      "    \"A loss function is only useful for qualitative comparisons between models.\",\n",
      "    \"The mean squared error (MSE) is an example of a loss function that can be used to evaluate the performance of a model.\"\n",
      "  ],\n",
      "  \"solution\": 0\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In the context of convex optimization, which of the following statements are true regarding the use of a loss function?\n",
       "\n",
       "- [x] A loss function allows us to move from a qualitative notion of how good a model fits the data to a very quantitative version.\n",
       "- [ ] A loss function is only useful for qualitative comparisons between models.\n",
       "- [ ] The mean squared error (MSE) is an example of a loss function that can be used to evaluate the performance of a model.\n"
      ],
      "text/plain": [
       "In the context of convex optimization, which of the following statements are true regarding the use of a loss function?\n",
       "\n",
       "- [x] A loss function allows us to move from a qualitative notion of how good a model fits the data to a very quantitative version.\n",
       "- [ ] A loss function is only useful for qualitative comparisons between models.\n",
       "- [ ] The mean squared error (MSE) is an example of a loss function that can be used to evaluate the performance of a model."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_and_parse_question(SingleSelection, \"convex optimization, difficulty 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0d368e9d-e392-43bc-90b5-97520ad4c29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_course_content` with `convex optimization`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(page_content=\"these model these problems are that they use the same statistical model F of a given data. There are some tools that allow us to solve the direct problem which again relates to simulating artificial data and these tools in fact turn out to be helpful when solving the inverse problem or learning something about the parameter vector theta. We're going to be continuing in this general framework of a statistical model the direct problem in the inverse problem as we talk today about the lake model of unemployment that we've been working with and we want to make sure that as we work through the materials in this lecture that you keep this overall framework in mind and our goal today will be to use the lake model and its parameters and inferences we can make about its parameters given real world data from the BLS and it will help us understand the unemployment and employment rates over time and how they may change in various settings or in various economic climates. This first code cell here will just import some of the tools we'll be using.\", metadata={'source': 'videos/transcripts_tiny/2.11.2 Lake Model Meets Data (1 of 2).srt', 'chunk_number': 3, 'timestamps': '00:04:11 --> 00:05:38'}), Document(page_content=\"So Jim's not a particularly. Hard guy to get along with. He's actually very friendly. And so his choice of the word argue. I think tells you a little bit about who you should be talking to about this. You don't want someone that's going to just tell you that it's nice work. You want someone that's going to be able to ask you questions and say, why did you do that? Well, what if you did this instead? So you want someone that's going to push back a little bit. Step eight is then returned to step two and work with a slightly richer model and we repeat steps three, four, five, six and seven. And then once you've done this with a sufficiently rich model, you should think about what decisions are going to be made from this analysis. Figure out what your loss function will be, kind of what are the costs of getting this right or wrong. And then you should perform make decisions based on statistical decision analysis. And so later in the semester, we'll talk more formally about what we mean by fitting your model and the work that goes along with it.\", metadata={'source': 'videos/transcripts_tiny/2.11.1 Lake Model.srt', 'chunk_number': 3, 'timestamps': '00:03:52 --> 00:05:05'}), Document(page_content=\"the average squared deviation of our steady state model for our good recession data ended up being about 29%. Or value 29%age points. Remember that was the units we chose. So the mean squared error was about 29 and for the COVID data it was about 12. So just kind of keep these numbers in the back your head as these are going to be our benchmark for evaluating one model versus another one. And in particular the use of a loss function allows us to be precise about what we mean when we say a model is better or has improved upon a different model. It allows us to move from a qualitative notion of how good a model fits the data to a very quantitative version. So for example instead of saying model 2 appears to do better than model 1 that matching the spike in the COVID error unemployment. We could say that the MSC COVID from model 2 is 5.1 relative to the value of 11.5 from model 1. So we've moved from a qualitative statement here to a quantitative numerical statement down below. And this will make it easier to have\", metadata={'source': 'videos/transcripts_tiny/2.11.2 Lake Model Meets Data (1 of 2).srt', 'chunk_number': 27, 'timestamps': '00:35:11 --> 00:36:31'}), Document(page_content=\"model and the blue line representing the COVID era data. So these initial test values as we just noticed did improve the MSC but we didn't have any reason to believe that the values we picked were going to be the optimal or best values. There are infinite numbers of configurations of alpha hat, beta hat and end we could have tried or infinite number of other models we could have used. And so what we're going to do next is we're going to assume the role of the visual econometrition and hard goals will be to look at these graphs and graphs and the MSC to try to manually adjust alpha hat, beta hat and end to improve upon this MSC of 2.6. So we're going to utilize the ipy widgets library to create an interactive version of our chart. So here we see that we're going to wrap the simulate plot and MSC steps in a function and then we're going to use the intractor team and say how we'd like alpha hat to be manipulated, beta hat to be manipulated and then a starting value for end. And what this did was it returned our MSC like we had before and we see that we're still near\", metadata={'source': 'videos/transcripts_tiny/2.11.2 Lake Model Meets Data (1 of 2).srt', 'chunk_number': 42, 'timestamps': '00:55:22 --> 00:56:55'})]\u001b[0m\u001b[32;1m\u001b[1;3m{\n",
      "  \"description\": \"Question where user is presented a prompt in `question_text` and \\na list of `choices`. They are supposed to provide the single best\\nanswer (`solution`) as an integer, which is the index into `choices.\\n\\nAll questions must have a minimum of 3 options\\n\\nExamples\\n--------\\n{\\n  \\\"question_text\\\": \\\"In the context of convex optimization, which of the following statements is true regarding the use of a loss function?\\n\\nBelow is an example of how it might be used\\n\\n```python\\n# Example of a loss function in Python\\ndef loss_function(actual, predicted):\\n    return ((actual - predicted) ** 2).mean()\\n```\\n\\\",\\n  \\\"difficulty\\\": 2,\\n  \\\"topics\\\": [\\\"convex optimization\\\", \\\"loss function\\\", \\\"model evaluation\\\"],\\n  \\\"choices\\\": [\\n    \\\"A loss function quantifies how well a model's predictions match the actual data\\\",\\n    \\\"A loss function is used to assign random weights to the model's parameters\\\",\\n    \\\"A loss function is only applicable for classification problems\\\"\\n  ],\\n  \\\"solution\\\": 0\\n}\\n\",\n",
      "  \"properties\": {\n",
      "    \"question_text\": {\n",
      "      \"description\": \"The main text of the question. Markdown formatted\",\n",
      "      \"title\": \"Question Text\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"difficulty\": {\n",
      "      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n",
      "      \"title\": \"Difficulty\",\n",
      "      \"type\": \"integer\"\n",
      "    },\n",
      "    \"topics\": {\n",
      "      \"description\": \"A list of one or more topics that the question is testing\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Topics\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"choices\": {\n",
      "      \"description\": \"A list of markdown formatted strings representing the options for the student. Minimum of length 3\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Choices\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"solution\": {\n",
      "      \"description\": \"Index into choices representing correct answer. Zero based\",\n",
      "      \"title\": \"Solution\",\n",
      "      \"type\": \"integer\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"question_text\",\n",
      "    \"difficulty\",\n",
      "    \"topics\",\n",
      "    \"choices\",\n",
      "    \"solution\"\n",
      "  ]\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "any intermediate_steps?:  True\n",
      "output:\n",
      " {\n",
      "  \"description\": \"Question where user is presented a prompt in `question_text` and \\na list of `choices`. They are supposed to provide the single best\\nanswer (`solution`) as an integer, which is the index into `choices.\\n\\nAll questions must have a minimum of 3 options\\n\\nExamples\\n--------\\n{\\n  \\\"question_text\\\": \\\"In the context of convex optimization, which of the following statements is true regarding the use of a loss function?\\n\\nBelow is an example of how it might be used\\n\\n```python\\n# Example of a loss function in Python\\ndef loss_function(actual, predicted):\\n    return ((actual - predicted) ** 2).mean()\\n```\\n\\\",\\n  \\\"difficulty\\\": 2,\\n  \\\"topics\\\": [\\\"convex optimization\\\", \\\"loss function\\\", \\\"model evaluation\\\"],\\n  \\\"choices\\\": [\\n    \\\"A loss function quantifies how well a model's predictions match the actual data\\\",\\n    \\\"A loss function is used to assign random weights to the model's parameters\\\",\\n    \\\"A loss function is only applicable for classification problems\\\"\\n  ],\\n  \\\"solution\\\": 0\\n}\\n\",\n",
      "  \"properties\": {\n",
      "    \"question_text\": {\n",
      "      \"description\": \"The main text of the question. Markdown formatted\",\n",
      "      \"title\": \"Question Text\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"difficulty\": {\n",
      "      \"description\": \"An integer from 1 to 3 representing how difficult the question should be. 1 is easiest. 3 is hardest\",\n",
      "      \"title\": \"Difficulty\",\n",
      "      \"type\": \"integer\"\n",
      "    },\n",
      "    \"topics\": {\n",
      "      \"description\": \"A list of one or more topics that the question is testing\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Topics\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"choices\": {\n",
      "      \"description\": \"A list of markdown formatted strings representing the options for the student. Minimum of length 3\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Choices\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"solution\": {\n",
      "      \"description\": \"Index into choices representing correct answer. Zero based\",\n",
      "      \"title\": \"Solution\",\n",
      "      \"type\": \"integer\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"question_text\",\n",
      "    \"difficulty\",\n",
      "    \"topics\",\n",
      "    \"choices\",\n",
      "    \"solution\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "5 validation errors for SingleSelection\nquestion_text\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ndifficulty\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ntopics\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nchoices\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nsolution\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_and_parse_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSingleSelection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2 more questions on convex optimization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[77], line 7\u001b[0m, in \u001b[0;36mgenerate_and_parse_question\u001b[0;34m(pydantic_model, query)\u001b[0m\n\u001b[1;32m      5\u001b[0m report_on_message(response)  \u001b[38;5;66;03m# print a summary of what was produced\u001b[39;00m\n\u001b[1;32m      6\u001b[0m parser \u001b[38;5;241m=\u001b[39m PydanticOutputParser(pydantic_object\u001b[38;5;241m=\u001b[39mpydantic_model)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:28\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     26\u001b[0m         json_str \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup()\n\u001b[1;32m     27\u001b[0m     json_object \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(json_str, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpydantic_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (json\u001b[38;5;241m.\u001b[39mJSONDecodeError, ValidationError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     31\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/typing_extensions.py:2360\u001b[0m, in \u001b[0;36mdeprecated.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2357\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(arg)\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2359\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, category\u001b[38;5;241m=\u001b[39mcategory, stacklevel\u001b[38;5;241m=\u001b[39mstacklevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 2360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/pydantic/main.py:1010\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;129m@typing_extensions\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated(\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39mPydanticDeprecatedSince20\n\u001b[1;32m   1007\u001b[0m )\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_obj\u001b[39m(\u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[Model], obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Model:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/pydantic/main.py:503\u001b[0m, in \u001b[0;36mBaseModel.model_validate\u001b[0;34m(cls, obj, strict, from_attributes, context)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    502\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 5 validation errors for SingleSelection\nquestion_text\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ndifficulty\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ntopics\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nchoices\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nsolution\n  Field required [type=missing, input_value={'description': 'Question... 'choices', 'solution']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing"
     ]
    }
   ],
   "source": [
    "generate_and_parse_question(SingleSelection, \"2 more questions on convex optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "06922d5c-e561-4fcf-814d-0e544e898185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_course_content` with `convex optimization`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(page_content=\"these model these problems are that they use the same statistical model F of a given data. There are some tools that allow us to solve the direct problem which again relates to simulating artificial data and these tools in fact turn out to be helpful when solving the inverse problem or learning something about the parameter vector theta. We're going to be continuing in this general framework of a statistical model the direct problem in the inverse problem as we talk today about the lake model of unemployment that we've been working with and we want to make sure that as we work through the materials in this lecture that you keep this overall framework in mind and our goal today will be to use the lake model and its parameters and inferences we can make about its parameters given real world data from the BLS and it will help us understand the unemployment and employment rates over time and how they may change in various settings or in various economic climates. This first code cell here will just import some of the tools we'll be using.\", metadata={'source': 'videos/transcripts_tiny/2.11.2 Lake Model Meets Data (1 of 2).srt', 'chunk_number': 3, 'timestamps': '00:04:11 --> 00:05:38'}), Document(page_content=\"So Jim's not a particularly. Hard guy to get along with. He's actually very friendly. And so his choice of the word argue. I think tells you a little bit about who you should be talking to about this. You don't want someone that's going to just tell you that it's nice work. You want someone that's going to be able to ask you questions and say, why did you do that? Well, what if you did this instead? So you want someone that's going to push back a little bit. Step eight is then returned to step two and work with a slightly richer model and we repeat steps three, four, five, six and seven. And then once you've done this with a sufficiently rich model, you should think about what decisions are going to be made from this analysis. Figure out what your loss function will be, kind of what are the costs of getting this right or wrong. And then you should perform make decisions based on statistical decision analysis. And so later in the semester, we'll talk more formally about what we mean by fitting your model and the work that goes along with it.\", metadata={'source': 'videos/transcripts_tiny/2.11.1 Lake Model.srt', 'chunk_number': 3, 'timestamps': '00:03:52 --> 00:05:05'}), Document(page_content=\"the average squared deviation of our steady state model for our good recession data ended up being about 29%. Or value 29%age points. Remember that was the units we chose. So the mean squared error was about 29 and for the COVID data it was about 12. So just kind of keep these numbers in the back your head as these are going to be our benchmark for evaluating one model versus another one. And in particular the use of a loss function allows us to be precise about what we mean when we say a model is better or has improved upon a different model. It allows us to move from a qualitative notion of how good a model fits the data to a very quantitative version. So for example instead of saying model 2 appears to do better than model 1 that matching the spike in the COVID error unemployment. We could say that the MSC COVID from model 2 is 5.1 relative to the value of 11.5 from model 1. So we've moved from a qualitative statement here to a quantitative numerical statement down below. And this will make it easier to have\", metadata={'source': 'videos/transcripts_tiny/2.11.2 Lake Model Meets Data (1 of 2).srt', 'chunk_number': 27, 'timestamps': '00:35:11 --> 00:36:31'}), Document(page_content=\"model and the blue line representing the COVID era data. So these initial test values as we just noticed did improve the MSC but we didn't have any reason to believe that the values we picked were going to be the optimal or best values. There are infinite numbers of configurations of alpha hat, beta hat and end we could have tried or infinite number of other models we could have used. And so what we're going to do next is we're going to assume the role of the visual econometrition and hard goals will be to look at these graphs and graphs and the MSC to try to manually adjust alpha hat, beta hat and end to improve upon this MSC of 2.6. So we're going to utilize the ipy widgets library to create an interactive version of our chart. So here we see that we're going to wrap the simulate plot and MSC steps in a function and then we're going to use the intractor team and say how we'd like alpha hat to be manipulated, beta hat to be manipulated and then a starting value for end. And what this did was it returned our MSC like we had before and we see that we're still near\", metadata={'source': 'videos/transcripts_tiny/2.11.2 Lake Model Meets Data (1 of 2).srt', 'chunk_number': 42, 'timestamps': '00:55:22 --> 00:56:55'})]\u001b[0m\u001b[32;1m\u001b[1;3m{\n",
      "  \"question_text\": \"Which of the following statements are true regarding the use of loss functions in convex optimization?\",\n",
      "  \"difficulty\": 3,\n",
      "  \"topics\": [\"convex optimization\", \"loss functions\"],\n",
      "  \"choices\": [\n",
      "    \"Loss functions allow for a quantitative comparison between models.\",\n",
      "    \"Loss functions are only applicable for linear models.\",\n",
      "    \"The mean squared error (MSE) is an example of a loss function used in convex optimization.\",\n",
      "    \"Loss functions can only be used when the model parameters are known with certainty.\"\n",
      "  ],\n",
      "  \"solution\": [0, 2]\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "any intermediate_steps?:  True\n",
      "output:\n",
      " {\n",
      "  \"question_text\": \"Which of the following statements are true regarding the use of loss functions in convex optimization?\",\n",
      "  \"difficulty\": 3,\n",
      "  \"topics\": [\"convex optimization\", \"loss functions\"],\n",
      "  \"choices\": [\n",
      "    \"Loss functions allow for a quantitative comparison between models.\",\n",
      "    \"Loss functions are only applicable for linear models.\",\n",
      "    \"The mean squared error (MSE) is an example of a loss function used in convex optimization.\",\n",
      "    \"Loss functions can only be used when the model parameters are known with certainty.\"\n",
      "  ],\n",
      "  \"solution\": [0, 2]\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Which of the following statements are true regarding the use of loss functions in convex optimization?\n",
       "\n",
       "- [x] Loss functions allow for a quantitative comparison between models.\n",
       "- [ ] Loss functions are only applicable for linear models.\n",
       "- [x] The mean squared error (MSE) is an example of a loss function used in convex optimization.\n",
       "- [ ] Loss functions can only be used when the model parameters are known with certainty.\n"
      ],
      "text/plain": [
       "Which of the following statements are true regarding the use of loss functions in convex optimization?\n",
       "\n",
       "- [x] Loss functions allow for a quantitative comparison between models.\n",
       "- [ ] Loss functions are only applicable for linear models.\n",
       "- [x] The mean squared error (MSE) is an example of a loss function used in convex optimization.\n",
       "- [ ] Loss functions can only be used when the model parameters are known with certainty."
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_and_parse_question(MultipleSelection, \"Give me a more difficult question on the convex optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "609d7fe2-77b3-4baa-a28d-618e8b6c4b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "  \"apology\": \"I apologize, but I can only generate one question at a time. Please provide the topic and difficulty for the next question you would like to generate.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "any intermediate_steps?:  False\n",
      "output:\n",
      " {\n",
      "  \"apology\": \"I apologize, but I can only generate one question at a time. Please provide the topic and difficulty for the next question you would like to generate.\"\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "5 validation errors for MultipleSelection\nquestion_text\n  Field required [type=missing, input_value={'apology': 'I apologize,...ould like to generate.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ndifficulty\n  Field required [type=missing, input_value={'apology': 'I apologize,...ould like to generate.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ntopics\n  Field required [type=missing, input_value={'apology': 'I apologize,...ould like to generate.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nchoices\n  Field required [type=missing, input_value={'apology': 'I apologize,...ould like to generate.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nsolution\n  Field required [type=missing, input_value={'apology': 'I apologize,...ould like to generate.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_and_parse_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMultipleSelection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGive me two more questions on convex optimization, difficulty 1.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[77], line 7\u001b[0m, in \u001b[0;36mgenerate_and_parse_question\u001b[0;34m(pydantic_model, query)\u001b[0m\n\u001b[1;32m      5\u001b[0m report_on_message(response)  \u001b[38;5;66;03m# print a summary of what was produced\u001b[39;00m\n\u001b[1;32m      6\u001b[0m parser \u001b[38;5;241m=\u001b[39m PydanticOutputParser(pydantic_object\u001b[38;5;241m=\u001b[39mpydantic_model)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/langchain/output_parsers/pydantic.py:28\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     26\u001b[0m         json_str \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup()\n\u001b[1;32m     27\u001b[0m     json_object \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(json_str, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpydantic_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (json\u001b[38;5;241m.\u001b[39mJSONDecodeError, ValidationError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     31\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/typing_extensions.py:2360\u001b[0m, in \u001b[0;36mdeprecated.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2357\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(arg)\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2359\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, category\u001b[38;5;241m=\u001b[39mcategory, stacklevel\u001b[38;5;241m=\u001b[39mstacklevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 2360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/pydantic/main.py:1010\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;129m@typing_extensions\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated(\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39mPydanticDeprecatedSince20\n\u001b[1;32m   1007\u001b[0m )\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_obj\u001b[39m(\u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[Model], obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Model:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/jupyteach/lib/python3.11/site-packages/pydantic/main.py:503\u001b[0m, in \u001b[0;36mBaseModel.model_validate\u001b[0;34m(cls, obj, strict, from_attributes, context)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    502\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 5 validation errors for MultipleSelection\nquestion_text\n  Field required [type=missing, input_value={'apology': 'I apologize,...ould like to generate.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ndifficulty\n  Field required [type=missing, input_value={'apology': 'I apologize,...ould like to generate.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\ntopics\n  Field required [type=missing, input_value={'apology': 'I apologize,...ould like to generate.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nchoices\n  Field required [type=missing, input_value={'apology': 'I apologize,...ould like to generate.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing\nsolution\n  Field required [type=missing, input_value={'apology': 'I apologize,...ould like to generate.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.4/v/missing"
     ]
    }
   ],
   "source": [
    "generate_and_parse_question(MultipleSelection, \"Give me two more questions on convex optimization, difficulty 1.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyteach)",
   "language": "python",
   "name": "jupyteach"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
